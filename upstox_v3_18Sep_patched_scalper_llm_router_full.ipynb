{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d508602e",
   "metadata": {},
   "source": [
    "\n",
    "# `upstox_v3_18Sep_patched_scalper_llm_router_full.ipynb`  \n",
    "**NIFTY Intraday Scalper** — Spot‑Anchored + Greeks + IV‑Z + Marketable‑Limit + Recenter + Latency + **LLM Router**\n",
    "\n",
    "**Scoring router:** Calls a local **stub** first (`LLM_ENDPOINT`), then calls **Ollama** only when `0.35 < score < 0.75`.  \n",
    "Logs comparative **latency** and **agreement rate** (stub‑only vs final decision).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c71ed5",
   "metadata": {},
   "source": [
    "\n",
    "## Requirements & safety\n",
    "- Python 3.9+; packages: `pandas`, `numpy`, `upstox-python-sdk` (or `upstox_client`), `requests`, `IPython`\n",
    "- Set token: `export UPSTOX_ACCESS_TOKEN=...` or paste into `CredentialUpstox.ACCESS_TOKEN`\n",
    "- Optional local scorer: run `uvicorn score_stub:app --host 127.0.0.1 --port 8000 --workers 1`\n",
    "\n",
    "**Safety defaults**\n",
    "- `SIMULATION_MODE = False` (live-first streaming)\n",
    "- `ORDERS_LIVE = False` (dry‑run orders)\n",
    "- `EXIT_MANAGER_LIVE = False` (simulated exits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Imports & global config ----\n",
    "import os, json, time, threading, math, traceback\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "# Upstox SDK\n",
    "try:\n",
    "    import upstox_client\n",
    "    from upstox_client.rest import ApiException\n",
    "    UPSDK_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    UPSDK_AVAILABLE = False\n",
    "    print(\"Upstox SDK not available. Install it to run live streaming and orders.\")\n",
    "    print(\"Example: pip install upstox-python-sdk   # confirm exact name per Upstox docs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e106aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Toggles & constants ----\n",
    "SIMULATION_MODE = False       # Live-first\n",
    "USE_LLM = True                # Enable scoring gate\n",
    "ORDERS_LIVE = False           # Default to dry-run\n",
    "EXIT_MANAGER_LIVE = False     # Simulated exits\n",
    "\n",
    "UNDERLYING = \"NIFTY\"\n",
    "UNDERLYING_SPOT_TOKEN = \"NSE_INDEX|Nifty 50\"\n",
    "SPAN_STRIKES = 2              # ATM ± 2 (5 strikes)\n",
    "WEBSOCKET_MODE = \"full_d30\"\n",
    "IST = \"Asia/Kolkata\"\n",
    "\n",
    "# Strike steps\n",
    "STRIKE_STEP = {\"NIFTY\": 50, \"BANKNIFTY\": 100, \"FINNIFTY\": 50}\n",
    "\n",
    "# Risk limits\n",
    "MAX_QTY_PER_LEG = 300\n",
    "MAX_OPEN_LEGS = 6\n",
    "\n",
    "# Recenter parameters\n",
    "RECENTER_COOLDOWN_S = 60.0\n",
    "RECENTER_LOG = True\n",
    "\n",
    "# === Trade gates & execution params (scalping) ===\n",
    "DELTA_MIN, DELTA_MAX = 0.45, 0.55           # abs(Delta) in [0.45, 0.55]\n",
    "SPREAD_MAX = 0.20                            # rupees\n",
    "DEPTH_IMB_MIN = 0.15                         # direction-of-entry bias\n",
    "IV_Z_MAX = 2.0                               # skip entries if |z_IV| > 2\n",
    "IV_Z_MIN_COUNT = 30                          # warm-up samples before gating IV\n",
    "\n",
    "# Execution (marketable limit orders)\n",
    "USE_MARKETABLE_LIMITS = True\n",
    "LIMIT_BUFFER_TICKS = 1                       # 1 tick beyond BBO to ensure fill while capping slippage\n",
    "\n",
    "# Throttle (burst control)\n",
    "ORDER_MIN_GAP_MS = 200                       # min time between order sends\n",
    "\n",
    "# === LLM Scoring ===\n",
    "# Option A: generic HTTP endpoint that returns {\"score\": float}\n",
    "LLM_ENDPOINT = os.getenv(\"LLM_ENDPOINT\", \"\") # e.g., http://127.0.0.1:8000/score\n",
    "LLM_TIMEOUT_S = float(os.getenv(\"LLM_TIMEOUT_S\", \"0.12\"))\n",
    "\n",
    "# Option B: local Ollama (if OLLAMA_MODEL is set)\n",
    "OLLAMA_HOST = os.getenv(\"OLLAMA_HOST\", \"http://127.0.0.1:11434\")\n",
    "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"\")  # e.g., \"mistral\"\n",
    "OLLAMA_TIMEOUT_S = float(os.getenv(\"OLLAMA_TIMEOUT_S\", \"0.20\"))\n",
    "OLLAMA_NUM_PREDICT = int(os.getenv(\"OLLAMA_NUM_PREDICT\", \"16\"))\n",
    "\n",
    "LLM_SCORE_THRESHOLD = 0.55                   # final trade/no-trade threshold\n",
    "\n",
    "# === Router (stub first, then Ollama in gray zone) ===\n",
    "USE_ROUTER = True\n",
    "STUB_LOWER, STUB_UPPER = 0.35, 0.75\n",
    "\n",
    "# Latency logging\n",
    "LATENCY_LOG = []\n",
    "LATENCY_LOG_MAX = 5000\n",
    "\n",
    "# Router logs\n",
    "ROUTER_LOG = []\n",
    "ROUTER_LOG_MAX = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f47c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Credentials & product mapping ----\n",
    "class CredentialUpstox:\n",
    "    ACCESS_TOKEN = os.getenv(\"UPSTOX_ACCESS_TOKEN\", \"\")  # paste here if not using env\n",
    "\n",
    "PRODUCT_MAP = {\n",
    "    \"MIS\": \"I\",   # Intraday\n",
    "    \"NRML\": \"D\",  # Carry/Delivery\n",
    "}\n",
    "DEFAULT_PRODUCT = \"MIS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70817d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Utilities ----\n",
    "def to_ist_ms(ms) -> pd.Timestamp:\n",
    "    try:\n",
    "        return pd.to_datetime(int(ms), unit=\"ms\", utc=True).tz_convert(IST)\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def resolve_next_listed_expiry(df_instruments: pd.DataFrame, underlying: str, today=None) -> str:\n",
    "    t = pd.Timestamp.now(IST).normalize() if today is None else pd.Timestamp(today, tz=IST).normalize()\n",
    "    dfx = df_instruments[\n",
    "        (df_instruments[\"segment\"] == \"NSE_FO\") &\n",
    "        (df_instruments[\"name\"].str.upper() == underlying.upper()) &\n",
    "        (df_instruments[\"instrument_type\"].isin([\"CE\",\"PE\"]))\n",
    "    ].copy()\n",
    "    if dfx.empty:\n",
    "        raise ValueError(f\"No derivatives found for {underlying} in instruments master\")\n",
    "    dfx[\"_exp\"] = pd.to_datetime(dfx[\"expiry\"], errors=\"coerce\")\n",
    "    dfx = dfx[dfx[\"_exp\"] >= t.tz_localize(None)]\n",
    "    if dfx.empty:\n",
    "        raise ValueError(f\"No upcoming expiry >= {t.date()} for {underlying}\")\n",
    "    return dfx[\"_exp\"].min().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def nearest_strikes_from_spot(spot_ltp: float, underlying: str, span: int = 2) -> List[int]:\n",
    "    step = STRIKE_STEP.get(underlying.upper(), 50)\n",
    "    nearest = int(step * math.floor((spot_ltp + step/2) / step))\n",
    "    return [nearest + i * step for i in range(-span, span+1)]\n",
    "\n",
    "def get_upstox_quote_client():\n",
    "    if not UPSDK_AVAILABLE:\n",
    "        raise RuntimeError(\"Upstox SDK is not available.\")\n",
    "    if not CredentialUpstox.ACCESS_TOKEN:\n",
    "        raise RuntimeError(\"ACCESS_TOKEN missing. Set UPSTOX_ACCESS_TOKEN or paste in CredentialUpstox.\")\n",
    "    configuration = upstox_client.Configuration()\n",
    "    configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n",
    "    return upstox_client.MarketQuoteV3Api(upstox_client.ApiClient(configuration))\n",
    "\n",
    "def _extract_ltp_from_entry(entry: dict) -> float:\n",
    "    if not isinstance(entry, dict):\n",
    "        raise KeyError(\"Invalid LTP entry\")\n",
    "    for k in (\"ltp\", \"last_price\", \"last_traded_price\", \"last\", \"close\"):\n",
    "        if k in entry and entry[k] is not None:\n",
    "            return float(entry[k])\n",
    "    if \"ltpc\" in entry and isinstance(entry[\"ltpc\"], dict) and \"ltp\" in entry[\"ltpc\"]:\n",
    "        return float(entry[\"ltpc\"][\"ltp\"])\n",
    "    raise KeyError(f\"No LTP field found in entry keys={list(entry.keys())}\")\n",
    "\n",
    "def get_index_spot_ltp(instrument_key: str = None) -> float:\n",
    "    instrument_key = instrument_key or UNDERLYING_SPOT_TOKEN\n",
    "    api = get_upstox_quote_client()\n",
    "    try:\n",
    "        api_response = api.get_ltp(instrument_key=[instrument_key])\n",
    "        data_dict = api_response.to_dict() if hasattr(api_response, \"to_dict\") else dict(api_response)\n",
    "        data = data_dict.get(\"data\", {})\n",
    "        entry = data.get(instrument_key) or (next(iter(data.values())) if data else {})\n",
    "        ltp = _extract_ltp_from_entry(entry)\n",
    "        if not np.isfinite(ltp):\n",
    "            raise RuntimeError(f\"LTP non-finite: {ltp}\")\n",
    "        return float(ltp)\n",
    "    except ApiException as e:\n",
    "        raise RuntimeError(f\"Upstox get_ltp ApiException: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc0e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Load instruments master (live) ----\n",
    "def load_instruments_live() -> pd.DataFrame:\n",
    "    url = \"https://assets.upstox.com/market-quote/instruments/exchange/NSE.json.gz\"\n",
    "    try:\n",
    "        df = pd.read_json(url)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load instruments from {url}: {e}\")\n",
    "    # Normalize\n",
    "    if \"expiry\" in df:\n",
    "        exp = pd.to_datetime(df[\"expiry\"], unit=\"ms\", errors=\"coerce\")\n",
    "        mask = exp.isna() & df[\"expiry\"].notna()\n",
    "        if mask.any():\n",
    "            exp2 = pd.to_datetime(df.loc[mask, \"expiry\"], errors=\"coerce\")\n",
    "            exp.loc[mask] = exp2\n",
    "        df[\"expiry\"] = exp.dt.strftime(\"%Y-%m-%d\")\n",
    "    for col in (\"strike_price\",\"lot_size\",\"tick_size\",\"minimum_lot\"):\n",
    "        if col in df:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "df_futureOptions = load_instruments_live()\n",
    "assert not df_futureOptions.empty, \"Instruments master is empty\"\n",
    "display(df_futureOptions.head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cead00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Build current chain & anchor ATM via spot ----\n",
    "expiry_target = resolve_next_listed_expiry(df_futureOptions, UNDERLYING)\n",
    "df_chain = df_futureOptions[\n",
    "    (df_futureOptions[\"segment\"] == \"NSE_FO\") &\n",
    "    (df_futureOptions[\"name\"].str.upper() == UNDERLYING.upper()) &\n",
    "    (df_futureOptions[\"instrument_type\"].isin([\"CE\",\"PE\"])) &\n",
    "    (df_futureOptions[\"expiry\"] == expiry_target)\n",
    "].copy()\n",
    "assert not df_chain.empty, f\"No options found for {UNDERLYING} expiry={expiry_target}\"\n",
    "print(f\"Chain size for {UNDERLYING} expiry {expiry_target}: {len(df_chain)} rows\")\n",
    "\n",
    "# Anchor ATM from live spot LTP (REST) with fallback\n",
    "try:\n",
    "    spot_ltp_initial = get_index_spot_ltp(UNDERLYING_SPOT_TOKEN)\n",
    "    print(f\"NIFTY 50 spot LTP: {spot_ltp_initial:.2f}\")\n",
    "except Exception as e:\n",
    "    print(\"Spot LTP lookup failed; falling back to chain median. Reason:\", e)\n",
    "    spot_ltp_initial = float(df_chain[\"strike_price\"].median())\n",
    "\n",
    "strike_list = nearest_strikes_from_spot(spot_ltp_initial, UNDERLYING, span=SPAN_STRIKES)\n",
    "df_chain_sel = df_chain[df_chain[\"strike_price\"].isin(strike_list)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "token_list = df_chain_sel[\"instrument_key\"].dropna().astype(str).unique().tolist()\n",
    "assert token_list, \"No tokens to subscribe after ATM filtering\"\n",
    "\n",
    "print(f\"Selected strikes from spot {spot_ltp_initial:.2f}: {sorted(set(strike_list))}\")\n",
    "display(df_chain_sel.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Feed structures, enrichment, IV stats ----\n",
    "df_feed = pd.DataFrame(columns=[\n",
    "    \"Token\",\"Ltp\",\"Ltq\",\"Cp\",\n",
    "    \"BidP1\",\"BidQ1\",\"AskP1\",\"AskQ1\",\n",
    "    \"Ltt\",\"Oi\",\"Iv\",\"Atp\",\"Tbq\",\"Tsq\",\n",
    "    \"Delta\",\"Theta\",\"Gamma\",\"Vega\",\"Rho\"\n",
    "])\n",
    "df_feed_enriched = pd.DataFrame()\n",
    "\n",
    "_df_lock = threading.Lock()\n",
    "\n",
    "def enrich_feed(_df_feed: pd.DataFrame, _df_meta: pd.DataFrame, cols_to_add=None) -> pd.DataFrame:\n",
    "    if cols_to_add is None:\n",
    "        cols_to_add = [\"lot_size\",\"trading_symbol\",\"strike_price\",\"tick_size\",\"instrument_type\",\"expiry\",\"name\"]\n",
    "    left = _df_feed.copy()\n",
    "    right = _df_meta[[\"instrument_key\"] + [c for c in cols_to_add if c in _df_meta.columns]].drop_duplicates(\"instrument_key\")\n",
    "    out = left.merge(right, left_on=\"Token\", right_on=\"instrument_key\", how=\"left\", validate=\"m:1\")\n",
    "    out[\"Mid\"] = np.where(out[\"BidP1\"].notna() & out[\"AskP1\"].notna(), (out[\"BidP1\"] + out[\"AskP1\"])/2.0, out[\"Ltp\"])\n",
    "    out[\"Spread\"] = np.where(out[\"BidP1\"].notna() & out[\"AskP1\"].notna(), (out[\"AskP1\"] - out[\"BidP1\"]), np.nan)\n",
    "    out[\"DepthImb\"] = np.where(\n",
    "        (out[\"BidQ1\"].notna() & out[\"AskQ1\"].notna() & ((out[\"BidQ1\"] + out[\"AskQ1\"]) > 0)),\n",
    "        (out[\"BidQ1\"] - out[\"AskQ1\"]) / (out[\"BidQ1\"] + out[\"AskQ1\"]),\n",
    "        np.nan,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# Online IV z-score stats (per token)\n",
    "from collections import defaultdict\n",
    "_iv_stats = defaultdict(lambda: {\"n\":0, \"mean\":0.0, \"M2\":0.0})\n",
    "\n",
    "def update_iv_stats(token: str, iv_value: float):\n",
    "    if iv_value is None or not np.isfinite(iv_value): \n",
    "        return\n",
    "    s = _iv_stats[token]\n",
    "    n1 = s[\"n\"] + 1\n",
    "    delta = iv_value - s[\"mean\"]\n",
    "    mean = s[\"mean\"] + delta / n1\n",
    "    delta2 = iv_value - mean\n",
    "    M2 = s[\"M2\"] + delta * delta2\n",
    "    s[\"n\"], s[\"mean\"], s[\"M2\"] = n1, mean, M2\n",
    "\n",
    "def iv_zscore_for(token: str, iv_value: float):\n",
    "    s = _iv_stats[token]\n",
    "    if s[\"n\"] < max(IV_Z_MIN_COUNT, 2):\n",
    "        return 0.0, True\n",
    "    var = s[\"M2\"] / max(s[\"n\"] - 1, 1)\n",
    "    std = math.sqrt(max(var, 1e-12))\n",
    "    z = (iv_value - s[\"mean\"]) / std if std > 0 else 0.0\n",
    "    return z, (abs(z) <= IV_Z_MAX)\n",
    "\n",
    "# Streaming globals\n",
    "live_streamer = None\n",
    "current_tokens = list(token_list)\n",
    "spot_ltp_current = spot_ltp_initial\n",
    "last_center_nearest = int(STRIKE_STEP[UNDERLYING] * math.floor((spot_ltp_initial + STRIKE_STEP[UNDERLYING]/2)/STRIKE_STEP[UNDERLYING]))\n",
    "_last_recenter_ts = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d7de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Live streamer (Greeks + IV stats + Spot) ----\n",
    "def start_live_stream(tokens: List[str], mode: str = \"full_d30\"):\n",
    "    global live_streamer\n",
    "    if not UPSDK_AVAILABLE:\n",
    "        raise RuntimeError(\"Upstox SDK not installed.\")\n",
    "    if not CredentialUpstox.ACCESS_TOKEN:\n",
    "        raise RuntimeError(\"ACCESS_TOKEN missing. Set UPSTOX_ACCESS_TOKEN or paste into CredentialUpstox.ACCESS_TOKEN\")\n",
    "\n",
    "    configuration = upstox_client.Configuration()\n",
    "    configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n",
    "    api_client = upstox_client.ApiClient(configuration)\n",
    "    streamer = upstox_client.MarketDataStreamerV3(api_client, instrument_key=tokens, mode=mode)\n",
    "\n",
    "    def _on_message(msg):\n",
    "        global df_feed, df_feed_enriched, spot_ltp_current\n",
    "        feeds = msg.get(\"feeds\", {})\n",
    "        for token, payload in feeds.items():\n",
    "            ff = payload.get(\"fullFeed\",{}).get(\"marketFF\",{})\n",
    "            ltpc = ff.get(\"ltpc\",{})\n",
    "            level = ff.get(\"marketLevel\",{}).get(\"bidAskQuote\",[{}])\n",
    "            greeks = ff.get(\"optionGreeks\",{}) or {}\n",
    "\n",
    "            if token == UNDERLYING_SPOT_TOKEN:\n",
    "                try:\n",
    "                    if ltpc.get(\"ltp\") is not None:\n",
    "                        spot_ltp_current = float(ltpc.get(\"ltp\"))\n",
    "                except Exception:\n",
    "                    pass\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                iv_val = ff.get(\"iv\")\n",
    "                if iv_val is not None:\n",
    "                    update_iv_stats(token, float(iv_val))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            row = {\n",
    "                \"Token\": token,\n",
    "                \"Ltp\": float(ltpc.get(\"ltp\")) if ltpc.get(\"ltp\") is not None else np.nan,\n",
    "                \"Ltq\": float(ltpc.get(\"ltq\")) if ltpc.get(\"ltq\") is not None else np.nan,\n",
    "                \"Cp\": float(ltpc.get(\"cp\")) if ltpc.get(\"cp\") is not None else np.nan,\n",
    "                \"BidP1\": float(level[0].get(\"bidP\")) if level and level[0].get(\"bidP\") is not None else np.nan,\n",
    "                \"BidQ1\": float(level[0].get(\"bidQ\")) if level and level[0].get(\"bidQ\") is not None else np.nan,\n",
    "                \"AskP1\": float(level[0].get(\"askP\")) if level and level[0].get(\"askP\") is not None else np.nan,\n",
    "                \"AskQ1\": float(level[0].get(\"askQ\")) if level and level[0].get(\"askQ\") is not None else np.nan,\n",
    "                \"Ltt\": to_ist_ms(ltpc.get(\"ltt\")),\n",
    "                \"Oi\": float(ff.get(\"oi\")) if ff.get(\"oi\") is not None else np.nan,\n",
    "                \"Iv\": float(ff.get(\"iv\")) if ff.get(\"iv\") is not None else np.nan,\n",
    "                \"Atp\": float(ff.get(\"atp\")) if ff.get(\"atp\") is not None else np.nan,\n",
    "                \"Tbq\": float(ff.get(\"tbq\")) if ff.get(\"tbq\") is not None else np.nan,\n",
    "                \"Tsq\": float(ff.get(\"tsq\")) if ff.get(\"tsq\") is not None else np.nan,\n",
    "                \"Delta\": float(greeks.get(\"delta\")) if greeks.get(\"delta\") is not None else np.nan,\n",
    "                \"Theta\": float(greeks.get(\"theta\")) if greeks.get(\"theta\") is not None else np.nan,\n",
    "                \"Gamma\": float(greeks.get(\"gamma\")) if greeks.get(\"gamma\") is not None else np.nan,\n",
    "                \"Vega\":  float(greeks.get(\"vega\"))  if greeks.get(\"vega\")  is not None else np.nan,\n",
    "                \"Rho\":   float(greeks.get(\"rho\"))   if greeks.get(\"rho\")   is not None else np.nan,\n",
    "            }\n",
    "            with _df_lock:\n",
    "                if token in df_feed[\"Token\"].values:\n",
    "                    for k,v in row.items():\n",
    "                        df_feed.loc[df_feed[\"Token\"]==token, k] = v\n",
    "                else:\n",
    "                    df_feed = pd.concat([df_feed, pd.DataFrame([row])], ignore_index=True)\n",
    "                df_feed_enriched = enrich_feed(df_feed, df_chain)\n",
    "\n",
    "    def _on_open():\n",
    "        print(\"WebSocket opened\")\n",
    "\n",
    "    def _on_error(err):\n",
    "        print(\"WebSocket error:\", err)\n",
    "\n",
    "    def _on_close():\n",
    "        print(\"WebSocket closed\")\n",
    "\n",
    "    streamer.on_message = _on_message\n",
    "    streamer.on_open = _on_open\n",
    "    streamer.on_error = _on_error\n",
    "    streamer.on_close = _on_close\n",
    "\n",
    "    streamer.connect()\n",
    "    live_streamer = streamer\n",
    "    return streamer\n",
    "\n",
    "def stop_live_stream():\n",
    "    global live_streamer\n",
    "    try:\n",
    "        if live_streamer is not None:\n",
    "            if hasattr(live_streamer, \"close\"):\n",
    "                live_streamer.close()\n",
    "            elif hasattr(live_streamer, \"disconnect\"):\n",
    "                live_streamer.disconnect()\n",
    "            elif hasattr(live_streamer, \"ws\"):\n",
    "                live_streamer.ws.close()\n",
    "            print(\"Stream stop requested.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error stopping stream:\", e)\n",
    "    finally:\n",
    "        live_streamer = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca0c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Dynamic recentering ----\n",
    "def compute_token_list_for_spot(spot_ltp: float) -> List[str]:\n",
    "    strikes = nearest_strikes_from_spot(spot_ltp, UNDERLYING, span=SPAN_STRIKES)\n",
    "    df_sel = df_chain[df_chain[\"strike_price\"].isin(strikes)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "    tokens = df_sel[\"instrument_key\"].dropna().astype(str).unique().tolist()\n",
    "    return tokens\n",
    "\n",
    "def maybe_recenter_tokens() -> bool:\n",
    "    global last_center_nearest, _last_recenter_ts, current_tokens, df_chain_sel\n",
    "    step = STRIKE_STEP.get(UNDERLYING.upper(), 50)\n",
    "    nearest = int(step * math.floor((spot_ltp_current + step/2)/step))\n",
    "    now = time.time()\n",
    "    if abs(nearest - last_center_nearest) >= step and (now - _last_recenter_ts) >= RECENTER_COOLDOWN_S:\n",
    "        try:\n",
    "            new_tokens = compute_token_list_for_spot(spot_ltp_current)\n",
    "            if not new_tokens:\n",
    "                return False\n",
    "            tokens_with_spot = list(dict.fromkeys(new_tokens + [UNDERLYING_SPOT_TOKEN]))\n",
    "            if RECENTER_LOG:\n",
    "                print(f\"[RECENTER] spot={spot_ltp_current:.2f}, nearest={nearest}, old_center={last_center_nearest}\")\n",
    "                print(f\"[RECENTER] tokens: {len(current_tokens)} → {len(new_tokens)}\")\n",
    "            stop_live_stream()\n",
    "            start_live_stream(tokens_with_spot, mode=WEBSOCKET_MODE)\n",
    "            last_center_nearest = nearest\n",
    "            _last_recenter_ts = now\n",
    "            current_tokens = new_tokens\n",
    "            df_chain_sel = df_chain[df_chain[\"instrument_key\"].isin(new_tokens)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(\"Recenter failed:\", e)\n",
    "            traceback.print_exc()\n",
    "    return False\n",
    "\n",
    "def recenter_daemon():\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(1.0)\n",
    "            maybe_recenter_tokens()\n",
    "        except Exception:\n",
    "            time.sleep(2.0)\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a521815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Strategy gates & helpers ----\n",
    "def eligible_entry(row: pd.Series, side: str):\n",
    "    reasons = []\n",
    "    delta = row.get(\"Delta\")\n",
    "    if delta is None or not np.isfinite(delta):\n",
    "        reasons.append(\"no_delta\")\n",
    "    else:\n",
    "        if not (DELTA_MIN <= abs(float(delta)) <= DELTA_MAX):\n",
    "            reasons.append(f\"absΔ={abs(float(delta)):.2f}∉[{DELTA_MIN},{DELTA_MAX}]\")\n",
    "    spread = row.get(\"Spread\")\n",
    "    if (spread is None) or (not np.isfinite(spread)) or (float(spread) > SPREAD_MAX):\n",
    "        reasons.append(f\"spread={spread} > {SPREAD_MAX}\")\n",
    "    imb = row.get(\"DepthImb\")\n",
    "    if imb is None or not np.isfinite(imb):\n",
    "        reasons.append(\"no_depthimb\")\n",
    "    else:\n",
    "        imb = float(imb)\n",
    "        if side.upper() == \"BUY\" and imb < +DEPTH_IMB_MIN:\n",
    "            reasons.append(f\"imb={imb:.2f} < +{DEPTH_IMB_MIN}\")\n",
    "        if side.upper() == \"SELL\" and imb > -DEPTH_IMB_MIN:\n",
    "            reasons.append(f\"imb={imb:.2f} > -{DEPTH_IMB_MIN}\")\n",
    "    iv = row.get(\"Iv\")\n",
    "    z, iv_ok = (0.0, True)\n",
    "    try:\n",
    "        if iv is not None and np.isfinite(iv):\n",
    "            z, iv_ok = iv_zscore_for(row[\"Token\"], float(iv))\n",
    "            if not iv_ok:\n",
    "                reasons.append(f\"|z_IV|={abs(z):.2f} > {IV_Z_MAX}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    ok = len(reasons) == 0\n",
    "    return ok, \";\".join(reasons), {\"iv_z\": z}\n",
    "\n",
    "def _compact_row(r: pd.Series):\n",
    "    return {\n",
    "        \"token\": str(r[\"Token\"]),\n",
    "        \"tsym\": str(r.get(\"trading_symbol\", \"\")),\n",
    "        \"mid\": float(r.get(\"Mid\", np.nan)),\n",
    "        \"spread\": float(r.get(\"Spread\", np.nan)),\n",
    "        \"delta\": float(r.get(\"Delta\", np.nan)),\n",
    "        \"gamma\": float(r.get(\"Gamma\", np.nan)),\n",
    "        \"theta\": float(r.get(\"Theta\", np.nan)),\n",
    "        \"iv\": float(r.get(\"Iv\", np.nan)),\n",
    "        \"depthImb\": float(r.get(\"DepthImb\", np.nan)),\n",
    "        \"strike\": float(r.get(\"strike_price\", np.nan)),\n",
    "        \"type\": str(r.get(\"instrument_type\",\"\")),\n",
    "    }\n",
    "\n",
    "def _build_ollama_prompt(context: dict) -> str:\n",
    "    rules = context.get(\"rules\", {})\n",
    "    ce, pe = context.get(\"ce\", {}), context.get(\"pe\", {})\n",
    "    spot = context.get(\"spot\", 0.0)\n",
    "    return (\n",
    "        \"You are a scalping trade scorer. Return a single JSON object with a numeric field 'score' in [0,1].\\n\"\n",
    "        \"Higher score means better conditions to open a short ATM strangle now.\\n\"\n",
    "        \"No explanation, no extra text.\\n\\n\"\n",
    "        f\"spot: {spot}\\n\"\n",
    "        f\"ce: mid={ce.get('mid')}, spread={ce.get('spread')}, delta={ce.get('delta')}, gamma={ce.get('gamma')}, theta={ce.get('theta')}, iv={ce.get('iv')}, depthImb={ce.get('depthImb')}\\n\"\n",
    "        f\"pe: mid={pe.get('mid')}, spread={pe.get('spread')}, delta={pe.get('delta')}, gamma={pe.get('gamma')}, theta={pe.get('theta')}, iv={pe.get('iv')}, depthImb={pe.get('depthImb')}\\n\"\n",
    "        f\"rules: absDelta={rules.get('absDelta')}, spreadMax={rules.get('spreadMax')}, depthImbMin={rules.get('depthImbMin')}, ivZMax={rules.get('ivZMax')}\\n\\n\"\n",
    "        \"Return strictly: {\\\"score\\\": <float>}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Gray-zone router scoring ----\n",
    "def _router_log(entry: dict):\n",
    "    entry = dict(entry)\n",
    "    entry.setdefault(\"t\", time.perf_counter())\n",
    "    ROUTER_LOG.append(entry)\n",
    "    if len(ROUTER_LOG) > ROUTER_LOG_MAX:\n",
    "        del ROUTER_LOG[: len(ROUTER_LOG) - ROUTER_LOG_MAX]\n",
    "\n",
    "def _post_stub(context: dict):\n",
    "    t0 = time.perf_counter()\n",
    "    if not LLM_ENDPOINT:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.post(LLM_ENDPOINT, json=context, timeout=LLM_TIMEOUT_S)\n",
    "        s = float(r.json().get(\"score\", 0.6)) if r.ok else 0.6\n",
    "        return max(0.0, min(1.0, s)), (time.perf_counter() - t0)*1000.0, True\n",
    "    except Exception:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False\n",
    "\n",
    "def _post_ollama(context: dict):\n",
    "    t0 = time.perf_counter()\n",
    "    if not OLLAMA_MODEL:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False\n",
    "    try:\n",
    "        import requests, re\n",
    "        prompt = _build_ollama_prompt(context)\n",
    "        payload = {\n",
    "            \"model\": OLLAMA_MODEL,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False,\n",
    "            \"options\": {\"temperature\": 0.1, \"num_predict\": OLLAMA_NUM_PREDICT},\n",
    "            \"format\": \"json\"\n",
    "        }\n",
    "        r = requests.post(f\"{OLLAMA_HOST}/api/generate\", json=payload, timeout=OLLAMA_TIMEOUT_S)\n",
    "        if not r.ok:\n",
    "            payload.pop(\"format\", None)\n",
    "            r = requests.post(f\"{OLLAMA_HOST}/api/generate\", json=payload, timeout=OLLAMA_TIMEOUT_S)\n",
    "        txt = r.json().get(\"response\", \"\") if r.ok else \"\"\n",
    "        try:\n",
    "            s = float(json.loads(txt).get(\"score\", 0.6))\n",
    "        except Exception:\n",
    "            m = re.search(r\"([01](?:\\.\\d+)?)\", txt)\n",
    "            s = float(m.group(1)) if m else 0.6\n",
    "        return max(0.0, min(1.0, s)), (time.perf_counter() - t0)*1000.0, True\n",
    "    except Exception:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False\n",
    "\n",
    "def _score_with_router(context: dict) -> float:\n",
    "    thr = LLM_SCORE_THRESHOLD\n",
    "    # Stub first\n",
    "    stub_score, stub_ms, stub_ok = _post_stub(context)\n",
    "    stub_decision = (stub_score >= thr)\n",
    "    route = \"no_stub\"\n",
    "    ollama_score, ollama_ms, used_ollama = (None, 0.0, False)\n",
    "\n",
    "    if stub_ok:\n",
    "        if stub_score >= STUB_UPPER:\n",
    "            final_score = stub_score; route = \"stub_high\"\n",
    "        elif stub_score <= STUB_LOWER:\n",
    "            final_score = stub_score; route = \"stub_low\"\n",
    "        else:\n",
    "            o_score, o_ms, o_ok = _post_ollama(context)\n",
    "            used_ollama = True; ollama_score, ollama_ms = (o_score, o_ms)\n",
    "            if o_ok:\n",
    "                final_score = o_score; route = \"gray_ollama\"\n",
    "            else:\n",
    "                final_score = stub_score; route = \"gray_fallback_stub\"\n",
    "    else:\n",
    "        o_score, o_ms, o_ok = _post_ollama(context)\n",
    "        used_ollama = True if o_ok else False; ollama_score, ollama_ms = (o_score, o_ms)\n",
    "        final_score = o_score if o_ok else 0.6\n",
    "        route = \"no_stub_ollama\" if o_ok else \"neutral\"\n",
    "\n",
    "    final_decision = (final_score >= thr)\n",
    "    _router_log({\n",
    "        \"route\": route,\n",
    "        \"stub_score\": stub_score,\n",
    "        \"stub_ms\": round(stub_ms, 2),\n",
    "        \"ollama_score\": ollama_score,\n",
    "        \"ollama_ms\": round(ollama_ms, 2),\n",
    "        \"final_score\": final_score,\n",
    "        \"stub_decision\": stub_decision,\n",
    "        \"final_decision\": final_decision,\n",
    "        \"used_ollama\": used_ollama\n",
    "    })\n",
    "    return float(final_score)\n",
    "\n",
    "def router_report(n_tail: int = 200):\n",
    "    tail = ROUTER_LOG[-n_tail:]\n",
    "    df = pd.DataFrame(tail)\n",
    "    if df.empty:\n",
    "        return df, {}\n",
    "    agree = (df[\"stub_decision\"] == df[\"final_decision\"]).mean()\n",
    "    used_ollama_rate = df[\"used_ollama\"].mean()\n",
    "    avg_stub = df[\"stub_ms\"].mean()\n",
    "    avg_ollama = df.loc[df[\"used_ollama\"], \"ollama_ms\"].mean() if (df[\"used_ollama\"].any()) else float(\"nan\")\n",
    "    routes = df[\"route\"].value_counts().to_dict()\n",
    "    summary = {\n",
    "        \"n\": int(len(df)),\n",
    "        \"agreement_rate\": float(round(agree, 4)),\n",
    "        \"used_ollama_rate\": float(round(used_ollama_rate, 4)),\n",
    "        \"avg_stub_ms\": float(round(avg_stub, 2)),\n",
    "        \"avg_ollama_ms\": float(round(avg_ollama, 2)) if avg_ollama == avg_ollama else None,\n",
    "        \"routes\": routes\n",
    "    }\n",
    "    return df, summary\n",
    "\n",
    "# Strategy with router-backed scoring\n",
    "def ask_llm_for_strategy(df_snapshot: pd.DataFrame, use_mock: bool = True) -> Dict[str, Any]:\n",
    "    if df_snapshot.empty:\n",
    "        return {\"legs\": []}\n",
    "    snap = df_snapshot.dropna(subset=[\"Mid\",\"strike_price\",\"instrument_type\"]).copy()\n",
    "    if snap.empty:\n",
    "        return {\"legs\": []}\n",
    "\n",
    "    snap[\"dist\"] = (snap[\"Mid\"] - snap[\"strike_price\"]).abs()\n",
    "    def delta_score(d):\n",
    "        try:\n",
    "            d = abs(float(d))\n",
    "            return abs(0.5 - d) if np.isfinite(d) else 0.5\n",
    "        except Exception:\n",
    "            return 0.5\n",
    "    snap[\"delta_score\"] = snap[\"Delta\"].apply(delta_score)\n",
    "\n",
    "    picks = []\n",
    "    for opt in (\"CE\",\"PE\"):\n",
    "        sub = snap[snap[\"instrument_type\"] == opt].sort_values([\"dist\",\"delta_score\"]).head(3)\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        picks.append(sub.iloc[0])\n",
    "    if len(picks) < 2:\n",
    "        return {\"legs\": []}\n",
    "    ce_row, pe_row = (picks[0], picks[1]) if picks[0][\"instrument_type\"]==\"CE\" else (picks[1], picks[0])\n",
    "\n",
    "    ce_ok, _, _ = eligible_entry(ce_row, side=\"SELL\")\n",
    "    pe_ok, _, _ = eligible_entry(pe_row, side=\"SELL\")\n",
    "    if not ce_ok or not pe_ok:\n",
    "        return {\"legs\": []}\n",
    "\n",
    "    context = {\n",
    "        \"spot\": float(spot_ltp_current),\n",
    "        \"ce\": _compact_row(ce_row),\n",
    "        \"pe\": _compact_row(pe_row),\n",
    "        \"position\": [],\n",
    "        \"rules\": {\n",
    "            \"absDelta\": [DELTA_MIN, DELTA_MAX],\n",
    "            \"spreadMax\": SPREAD_MAX,\n",
    "            \"depthImbMin\": DEPTH_IMB_MIN,\n",
    "            \"ivZMax\": IV_Z_MAX\n",
    "        }\n",
    "    }\n",
    "    # Always use router; USE_LLM only controls gating by threshold\n",
    "    score = _score_with_router(context)\n",
    "    if USE_LLM and (score < LLM_SCORE_THRESHOLD):\n",
    "        return {\"legs\": []}\n",
    "\n",
    "    legs = []\n",
    "    for r in (ce_row, pe_row):\n",
    "        lot = int(r.get(\"lot_size\") or 0) or 50\n",
    "        legs.append({\"token\": str(r[\"Token\"]), \"side\": \"SELL\", \"qty\": lot, \"product\": DEFAULT_PRODUCT, \"order_type\": \"LIMIT\"})\n",
    "    return {\"legs\": legs, \"meta\": {\"score\": score}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Orders, throttle, latency, exits ----\n",
    "open_positions = {}  # token -> dict(side, qty, avg_price)\n",
    "\n",
    "def record_fill(fill: Dict[str, Any]):\n",
    "    token = str(fill[\"token\"])\n",
    "    side = fill[\"side\"].upper()\n",
    "    qty = int(fill[\"qty\"])\n",
    "    price = float(fill.get(\"price\", 0.0))\n",
    "    pos = open_positions.get(token, {\"qty\": 0, \"side\": side, \"avg_price\": 0.0})\n",
    "    if pos[\"qty\"] == 0:\n",
    "        pos = {\"qty\": qty, \"side\": side, \"avg_price\": price}\n",
    "    else:\n",
    "        new_qty = pos[\"qty\"] + qty if side == pos[\"side\"] else pos[\"qty\"] - qty\n",
    "        if new_qty <= 0:\n",
    "            pos = {\"qty\": 0, \"side\": side, \"avg_price\": 0.0}\n",
    "        else:\n",
    "            pos = {\"qty\": new_qty, \"side\": side, \"avg_price\": (pos[\"avg_price\"]*pos[\"qty\"] + price*qty)/max(new_qty,1)}\n",
    "    open_positions[token] = pos\n",
    "\n",
    "@dataclass\n",
    "class ExitConfig:\n",
    "    dry_run: bool = True\n",
    "    target_pct: float = 0.2\n",
    "    stop_pct: float = 0.4\n",
    "    check_interval_s: float = 1.0\n",
    "\n",
    "_exit_thread = None\n",
    "_exit_stop_evt = threading.Event()\n",
    "\n",
    "def should_exit_position(token: str, row: pd.Series, pos: Dict[str, Any], cfg: ExitConfig) -> Optional[Dict[str, Any]]:\n",
    "    px = row.get(\"Mid\", np.nan)\n",
    "    if np.isnan(px):\n",
    "        px = row.get(\"Ltp\", np.nan)\n",
    "    if np.isnan(px) or pos[\"qty\"] <= 0:\n",
    "        return None\n",
    "    entry = pos[\"avg_price\"]\n",
    "    side = pos[\"side\"]\n",
    "    pnl = (px - entry) if side==\"BUY\" else (entry - px)\n",
    "    if entry <= 0:\n",
    "        return None\n",
    "    pnl_pct = pnl / entry\n",
    "    if pnl_pct >= cfg.target_pct:\n",
    "        return {\"action\":\"EXIT\",\"reason\":\"target\",\"token\":token,\"qty\":pos[\"qty\"],\"side\": \"SELL\" if side==\"BUY\" else \"BUY\"}\n",
    "    if pnl_pct <= -cfg.stop_pct:\n",
    "        return {\"action\":\"EXIT\",\"reason\":\"stop\",\"token\":token,\"qty\":pos[\"qty\"],\"side\": \"SELL\" if side==\"BUY\" else \"BUY\"}\n",
    "    return None\n",
    "\n",
    "def _exit_worker(cfg: ExitConfig):\n",
    "    while not _exit_stop_evt.is_set():\n",
    "        time.sleep(cfg.check_interval_s)\n",
    "        with _df_lock:\n",
    "            snapshot = df_feed_enriched.copy()\n",
    "        for token, pos in list(open_positions.items()):\n",
    "            if pos[\"qty\"] <= 0:\n",
    "                continue\n",
    "            row = snapshot.loc[snapshot[\"Token\"]==token]\n",
    "            if row.empty:\n",
    "                continue\n",
    "            row = row.iloc[0]\n",
    "            signal = should_exit_position(token, row, pos, cfg)\n",
    "            if signal:\n",
    "                if cfg.dry_run:\n",
    "                    print(f\"[EXIT-SIM] {signal}\")\n",
    "                else:\n",
    "                    print(f\"[EXIT-LIVE] Would place exit for {token}: {signal}\")\n",
    "                open_positions[token] = {\"qty\": 0, \"side\": pos[\"side\"], \"avg_price\": pos[\"avg_price\"]}\n",
    "\n",
    "def start_exit_manager(cfg: ExitConfig):\n",
    "    global _exit_thread, _exit_stop_evt\n",
    "    _exit_stop_evt = threading.Event()\n",
    "    _exit_thread = threading.Thread(target=_exit_worker, args=(cfg,), daemon=True)\n",
    "    _exit_thread.start()\n",
    "\n",
    "def stop_exit_manager():\n",
    "    global _exit_thread, _exit_stop_evt\n",
    "    _exit_stop_evt.set()\n",
    "    if _exit_thread is not None:\n",
    "        _exit_thread.join(timeout=5)\n",
    "\n",
    "_last_order_ts = 0.0\n",
    "\n",
    "def _to_tick(price: float, tick: float, side: str):\n",
    "    if not np.isfinite(price) or not np.isfinite(tick) or tick <= 0:\n",
    "        return float(price)\n",
    "    if side.upper() == \"BUY\":\n",
    "        return round(math.ceil(price / tick) * tick, 2)\n",
    "    else:\n",
    "        return round(math.floor(price / tick) * tick, 2)\n",
    "\n",
    "def _marketable_limit(row: pd.Series, side: str, buf_ticks: int = LIMIT_BUFFER_TICKS):\n",
    "    tick = float(row.get(\"tick_size\") or 0.05)\n",
    "    bid = float(row.get(\"BidP1\") or np.nan)\n",
    "    ask = float(row.get(\"AskP1\") or np.nan)\n",
    "    if side.upper() == \"BUY\":\n",
    "        base = ask if np.isfinite(ask) else float(row.get(\"Mid\", 0.0))\n",
    "        return _to_tick(base + buf_ticks*tick, tick, \"BUY\")\n",
    "    else:\n",
    "        base = bid if np.isfinite(bid) else float(row.get(\"Mid\", 0.0))\n",
    "        px = base - buf_ticks*tick\n",
    "        return _to_tick(px, tick, \"SELL\")\n",
    "\n",
    "def _lat_log(event: str, **kwargs):\n",
    "    ts = time.perf_counter()\n",
    "    LATENCY_LOG.append({\"t\": ts, \"event\": event, **kwargs})\n",
    "    if len(LATENCY_LOG) > LATENCY_LOG_MAX:\n",
    "        del LATENCY_LOG[: len(LATENCY_LOG) - LATENCY_LOG_MAX]\n",
    "\n",
    "def place_orders(plan: Dict[str, Any], df_enriched: pd.DataFrame, dry_run: bool = True) -> List[Dict[str, Any]]:\n",
    "    results = []\n",
    "    if not plan or \"legs\" not in plan:\n",
    "        return results\n",
    "\n",
    "    order_api = None\n",
    "    if not dry_run:\n",
    "        if not UPSDK_AVAILABLE:\n",
    "            raise RuntimeError(\"Upstox SDK not available for live orders\")\n",
    "        if not CredentialUpstox.ACCESS_TOKEN:\n",
    "            raise RuntimeError(\"ACCESS_TOKEN missing for live orders\")\n",
    "        configuration = upstox_client.Configuration()\n",
    "        configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n",
    "        api_client = upstox_client.ApiClient(configuration)\n",
    "        order_api = upstox_client.OrderApi(api_client)\n",
    "\n",
    "    global _last_order_ts\n",
    "    for leg in plan[\"legs\"]:\n",
    "        token = str(leg[\"token\"])\n",
    "        row = df_enriched.loc[df_enriched[\"Token\"]==token]\n",
    "        if row.empty:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":\"token_not_found\",\"leg\":leg})\n",
    "            continue\n",
    "        row = row.iloc[0]\n",
    "        lot = int(row.get(\"lot_size\") or 0)\n",
    "        qty = int(leg.get(\"qty\", 0))\n",
    "        if lot and qty % lot != 0:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":f\"qty_not_multiple_of_lot({lot})\",\"leg\":leg}); continue\n",
    "        if qty <= 0 or qty > MAX_QTY_PER_LEG:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":\"qty_bounds\",\"leg\":leg}); continue\n",
    "\n",
    "        side = leg[\"side\"].upper()\n",
    "        product_code = PRODUCT_MAP.get(leg.get(\"product\", DEFAULT_PRODUCT), PRODUCT_MAP[DEFAULT_PRODUCT])\n",
    "\n",
    "        order_type = leg.get(\"order_type\",\"MARKET\").upper()\n",
    "        px = None\n",
    "        if USE_MARKETABLE_LIMITS:\n",
    "            px = _marketable_limit(row, side)\n",
    "            order_type = \"LIMIT\"\n",
    "        else:\n",
    "            px = float(leg.get(\"price\") or 0.0)\n",
    "\n",
    "        now = time.perf_counter()\n",
    "        delay_ms = ORDER_MIN_GAP_MS - (now - _last_order_ts) * 1000.0\n",
    "        if delay_ms > 0:\n",
    "            time.sleep(delay_ms / 1000.0)\n",
    "        _last_order_ts = time.perf_counter()\n",
    "\n",
    "        _lat_log(\"order_send\", token=token, side=side, qty=qty, px=px, order_type=order_type)\n",
    "        if dry_run:\n",
    "            fill = float(row.get(\"Mid\")) if np.isfinite(row.get(\"Mid\", np.nan)) else float(row.get(\"Ltp\", 0.0))\n",
    "            results.append({\"status\":\"simulated\",\"token\":token,\"qty\":qty,\"side\":side,\"product\":product_code,\"order_type\":order_type,\"limit_price\":px,\"fill_price\":fill})\n",
    "            record_fill({\"token\": token, \"side\": side, \"qty\": qty, \"price\": fill})\n",
    "            _lat_log(\"order_ack\", token=token)\n",
    "        else:\n",
    "            req = upstox_client.PlaceOrderRequest(\n",
    "                quantity=str(qty),\n",
    "                product=product_code,\n",
    "                validity=\"DAY\",\n",
    "                price=float(px) if order_type==\"LIMIT\" else 0.0,\n",
    "                tag=\"LLM-STRATEGY\",\n",
    "                instrument_token=token,\n",
    "                order_type=order_type,\n",
    "                transaction_type=side,\n",
    "                disclosed_quantity=0,\n",
    "                trigger_price=0.0,\n",
    "                is_amo=False\n",
    "            )\n",
    "            resp = order_api.place_order(body=req, api_version=\"3.0\")\n",
    "            results.append({\"status\":\"placed\",\"order_id\":resp.data.order_id,\"token\":token,\"qty\":qty,\"side\":side,\"limit_price\":px})\n",
    "            record_fill({\"token\": token, \"side\": side, \"qty\": qty, \"price\": float(row.get(\"Mid\") or row.get(\"Ltp\") or 0.0)})\n",
    "            _lat_log(\"order_ack\", token=token)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b13812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Orchestration (live-first) ----\n",
    "if SIMULATION_MODE:\n",
    "    raise RuntimeError(\"This notebook is live-first. Set SIMULATION_MODE=False to proceed.\")\n",
    "\n",
    "tokens_with_spot = list(dict.fromkeys(token_list + [UNDERLYING_SPOT_TOKEN]))\n",
    "streamer = start_live_stream(tokens_with_spot, mode=WEBSOCKET_MODE)\n",
    "\n",
    "time.sleep(3.0)\n",
    "\n",
    "with _df_lock:\n",
    "    snapshot = df_feed_enriched.copy()\n",
    "print(\"Feed snapshot rows:\", len(snapshot))\n",
    "display(snapshot.tail(6))\n",
    "\n",
    "LATENCY_LOG.clear()\n",
    "def _lat_log(event: str, **kwargs):\n",
    "    ts = time.perf_counter()\n",
    "    LATENCY_LOG.append({\"t\": ts, \"event\": event, **kwargs})\n",
    "    if len(LATENCY_LOG) > LATENCY_LOG_MAX:\n",
    "        del LATENCY_LOG[: len(LATENCY_LOG) - LATENCY_LOG_MAX]\n",
    "\n",
    "_lat_log(\"decision_start\", rows=len(snapshot))\n",
    "plan = ask_llm_for_strategy(snapshot, use_mock=True)  # scoring via router; USE_LLM gate applied inside\n",
    "_lat_log(\"decision_end\", legs=len(plan.get(\"legs\", [])))\n",
    "\n",
    "try:\n",
    "    _lat_log(\"validate_start\")\n",
    "    validated = validate_strategy(plan, snapshot)\n",
    "    _lat_log(\"validate_end\", ok=True)\n",
    "except Exception as e:\n",
    "    validated = None\n",
    "    _lat_log(\"validate_end\", ok=False, err=str(e))\n",
    "    print(\"Validation failed:\", e)\n",
    "\n",
    "orders = []\n",
    "if validated:\n",
    "    _lat_log(\"place_start\", nlegs=len(validated[\"legs\"]))\n",
    "    orders = place_orders(validated, snapshot, dry_run=(not ORDERS_LIVE))\n",
    "    _lat_log(\"place_end\", norders=len(orders))\n",
    "    print(\"Order results:\")\n",
    "    print(json.dumps(orders, indent=2))\n",
    "\n",
    "cfg = ExitConfig(dry_run=(not EXIT_MANAGER_LIVE))\n",
    "start_exit_manager(cfg)\n",
    "\n",
    "_recenter_thread = threading.Thread(target=recenter_daemon, daemon=True)\n",
    "_recenter_thread.start()\n",
    "\n",
    "print(\"Live scalper pipeline running. Use the Stop cell to close sockets and exit manager.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Monitor + diagnostics + router summary ----\n",
    "with _df_lock:\n",
    "    mon = df_feed_enriched.copy()\n",
    "display(mon.tail(12))\n",
    "\n",
    "if not mon.empty:\n",
    "    mon[\"dist\"] = (mon[\"Mid\"] - mon[\"strike_price\"]).abs()\n",
    "    picks = mon.sort_values([\"dist\"]).groupby(\"instrument_type\").head(2)\n",
    "    rows = []\n",
    "    for _, r in picks.iterrows():\n",
    "        ok_sell, why_sell, ex = eligible_entry(r, side=\"SELL\")\n",
    "        rows.append({\n",
    "            \"tsym\": r.get(\"trading_symbol\",\"\"),\n",
    "            \"type\": r.get(\"instrument_type\",\"\"),\n",
    "            \"mid\": r.get(\"Mid\"),\n",
    "            \"spread\": r.get(\"Spread\"),\n",
    "            \"depthImb\": r.get(\"DepthImb\"),\n",
    "            \"delta\": r.get(\"Delta\"),\n",
    "            \"iv\": r.get(\"Iv\"),\n",
    "            \"ok_sell\": ok_sell,\n",
    "            \"why_sell\": why_sell,\n",
    "            \"iv_z\": ex.get(\"iv_z\")\n",
    "        })\n",
    "    df_check = pd.DataFrame(rows)\n",
    "    display(df_check)\n",
    "else:\n",
    "    print(\"No feed yet.\")\n",
    "\n",
    "# Router summary (agreement & latency)\n",
    "df_router, summary = router_report(200)\n",
    "display(df_router.tail(10))\n",
    "print(\"Router summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbea5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Latency report & cleanup ----\n",
    "def latency_report(n_tail: int = 50) -> pd.DataFrame:\n",
    "    df = pd.DataFrame(LATENCY_LOG[-n_tail:])\n",
    "    return df\n",
    "\n",
    "display(latency_report(30))\n",
    "\n",
    "# Stop streaming & exit manager\n",
    "stop_exit_manager()\n",
    "stop_live_stream()\n",
    "print(\"Shutdown requested.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
