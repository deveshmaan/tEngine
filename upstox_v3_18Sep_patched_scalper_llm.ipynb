{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4d0ed2",
   "metadata": {},
   "source": [
    "\n",
    "# `upstox_v3_18Sep_patched_scalper_llm.ipynb` — NIFTY Intraday Scalper (Spot‑Anchored + Greeks + Recenter + Latency + **LLM Scoring**)\n",
    "\n",
    "**What’s new here**  \n",
    "A **plug‑and‑play LLM scoring cell** that works with either:\n",
    "- A **generic HTTP** scorer endpoint returning `{\"score\": float}`\n",
    "- A **local Ollama** server (e.g., `ollama run mistral`) via `http://127.0.0.1:11434/api/generate`\n",
    "\n",
    "The rest is the same scalper pipeline: spot‑anchored ATM, Greeks ingestion, microstructure features, IV z‑score gating, marketable limits, throttle, latency logging, dynamic recentering, strict validation, dry‑run orders by default, and exit manager.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf4cbd9",
   "metadata": {},
   "source": [
    "\n",
    "## Requirements & safety\n",
    "\n",
    "- Python 3.9+; packages: `pandas`, `numpy`, `upstox-python-sdk` (or `upstox_client`), `IPython`\n",
    "- Optional: `requests` (for LLM HTTP/Ollama calls)\n",
    "- Token: `export UPSTOX_ACCESS_TOKEN=...` or paste into `CredentialUpstox.ACCESS_TOKEN`\n",
    "\n",
    "**Safety defaults**\n",
    "- `SIMULATION_MODE = False` (live-first)\n",
    "- `ORDERS_LIVE = False` (dry‑run orders)\n",
    "- `EXIT_MANAGER_LIVE = False` (simulated exits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f216905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Imports & global config ----\n",
    "import os, json, time, threading, math, traceback\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "# Upstox SDK\n",
    "try:\n",
    "    import upstox_client\n",
    "    from upstox_client.rest import ApiException\n",
    "    UPSDK_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    UPSDK_AVAILABLE = False\n",
    "    print(\"Upstox SDK not available. Install it to run live streaming and orders.\")\n",
    "    print(\"Example: pip install upstox-python-sdk   # confirm exact name per Upstox docs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac17f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Toggles & constants ----\n",
    "SIMULATION_MODE = False       # Live-first\n",
    "USE_LLM = True                # Use LLM scorer (Ollama or HTTP); set False to bypass\n",
    "ORDERS_LIVE = False           # Default to dry-run\n",
    "EXIT_MANAGER_LIVE = False     # Simulated exits\n",
    "\n",
    "UNDERLYING = \"NIFTY\"\n",
    "UNDERLYING_SPOT_TOKEN = \"NSE_INDEX|Nifty 50\"\n",
    "SPAN_STRIKES = 2              # ATM ± 2 (5 strikes)\n",
    "WEBSOCKET_MODE = \"full_d30\"\n",
    "IST = \"Asia/Kolkata\"\n",
    "\n",
    "# Strike steps\n",
    "STRIKE_STEP = {\"NIFTY\": 50, \"BANKNIFTY\": 100, \"FINNIFTY\": 50}\n",
    "\n",
    "# Risk limits\n",
    "MAX_QTY_PER_LEG = 300\n",
    "MAX_OPEN_LEGS = 6\n",
    "\n",
    "# Recenter parameters\n",
    "RECENTER_COOLDOWN_S = 60.0\n",
    "RECENTER_LOG = True\n",
    "\n",
    "# === Trade gates & execution params (scalping) ===\n",
    "# Greeks filter\n",
    "DELTA_MIN, DELTA_MAX = 0.45, 0.55           # abs(Delta) in [0.45, 0.55]\n",
    "SPREAD_MAX = 0.20                            # rupees\n",
    "DEPTH_IMB_MIN = 0.15                         # direction-of-entry bias\n",
    "IV_Z_MAX = 2.0                               # skip entries if |z_IV| > 2\n",
    "IV_Z_MIN_COUNT = 30                          # warm-up samples before gating IV\n",
    "\n",
    "# Execution (marketable limit orders)\n",
    "USE_MARKETABLE_LIMITS = True\n",
    "LIMIT_BUFFER_TICKS = 1                       # 1 tick beyond BBO to ensure fill while capping slippage\n",
    "\n",
    "# Throttle (burst control)\n",
    "ORDER_MIN_GAP_MS = 200                       # min time between order sends\n",
    "\n",
    "# === LLM Scoring ===\n",
    "# Option A: generic HTTP endpoint that accepts context JSON and returns {\"score\": float}\n",
    "LLM_ENDPOINT = os.getenv(\"LLM_ENDPOINT\", \"\") # e.g., http://127.0.0.1:8000/score\n",
    "LLM_TIMEOUT_S = float(os.getenv(\"LLM_TIMEOUT_S\", \"0.12\"))  # modest budget\n",
    "\n",
    "# Option B: local Ollama (if OLLAMA_MODEL is set, we call it directly)\n",
    "OLLAMA_HOST = os.getenv(\"OLLAMA_HOST\", \"http://127.0.0.1:11434\")\n",
    "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"\")  # e.g., \"mistral\", \"llama3:8b-instruct\"\n",
    "OLLAMA_TIMEOUT_S = float(os.getenv(\"OLLAMA_TIMEOUT_S\", \"0.20\"))\n",
    "OLLAMA_NUM_PREDICT = int(os.getenv(\"OLLAMA_NUM_PREDICT\", \"16\"))\n",
    "\n",
    "LLM_SCORE_THRESHOLD = 0.55                   # require modest confirmation to trade\n",
    "\n",
    "# Latency logging\n",
    "LATENCY_LOG = []\n",
    "LATENCY_LOG_MAX = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a489fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Credentials & product mapping ----\n",
    "class CredentialUpstox:\n",
    "    ACCESS_TOKEN = os.getenv(\"UPSTOX_ACCESS_TOKEN\", \"\")  # paste here if not using env\n",
    "\n",
    "PRODUCT_MAP = {\n",
    "    \"MIS\": \"I\",   # Intraday\n",
    "    \"NRML\": \"D\",  # Carry/Delivery\n",
    "}\n",
    "DEFAULT_PRODUCT = \"MIS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32d3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Utilities ----\n",
    "def to_ist_ms(ms) -> pd.Timestamp:\n",
    "    try:\n",
    "        return pd.to_datetime(int(ms), unit=\"ms\", utc=True).tz_convert(IST)\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def resolve_next_listed_expiry(df_instruments: pd.DataFrame, underlying: str, today=None) -> str:\n",
    "    t = pd.Timestamp.now(IST).normalize() if today is None else pd.Timestamp(today, tz=IST).normalize()\n",
    "    dfx = df_instruments[\n",
    "        (df_instruments[\"segment\"] == \"NSE_FO\") &\n",
    "        (df_instruments[\"name\"].str.upper() == underlying.upper()) &\n",
    "        (df_instruments[\"instrument_type\"].isin([\"CE\",\"PE\"]))\n",
    "    ].copy()\n",
    "    if dfx.empty:\n",
    "        raise ValueError(f\"No derivatives found for {underlying} in instruments master\")\n",
    "    dfx[\"_exp\"] = pd.to_datetime(dfx[\"expiry\"], errors=\"coerce\")\n",
    "    dfx = dfx[dfx[\"_exp\"] >= t.tz_localize(None)]\n",
    "    if dfx.empty:\n",
    "        raise ValueError(f\"No upcoming expiry >= {t.date()} for {underlying}\")\n",
    "    return dfx[\"_exp\"].min().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def nearest_strikes_from_spot(spot_ltp: float, underlying: str, span: int = 2) -> List[int]:\n",
    "    step = STRIKE_STEP.get(underlying.upper(), 50)\n",
    "    nearest = int(step * math.floor((spot_ltp + step/2) / step))\n",
    "    return [nearest + i * step for i in range(-span, span+1)]\n",
    "\n",
    "def get_upstox_quote_client():\n",
    "    if not UPSDK_AVAILABLE:\n",
    "        raise RuntimeError(\"Upstox SDK is not available.\")\n",
    "    if not CredentialUpstox.ACCESS_TOKEN:\n",
    "        raise RuntimeError(\"ACCESS_TOKEN missing. Set UPSTOX_ACCESS_TOKEN or paste in CredentialUpstox.\")\n",
    "    configuration = upstox_client.Configuration()\n",
    "    configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n",
    "    return upstox_client.MarketQuoteV3Api(upstox_client.ApiClient(configuration))\n",
    "\n",
    "def _extract_ltp_from_entry(entry: dict) -> float:\n",
    "    if not isinstance(entry, dict):\n",
    "        raise KeyError(\"Invalid LTP entry\")\n",
    "    for k in (\"ltp\", \"last_price\", \"last_traded_price\", \"last\", \"close\"):\n",
    "        if k in entry and entry[k] is not None:\n",
    "            return float(entry[k])\n",
    "    if \"ltpc\" in entry and isinstance(entry[\"ltpc\"], dict) and \"ltp\" in entry[\"ltpc\"]:\n",
    "        return float(entry[\"ltpc\"][\"ltp\"])\n",
    "    raise KeyError(f\"No LTP field found in entry keys={list(entry.keys())}\")\n",
    "\n",
    "def get_index_spot_ltp(instrument_key: str = None) -> float:\n",
    "    instrument_key = instrument_key or UNDERLYING_SPOT_TOKEN\n",
    "    api = get_upstox_quote_client()\n",
    "    try:\n",
    "        api_response = api.get_ltp(instrument_key=[instrument_key])\n",
    "        data_dict = api_response.to_dict() if hasattr(api_response, \"to_dict\") else dict(api_response)\n",
    "        data = data_dict.get(\"data\", {})\n",
    "        entry = data.get(instrument_key) or (next(iter(data.values())) if data else {})\n",
    "        ltp = _extract_ltp_from_entry(entry)\n",
    "        if not np.isfinite(ltp):\n",
    "            raise RuntimeError(f\"LTP non-finite: {ltp}\")\n",
    "        return float(ltp)\n",
    "    except ApiException as e:\n",
    "        raise RuntimeError(f\"Upstox get_ltp ApiException: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650b4d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekly</th>\n",
       "      <th>segment</th>\n",
       "      <th>name</th>\n",
       "      <th>exchange</th>\n",
       "      <th>expiry</th>\n",
       "      <th>instrument_type</th>\n",
       "      <th>asset_symbol</th>\n",
       "      <th>underlying_symbol</th>\n",
       "      <th>instrument_key</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>freeze_quantity</th>\n",
       "      <th>exchange_token</th>\n",
       "      <th>minimum_lot</th>\n",
       "      <th>tick_size</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>underlying_type</th>\n",
       "      <th>trading_symbol</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>qty_multiplier</th>\n",
       "      <th>isin</th>\n",
       "      <th>security_type</th>\n",
       "      <th>short_name</th>\n",
       "      <th>asset_key</th>\n",
       "      <th>underlying_key</th>\n",
       "      <th>last_trading_date</th>\n",
       "      <th>price_quote_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NCD_FO</td>\n",
       "      <td>JPYINR</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2026-03-27</td>\n",
       "      <td>CE</td>\n",
       "      <td>JPYINR</td>\n",
       "      <td>JPYINR</td>\n",
       "      <td>NCD_FO|14294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>14294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>CUR</td>\n",
       "      <td>CUR</td>\n",
       "      <td>JPYINR 61 CE 27 MAR 26</td>\n",
       "      <td>61.00</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NCD_FO</td>\n",
       "      <td>JPYINR</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2026-03-27</td>\n",
       "      <td>PE</td>\n",
       "      <td>JPYINR</td>\n",
       "      <td>JPYINR</td>\n",
       "      <td>NCD_FO|14295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>14295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>CUR</td>\n",
       "      <td>CUR</td>\n",
       "      <td>JPYINR 61 PE 27 MAR 26</td>\n",
       "      <td>61.00</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_EQ</td>\n",
       "      <td>SDL RJ 7.49% 2035</td>\n",
       "      <td>NSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_EQ|IN2920250163</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>758718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>749RJ35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IN2920250163</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_EQ</td>\n",
       "      <td>SDL RJ 7.57% 2043</td>\n",
       "      <td>NSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_EQ|IN2920250171</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>758723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>757RJ43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IN2920250171</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NCD_FO</td>\n",
       "      <td>GBPINR</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-12-29</td>\n",
       "      <td>PE</td>\n",
       "      <td>GBPINR</td>\n",
       "      <td>GBPINR</td>\n",
       "      <td>NCD_FO|14277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>14277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>CUR</td>\n",
       "      <td>CUR</td>\n",
       "      <td>GBPINR 118.25 PE 29 DEC 25</td>\n",
       "      <td>118.25</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NCD_FO</td>\n",
       "      <td>GBPINR</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-12-29</td>\n",
       "      <td>CE</td>\n",
       "      <td>GBPINR</td>\n",
       "      <td>GBPINR</td>\n",
       "      <td>NCD_FO|14274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>14274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>CUR</td>\n",
       "      <td>CUR</td>\n",
       "      <td>GBPINR 118 CE 29 DEC 25</td>\n",
       "      <td>118.00</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekly segment               name exchange      expiry instrument_type asset_symbol underlying_symbol       instrument_key  lot_size  freeze_quantity  \\\n",
       "0     0.0  NCD_FO             JPYINR      NSE  2026-03-27              CE       JPYINR            JPYINR         NCD_FO|14294       1.0          10000.0   \n",
       "1     0.0  NCD_FO             JPYINR      NSE  2026-03-27              PE       JPYINR            JPYINR         NCD_FO|14295       1.0          10000.0   \n",
       "2     NaN  NSE_EQ  SDL RJ 7.49% 2035      NSE         NaN              SG          NaN               NaN  NSE_EQ|IN2920250163     100.0         100000.0   \n",
       "3     NaN  NSE_EQ  SDL RJ 7.57% 2043      NSE         NaN              SG          NaN               NaN  NSE_EQ|IN2920250171     100.0         100000.0   \n",
       "4     0.0  NCD_FO             GBPINR      NSE  2025-12-29              PE       GBPINR            GBPINR         NCD_FO|14277       1.0          10000.0   \n",
       "5     0.0  NCD_FO             GBPINR      NSE  2025-12-29              CE       GBPINR            GBPINR         NCD_FO|14274       1.0          10000.0   \n",
       "\n",
       "   exchange_token  minimum_lot  tick_size asset_type underlying_type              trading_symbol  strike_price  qty_multiplier          isin security_type  \\\n",
       "0           14294          1.0       0.25        CUR             CUR      JPYINR 61 CE 27 MAR 26         61.00          1000.0           NaN           NaN   \n",
       "1           14295          1.0       0.25        CUR             CUR      JPYINR 61 PE 27 MAR 26         61.00          1000.0           NaN           NaN   \n",
       "2          758718          NaN       1.00        NaN             NaN                     749RJ35           NaN             1.0  IN2920250163        NORMAL   \n",
       "3          758723          NaN       1.00        NaN             NaN                     757RJ43           NaN             1.0  IN2920250171        NORMAL   \n",
       "4           14277          1.0       0.25        CUR             CUR  GBPINR 118.25 PE 29 DEC 25        118.25          1000.0           NaN           NaN   \n",
       "5           14274          1.0       0.25        CUR             CUR     GBPINR 118 CE 29 DEC 25        118.00          1000.0           NaN           NaN   \n",
       "\n",
       "  short_name asset_key underlying_key  last_trading_date price_quote_unit  \n",
       "0        NaN       NaN            NaN                NaN              NaN  \n",
       "1        NaN       NaN            NaN                NaN              NaN  \n",
       "2        NaN       NaN            NaN                NaN              NaN  \n",
       "3        NaN       NaN            NaN                NaN              NaN  \n",
       "4        NaN       NaN            NaN                NaN              NaN  \n",
       "5        NaN       NaN            NaN                NaN              NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ---- Load instruments master (live) ----\n",
    "def load_instruments_live() -> pd.DataFrame:\n",
    "    url = \"https://assets.upstox.com/market-quote/instruments/exchange/NSE.json.gz\"\n",
    "    try:\n",
    "        df = pd.read_json(url)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load instruments from {url}: {e}\")\n",
    "    # Normalize\n",
    "    if \"expiry\" in df:\n",
    "        exp = pd.to_datetime(df[\"expiry\"], unit=\"ms\", errors=\"coerce\")\n",
    "        mask = exp.isna() & df[\"expiry\"].notna()\n",
    "        if mask.any():\n",
    "            exp2 = pd.to_datetime(df.loc[mask, \"expiry\"], errors=\"coerce\")\n",
    "            exp.loc[mask] = exp2\n",
    "        df[\"expiry\"] = exp.dt.strftime(\"%Y-%m-%d\")\n",
    "    for col in (\"strike_price\",\"lot_size\",\"tick_size\",\"minimum_lot\"):\n",
    "        if col in df:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "df_futureOptions = load_instruments_live()\n",
    "assert not df_futureOptions.empty, \"Instruments master is empty\"\n",
    "display(df_futureOptions.head(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d98f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain size for NIFTY expiry 2025-09-23: 180 rows\n",
      "Spot LTP lookup failed; falling back to chain median. Reason: Upstox get_ltp ApiException: (400)\n",
      "Reason: Bad Request\n",
      "HTTP response headers: HTTPHeaderDict({'Date': 'Fri, 19 Sep 2025 09:31:36 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'CF-RAY': '981812320b2d25cd-DEL', 'reqid': '972a0e73-bc4f-4dee-ae59-3fe91b538fb5', 'vary': 'Origin, Access-Control-Request-Method, Access-Control-Request-Headers', 'message': 'request failed', 'requestid': '0683d623-2b0e-4794-9b0f-fa9b743f2fa3', 'x-content-type-options': 'nosniff', 'x-xss-protection': '0', 'Cache-Control': 'no-cache, no-store, max-age=0, must-revalidate', 'pragma': 'no-cache', 'expires': '0', 'strict-transport-security': 'max-age=0; includeSubDomains', 'x-frame-options': 'DENY', 'cf-cache-status': 'DYNAMIC', 'Set-Cookie': '__cf_bm=sv7I034E2HzDnYesDqJjtUAWCYMio003C.IOh9Gdk38-1758274296-1.0.1.1-kRt6iIWFazKiqBwM8YpHHX4E_zh4zak1pYSnVSxqUSwjnFHgBDyZy.9RdyvwM9mu; path=/; expires=Fri, 19-Sep-25 10:01:36 GMT; domain=.upstox.com; HttpOnly; Secure; SameSite=None, _cfuvid=MJP68y6obto8Bl.HOD3mqiXBENGUNhkR6Z95qFBIUx0-1758274296688-0.0.1.1-604800000; path=/; domain=.upstox.com; HttpOnly; Secure; SameSite=None', 'Server': 'cloudflare', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "HTTP response body: b'{\"status\":\"error\",\"errors\":[{\"errorCode\":\"UDAPI1087\",\"message\":\"One of either symbol or instrument_key is invalid.\",\"propertyPath\":null,\"invalidValue\":null,\"error_code\":\"UDAPI1087\",\"property_path\":null,\"invalid_value\":null}]}'\n",
      "\n",
      "Selected strikes from spot 24925.00: [24850, 24900, 24950, 25000, 25050]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekly</th>\n",
       "      <th>segment</th>\n",
       "      <th>name</th>\n",
       "      <th>exchange</th>\n",
       "      <th>expiry</th>\n",
       "      <th>instrument_type</th>\n",
       "      <th>asset_symbol</th>\n",
       "      <th>underlying_symbol</th>\n",
       "      <th>instrument_key</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>freeze_quantity</th>\n",
       "      <th>exchange_token</th>\n",
       "      <th>minimum_lot</th>\n",
       "      <th>tick_size</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>underlying_type</th>\n",
       "      <th>trading_symbol</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>qty_multiplier</th>\n",
       "      <th>isin</th>\n",
       "      <th>security_type</th>\n",
       "      <th>short_name</th>\n",
       "      <th>asset_key</th>\n",
       "      <th>underlying_key</th>\n",
       "      <th>last_trading_date</th>\n",
       "      <th>price_quote_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16851</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NSE_FO</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>CE</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE_FO|47711</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>47711</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>NIFTY 24850 CE 23 SEP 25</td>\n",
       "      <td>24850.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NSE_FO</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>PE</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE_FO|47712</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>47712</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>NIFTY 24850 PE 23 SEP 25</td>\n",
       "      <td>24850.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NSE_FO</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>CE</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE_FO|47717</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>47717</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>NIFTY 24900 CE 23 SEP 25</td>\n",
       "      <td>24900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NSE_FO</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>PE</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE_FO|47718</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>47718</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>NIFTY 24900 PE 23 SEP 25</td>\n",
       "      <td>24900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16844</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NSE_FO</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>CE</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE_FO|47723</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>47723</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>NIFTY 24950 CE 23 SEP 25</td>\n",
       "      <td>24950.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NSE_FO</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>PE</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE_FO|47724</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>47724</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>NIFTY 24950 PE 23 SEP 25</td>\n",
       "      <td>24950.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16876</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NSE_FO</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>CE</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE_FO|47733</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>47733</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>NIFTY 25000 CE 23 SEP 25</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16875</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NSE_FO</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>PE</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE_FO|47734</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>47734</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>NIFTY 25000 PE 23 SEP 25</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16865</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NSE_FO</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>CE</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE_FO|47751</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>47751</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>NIFTY 25050 CE 23 SEP 25</td>\n",
       "      <td>25050.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16864</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NSE_FO</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>PE</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NIFTY</td>\n",
       "      <td>NSE_FO|47752</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>47752</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>NIFTY 25050 PE 23 SEP 25</td>\n",
       "      <td>25050.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NSE_INDEX|Nifty 50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weekly segment   name exchange      expiry instrument_type asset_symbol underlying_symbol instrument_key  lot_size  freeze_quantity  exchange_token  \\\n",
       "16851     1.0  NSE_FO  NIFTY      NSE  2025-09-23              CE        NIFTY             NIFTY   NSE_FO|47711      75.0           1800.0           47711   \n",
       "16850     1.0  NSE_FO  NIFTY      NSE  2025-09-23              PE        NIFTY             NIFTY   NSE_FO|47712      75.0           1800.0           47712   \n",
       "16849     1.0  NSE_FO  NIFTY      NSE  2025-09-23              CE        NIFTY             NIFTY   NSE_FO|47717      75.0           1800.0           47717   \n",
       "16848     1.0  NSE_FO  NIFTY      NSE  2025-09-23              PE        NIFTY             NIFTY   NSE_FO|47718      75.0           1800.0           47718   \n",
       "16844     1.0  NSE_FO  NIFTY      NSE  2025-09-23              CE        NIFTY             NIFTY   NSE_FO|47723      75.0           1800.0           47723   \n",
       "16847     1.0  NSE_FO  NIFTY      NSE  2025-09-23              PE        NIFTY             NIFTY   NSE_FO|47724      75.0           1800.0           47724   \n",
       "16876     1.0  NSE_FO  NIFTY      NSE  2025-09-23              CE        NIFTY             NIFTY   NSE_FO|47733      75.0           1800.0           47733   \n",
       "16875     1.0  NSE_FO  NIFTY      NSE  2025-09-23              PE        NIFTY             NIFTY   NSE_FO|47734      75.0           1800.0           47734   \n",
       "16865     1.0  NSE_FO  NIFTY      NSE  2025-09-23              CE        NIFTY             NIFTY   NSE_FO|47751      75.0           1800.0           47751   \n",
       "16864     1.0  NSE_FO  NIFTY      NSE  2025-09-23              PE        NIFTY             NIFTY   NSE_FO|47752      75.0           1800.0           47752   \n",
       "\n",
       "       minimum_lot  tick_size asset_type underlying_type            trading_symbol  strike_price  qty_multiplier isin security_type short_name  \\\n",
       "16851         75.0        5.0      INDEX           INDEX  NIFTY 24850 CE 23 SEP 25       24850.0             1.0  NaN           NaN        NaN   \n",
       "16850         75.0        5.0      INDEX           INDEX  NIFTY 24850 PE 23 SEP 25       24850.0             1.0  NaN           NaN        NaN   \n",
       "16849         75.0        5.0      INDEX           INDEX  NIFTY 24900 CE 23 SEP 25       24900.0             1.0  NaN           NaN        NaN   \n",
       "16848         75.0        5.0      INDEX           INDEX  NIFTY 24900 PE 23 SEP 25       24900.0             1.0  NaN           NaN        NaN   \n",
       "16844         75.0        5.0      INDEX           INDEX  NIFTY 24950 CE 23 SEP 25       24950.0             1.0  NaN           NaN        NaN   \n",
       "16847         75.0        5.0      INDEX           INDEX  NIFTY 24950 PE 23 SEP 25       24950.0             1.0  NaN           NaN        NaN   \n",
       "16876         75.0        5.0      INDEX           INDEX  NIFTY 25000 CE 23 SEP 25       25000.0             1.0  NaN           NaN        NaN   \n",
       "16875         75.0        5.0      INDEX           INDEX  NIFTY 25000 PE 23 SEP 25       25000.0             1.0  NaN           NaN        NaN   \n",
       "16865         75.0        5.0      INDEX           INDEX  NIFTY 25050 CE 23 SEP 25       25050.0             1.0  NaN           NaN        NaN   \n",
       "16864         75.0        5.0      INDEX           INDEX  NIFTY 25050 PE 23 SEP 25       25050.0             1.0  NaN           NaN        NaN   \n",
       "\n",
       "                asset_key      underlying_key  last_trading_date price_quote_unit  \n",
       "16851  NSE_INDEX|Nifty 50  NSE_INDEX|Nifty 50                NaN              NaN  \n",
       "16850  NSE_INDEX|Nifty 50  NSE_INDEX|Nifty 50                NaN              NaN  \n",
       "16849  NSE_INDEX|Nifty 50  NSE_INDEX|Nifty 50                NaN              NaN  \n",
       "16848  NSE_INDEX|Nifty 50  NSE_INDEX|Nifty 50                NaN              NaN  \n",
       "16844  NSE_INDEX|Nifty 50  NSE_INDEX|Nifty 50                NaN              NaN  \n",
       "16847  NSE_INDEX|Nifty 50  NSE_INDEX|Nifty 50                NaN              NaN  \n",
       "16876  NSE_INDEX|Nifty 50  NSE_INDEX|Nifty 50                NaN              NaN  \n",
       "16875  NSE_INDEX|Nifty 50  NSE_INDEX|Nifty 50                NaN              NaN  \n",
       "16865  NSE_INDEX|Nifty 50  NSE_INDEX|Nifty 50                NaN              NaN  \n",
       "16864  NSE_INDEX|Nifty 50  NSE_INDEX|Nifty 50                NaN              NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ---- Build current chain & anchor ATM via spot ----\n",
    "expiry_target = resolve_next_listed_expiry(df_futureOptions, UNDERLYING)\n",
    "df_chain = df_futureOptions[\n",
    "    (df_futureOptions[\"segment\"] == \"NSE_FO\") &\n",
    "    (df_futureOptions[\"name\"].str.upper() == UNDERLYING.upper()) &\n",
    "    (df_futureOptions[\"instrument_type\"].isin([\"CE\",\"PE\"])) &\n",
    "    (df_futureOptions[\"expiry\"] == expiry_target)\n",
    "].copy()\n",
    "assert not df_chain.empty, f\"No options found for {UNDERLYING} expiry={expiry_target}\"\n",
    "print(f\"Chain size for {UNDERLYING} expiry {expiry_target}: {len(df_chain)} rows\")\n",
    "\n",
    "# Anchor ATM from live spot LTP (REST) with fallback\n",
    "try:\n",
    "    spot_ltp_initial = get_index_spot_ltp(UNDERLYING_SPOT_TOKEN)\n",
    "    print(f\"NIFTY 50 spot LTP: {spot_ltp_initial:.2f}\")\n",
    "except Exception as e:\n",
    "    print(\"Spot LTP lookup failed; falling back to chain median. Reason:\", e)\n",
    "    spot_ltp_initial = float(df_chain[\"strike_price\"].median())\n",
    "\n",
    "strike_list = nearest_strikes_from_spot(spot_ltp_initial, UNDERLYING, span=SPAN_STRIKES)\n",
    "df_chain_sel = df_chain[df_chain[\"strike_price\"].isin(strike_list)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "token_list = df_chain_sel[\"instrument_key\"].dropna().astype(str).unique().tolist()\n",
    "assert token_list, \"No tokens to subscribe after ATM filtering\"\n",
    "\n",
    "print(f\"Selected strikes from spot {spot_ltp_initial:.2f}: {sorted(set(strike_list))}\")\n",
    "display(df_chain_sel.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ac121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Feed structures, enrichment, IV stats ----\n",
    "df_feed = pd.DataFrame(columns=[\n",
    "    \"Token\",\"Ltp\",\"Ltq\",\"Cp\",\n",
    "    \"BidP1\",\"BidQ1\",\"AskP1\",\"AskQ1\",\n",
    "    \"Ltt\",\"Oi\",\"Iv\",\"Atp\",\"Tbq\",\"Tsq\",\n",
    "    \"Delta\",\"Theta\",\"Gamma\",\"Vega\",\"Rho\"\n",
    "])\n",
    "df_feed_enriched = pd.DataFrame()\n",
    "\n",
    "_df_lock = threading.Lock()\n",
    "\n",
    "def enrich_feed(_df_feed: pd.DataFrame, _df_meta: pd.DataFrame, cols_to_add=None) -> pd.DataFrame:\n",
    "    if cols_to_add is None:\n",
    "        cols_to_add = [\"lot_size\",\"trading_symbol\",\"strike_price\",\"tick_size\",\"instrument_type\",\"expiry\",\"name\"]\n",
    "    left = _df_feed.copy()\n",
    "    right = _df_meta[[\"instrument_key\"] + [c for c in cols_to_add if c in _df_meta.columns]].drop_duplicates(\"instrument_key\")\n",
    "    out = left.merge(right, left_on=\"Token\", right_on=\"instrument_key\", how=\"left\", validate=\"m:1\")\n",
    "    out[\"Mid\"] = np.where(out[\"BidP1\"].notna() & out[\"AskP1\"].notna(), (out[\"BidP1\"] + out[\"AskP1\"])/2.0, out[\"Ltp\"])\n",
    "    out[\"Spread\"] = np.where(out[\"BidP1\"].notna() & out[\"AskP1\"].notna(), (out[\"AskP1\"] - out[\"BidP1\"]), np.nan)\n",
    "    out[\"DepthImb\"] = np.where(\n",
    "        (out[\"BidQ1\"].notna() & out[\"AskQ1\"].notna() & ((out[\"BidQ1\"] + out[\"AskQ1\"]) > 0)),\n",
    "        (out[\"BidQ1\"] - out[\"AskQ1\"]) / (out[\"BidQ1\"] + out[\"AskQ1\"]),\n",
    "        np.nan,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# Online IV z-score stats (per token)\n",
    "from collections import defaultdict\n",
    "_iv_stats = defaultdict(lambda: {\"n\":0, \"mean\":0.0, \"M2\":0.0})\n",
    "\n",
    "def update_iv_stats(token: str, iv_value: float):\n",
    "    if iv_value is None or not np.isfinite(iv_value): \n",
    "        return\n",
    "    s = _iv_stats[token]\n",
    "    n1 = s[\"n\"] + 1\n",
    "    delta = iv_value - s[\"mean\"]\n",
    "    mean = s[\"mean\"] + delta / n1\n",
    "    delta2 = iv_value - mean\n",
    "    M2 = s[\"M2\"] + delta * delta2\n",
    "    s[\"n\"], s[\"mean\"], s[\"M2\"] = n1, mean, M2\n",
    "\n",
    "def iv_zscore_for(token: str, iv_value: float):\n",
    "    s = _iv_stats[token]\n",
    "    if s[\"n\"] < max(IV_Z_MIN_COUNT, 2):\n",
    "        return 0.0, True\n",
    "    var = s[\"M2\"] / max(s[\"n\"] - 1, 1)\n",
    "    std = math.sqrt(max(var, 1e-12))\n",
    "    z = (iv_value - s[\"mean\"]) / std if std > 0 else 0.0\n",
    "    return z, (abs(z) <= IV_Z_MAX)\n",
    "\n",
    "# Streaming globals\n",
    "live_streamer = None\n",
    "current_tokens = list(token_list)\n",
    "spot_ltp_current = spot_ltp_initial\n",
    "last_center_nearest = int(STRIKE_STEP[UNDERLYING] * math.floor((spot_ltp_initial + STRIKE_STEP[UNDERLYING]/2)/STRIKE_STEP[UNDERLYING]))\n",
    "_last_recenter_ts = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c86289b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Live streamer (Greeks + IV stats + Spot) ----\n",
    "def start_live_stream(tokens: List[str], mode: str = \"full_d30\"):\n",
    "    global live_streamer\n",
    "    if not UPSDK_AVAILABLE:\n",
    "        raise RuntimeError(\"Upstox SDK not installed.\")\n",
    "    if not CredentialUpstox.ACCESS_TOKEN:\n",
    "        raise RuntimeError(\"ACCESS_TOKEN missing. Set UPSTOX_ACCESS_TOKEN or paste into CredentialUpstox.ACCESS_TOKEN\")\n",
    "\n",
    "    configuration = upstox_client.Configuration()\n",
    "    configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n",
    "    api_client = upstox_client.ApiClient(configuration)\n",
    "    streamer = upstox_client.MarketDataStreamerV3(api_client, instrument_key=tokens, mode=mode)\n",
    "\n",
    "    def _on_message(msg):\n",
    "        global df_feed, df_feed_enriched, spot_ltp_current\n",
    "        feeds = msg.get(\"feeds\", {})\n",
    "        for token, payload in feeds.items():\n",
    "            ff = payload.get(\"fullFeed\",{}).get(\"marketFF\",{})\n",
    "            ltpc = ff.get(\"ltpc\",{})\n",
    "            level = ff.get(\"marketLevel\",{}).get(\"bidAskQuote\",[{}])\n",
    "            greeks = ff.get(\"optionGreeks\",{}) or {}\n",
    "\n",
    "            # Update spot if index token arrives\n",
    "            if token == UNDERLYING_SPOT_TOKEN:\n",
    "                try:\n",
    "                    if ltpc.get(\"ltp\") is not None:\n",
    "                        spot_ltp_current = float(ltpc.get(\"ltp\"))\n",
    "                except Exception:\n",
    "                    pass\n",
    "                continue\n",
    "\n",
    "            # Update IV stats\n",
    "            try:\n",
    "                iv_val = ff.get(\"iv\")\n",
    "                if iv_val is not None:\n",
    "                    update_iv_stats(token, float(iv_val))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            row = {\n",
    "                \"Token\": token,\n",
    "                \"Ltp\": float(ltpc.get(\"ltp\")) if ltpc.get(\"ltp\") is not None else np.nan,\n",
    "                \"Ltq\": float(ltpc.get(\"ltq\")) if ltpc.get(\"ltq\") is not None else np.nan,\n",
    "                \"Cp\": float(ltpc.get(\"cp\")) if ltpc.get(\"cp\") is not None else np.nan,\n",
    "                \"BidP1\": float(level[0].get(\"bidP\")) if level and level[0].get(\"bidP\") is not None else np.nan,\n",
    "                \"BidQ1\": float(level[0].get(\"bidQ\")) if level and level[0].get(\"bidQ\") is not None else np.nan,\n",
    "                \"AskP1\": float(level[0].get(\"askP\")) if level and level[0].get(\"askP\") is not None else np.nan,\n",
    "                \"AskQ1\": float(level[0].get(\"askQ\")) if level and level[0].get(\"askQ\") is not None else np.nan,\n",
    "                \"Ltt\": to_ist_ms(ltpc.get(\"ltt\")),\n",
    "                \"Oi\": float(ff.get(\"oi\")) if ff.get(\"oi\") is not None else np.nan,\n",
    "                \"Iv\": float(ff.get(\"iv\")) if ff.get(\"iv\") is not None else np.nan,\n",
    "                \"Atp\": float(ff.get(\"atp\")) if ff.get(\"atp\") is not None else np.nan,\n",
    "                \"Tbq\": float(ff.get(\"tbq\")) if ff.get(\"tbq\") is not None else np.nan,\n",
    "                \"Tsq\": float(ff.get(\"tsq\")) if ff.get(\"tsq\") is not None else np.nan,\n",
    "                \"Delta\": float(greeks.get(\"delta\")) if greeks.get(\"delta\") is not None else np.nan,\n",
    "                \"Theta\": float(greeks.get(\"theta\")) if greeks.get(\"theta\") is not None else np.nan,\n",
    "                \"Gamma\": float(greeks.get(\"gamma\")) if greeks.get(\"gamma\") is not None else np.nan,\n",
    "                \"Vega\":  float(greeks.get(\"vega\"))  if greeks.get(\"vega\")  is not None else np.nan,\n",
    "                \"Rho\":   float(greeks.get(\"rho\"))   if greeks.get(\"rho\")   is not None else np.nan,\n",
    "            }\n",
    "            with _df_lock:\n",
    "                if token in df_feed[\"Token\"].values:\n",
    "                    for k,v in row.items():\n",
    "                        df_feed.loc[df_feed[\"Token\"]==token, k] = v\n",
    "                else:\n",
    "                    df_feed = pd.concat([df_feed, pd.DataFrame([row])], ignore_index=True)\n",
    "                df_feed_enriched = enrich_feed(df_feed, df_chain)\n",
    "\n",
    "    def _on_open():\n",
    "        print(\"WebSocket opened\")\n",
    "\n",
    "    def _on_error(err):\n",
    "        print(\"WebSocket error:\", err)\n",
    "\n",
    "    def _on_close():\n",
    "        print(\"WebSocket closed\")\n",
    "\n",
    "    streamer.on_message = _on_message\n",
    "    streamer.on_open = _on_open\n",
    "    streamer.on_error = _on_error\n",
    "    streamer.on_close = _on_close\n",
    "\n",
    "    streamer.connect()\n",
    "    live_streamer = streamer\n",
    "    return streamer\n",
    "\n",
    "def stop_live_stream():\n",
    "    global live_streamer\n",
    "    try:\n",
    "        if live_streamer is not None:\n",
    "            if hasattr(live_streamer, \"close\"):\n",
    "                live_streamer.close()\n",
    "            elif hasattr(live_streamer, \"disconnect\"):\n",
    "                live_streamer.disconnect()\n",
    "            elif hasattr(live_streamer, \"ws\"):\n",
    "                live_streamer.ws.close()\n",
    "            print(\"Stream stop requested.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error stopping stream:\", e)\n",
    "    finally:\n",
    "        live_streamer = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a73402ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Dynamic recentering ----\n",
    "def compute_token_list_for_spot(spot_ltp: float) -> List[str]:\n",
    "    strikes = nearest_strikes_from_spot(spot_ltp, UNDERLYING, span=SPAN_STRIKES)\n",
    "    df_sel = df_chain[df_chain[\"strike_price\"].isin(strikes)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "    tokens = df_sel[\"instrument_key\"].dropna().astype(str).unique().tolist()\n",
    "    return tokens\n",
    "\n",
    "def maybe_recenter_tokens() -> bool:\n",
    "    global last_center_nearest, _last_recenter_ts, current_tokens, df_chain_sel\n",
    "    step = STRIKE_STEP.get(UNDERLYING.upper(), 50)\n",
    "    nearest = int(step * math.floor((spot_ltp_current + step/2)/step))\n",
    "    now = time.time()\n",
    "    if abs(nearest - last_center_nearest) >= step and (now - _last_recenter_ts) >= RECENTER_COOLDOWN_S:\n",
    "        try:\n",
    "            new_tokens = compute_token_list_for_spot(spot_ltp_current)\n",
    "            if not new_tokens:\n",
    "                return False\n",
    "            tokens_with_spot = list(dict.fromkeys(new_tokens + [UNDERLYING_SPOT_TOKEN]))\n",
    "            if RECENTER_LOG:\n",
    "                print(f\"[RECENTER] spot={spot_ltp_current:.2f}, nearest={nearest}, old_center={last_center_nearest}\")\n",
    "                print(f\"[RECENTER] tokens: {len(current_tokens)} → {len(new_tokens)}\")\n",
    "            stop_live_stream()\n",
    "            start_live_stream(tokens_with_spot, mode=WEBSOCKET_MODE)\n",
    "            last_center_nearest = nearest\n",
    "            _last_recenter_ts = now\n",
    "            current_tokens = new_tokens\n",
    "            df_chain_sel = df_chain[df_chain[\"instrument_key\"].isin(new_tokens)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(\"Recenter failed:\", e)\n",
    "            traceback.print_exc()\n",
    "    return False\n",
    "\n",
    "def recenter_daemon():\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(1.0)\n",
    "            maybe_recenter_tokens()\n",
    "        except Exception:\n",
    "            time.sleep(2.0)\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b6a8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Strategy with gates + LLM scoring (Ollama or HTTP) ----\n",
    "def eligible_entry(row: pd.Series, side: str):\n",
    "    reasons = []\n",
    "    # Delta\n",
    "    delta = row.get(\"Delta\")\n",
    "    if delta is None or not np.isfinite(delta):\n",
    "        reasons.append(\"no_delta\")\n",
    "    else:\n",
    "        if not (DELTA_MIN <= abs(float(delta)) <= DELTA_MAX):\n",
    "            reasons.append(f\"absΔ={abs(float(delta)):.2f}∉[{DELTA_MIN},{DELTA_MAX}]\")\n",
    "    # Spread\n",
    "    spread = row.get(\"Spread\")\n",
    "    if (spread is None) or (not np.isfinite(spread)) or (float(spread) > SPREAD_MAX):\n",
    "        reasons.append(f\"spread={spread} > {SPREAD_MAX}\")\n",
    "    # Depth imbalance\n",
    "    imb = row.get(\"DepthImb\")\n",
    "    if imb is None or not np.isfinite(imb):\n",
    "        reasons.append(\"no_depthimb\")\n",
    "    else:\n",
    "        imb = float(imb)\n",
    "        if side.upper() == \"BUY\" and imb < +DEPTH_IMB_MIN:\n",
    "            reasons.append(f\"imb={imb:.2f} < +{DEPTH_IMB_MIN}\")\n",
    "        if side.upper() == \"SELL\" and imb > -DEPTH_IMB_MIN:\n",
    "            reasons.append(f\"imb={imb:.2f} > -{DEPTH_IMB_MIN}\")\n",
    "    # IV regime\n",
    "    iv = row.get(\"Iv\")\n",
    "    z, iv_ok = (0.0, True)\n",
    "    try:\n",
    "        if iv is not None and np.isfinite(iv):\n",
    "            z, iv_ok = iv_zscore_for(row[\"Token\"], float(iv))\n",
    "            if not iv_ok:\n",
    "                reasons.append(f\"|z_IV|={abs(z):.2f} > {IV_Z_MAX}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    ok = len(reasons) == 0\n",
    "    return ok, \";\".join(reasons), {\"iv_z\": z}\n",
    "\n",
    "def _compact_row(r: pd.Series):\n",
    "    return {\n",
    "        \"token\": str(r[\"Token\"]),\n",
    "        \"tsym\": str(r.get(\"trading_symbol\", \"\")),\n",
    "        \"mid\": float(r.get(\"Mid\", np.nan)),\n",
    "        \"spread\": float(r.get(\"Spread\", np.nan)),\n",
    "        \"delta\": float(r.get(\"Delta\", np.nan)),\n",
    "        \"gamma\": float(r.get(\"Gamma\", np.nan)),\n",
    "        \"theta\": float(r.get(\"Theta\", np.nan)),\n",
    "        \"iv\": float(r.get(\"Iv\", np.nan)),\n",
    "        \"depthImb\": float(r.get(\"DepthImb\", np.nan)),\n",
    "        \"strike\": float(r.get(\"strike_price\", np.nan)),\n",
    "        \"type\": str(r.get(\"instrument_type\",\"\")),\n",
    "    }\n",
    "\n",
    "def _build_ollama_prompt(context: dict) -> str:\n",
    "    # Tiny, schema-bound prompt to elicit {\"score\": float}\n",
    "    rules = context.get(\"rules\", {})\n",
    "    ce, pe = context.get(\"ce\", {}), context.get(\"pe\", {})\n",
    "    spot = context.get(\"spot\", 0.0)\n",
    "    return (\n",
    "        \"You are a scalping trade scorer. Return a single JSON object with a numeric field 'score' in [0,1].\"\n",
    "        \"Higher score means better conditions to open a short ATM strangle now.\"\n",
    "        \"No explanation, no extra text.\"\n",
    "        f\"spot: {spot}\"\n",
    "        f\"ce: mid={ce.get('mid')}, spread={ce.get('spread')}, delta={ce.get('delta')}, gamma={ce.get('gamma')}, theta={ce.get('theta')}, iv={ce.get('iv')}, depthImb={ce.get('depthImb')}\"\n",
    "        f\"pe: mid={pe.get('mid')}, spread={pe.get('spread')}, delta={pe.get('delta')}, gamma={pe.get('gamma')}, theta={pe.get('theta')}, iv={pe.get('iv')}, depthImb={pe.get('depthImb')}\"\n",
    "        f\"rules: absDelta={rules.get('absDelta')}, spreadMax={rules.get('spreadMax')}, depthImbMin={rules.get('depthImbMin')}, ivZMax={rules.get('ivZMax')}\"\n",
    "        'Return strictly: {\"score\": <float>}'\n",
    "    )\n",
    "\n",
    "def _llm_score(context: dict) -> float:\n",
    "    # 1) Prefer Ollama if model is provided\n",
    "    if OLLAMA_MODEL:\n",
    "        try:\n",
    "            import requests\n",
    "            prompt = _build_ollama_prompt(context)\n",
    "            payload = {\n",
    "                \"model\": OLLAMA_MODEL,\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False,\n",
    "                \"options\": {\"temperature\": 0.1, \"num_predict\": OLLAMA_NUM_PREDICT},\n",
    "                \"format\": \"json\"\n",
    "            }\n",
    "            r = requests.post(f\"{OLLAMA_HOST}/api/generate\", json=payload, timeout=OLLAMA_TIMEOUT_S)\n",
    "            if not r.ok:\n",
    "                # fallback: try without json forcing\n",
    "                payload.pop(\"format\", None)\n",
    "                r = requests.post(f\"{OLLAMA_HOST}/api/generate\", json=payload, timeout=OLLAMA_TIMEOUT_S)\n",
    "            j = r.json() if r.ok else {}\n",
    "            txt = j.get(\"response\", \"\").strip()\n",
    "            try:\n",
    "                obj = json.loads(txt)\n",
    "                s = float(obj.get(\"score\", 0.6))\n",
    "            except Exception:\n",
    "                # try to extract a number\n",
    "                import re\n",
    "                m = re.search(r\"([01](?:\\.\\d+)?)\", txt)\n",
    "                s = float(m.group(1)) if m else 0.6\n",
    "            return max(0.0, min(1.0, s))\n",
    "        except Exception:\n",
    "            return 0.6\n",
    "\n",
    "    # 2) Generic HTTP endpoint if configured\n",
    "    if LLM_ENDPOINT:\n",
    "        try:\n",
    "            import requests\n",
    "            r = requests.post(LLM_ENDPOINT, json=context, timeout=LLM_TIMEOUT_S)\n",
    "            j = r.json() if r.ok else {}\n",
    "            s = float(j.get(\"score\", 0.6))\n",
    "            return max(0.0, min(1.0, s))\n",
    "        except Exception:\n",
    "            return 0.6\n",
    "\n",
    "    # 3) Neutral if nothing configured\n",
    "    return 0.6\n",
    "\n",
    "def ask_llm_for_strategy(df_snapshot: pd.DataFrame, use_mock: bool = True) -> Dict[str, Any]:\n",
    "    if df_snapshot.empty:\n",
    "        return {\"legs\": []}\n",
    "    snap = df_snapshot.dropna(subset=[\"Mid\",\"strike_price\",\"instrument_type\"]).copy()\n",
    "    if snap.empty:\n",
    "        return {\"legs\": []}\n",
    "\n",
    "    # Prefer near-ATM and Delta ~0.5\n",
    "    snap[\"dist\"] = (snap[\"Mid\"] - snap[\"strike_price\"]).abs()\n",
    "    def delta_score(d):\n",
    "        try:\n",
    "            d = abs(float(d))\n",
    "            return abs(0.5 - d) if np.isfinite(d) else 0.5\n",
    "        except Exception:\n",
    "            return 0.5\n",
    "    snap[\"delta_score\"] = snap[\"Delta\"].apply(delta_score)\n",
    "\n",
    "    picks = []\n",
    "    for opt in (\"CE\",\"PE\"):\n",
    "        sub = snap[snap[\"instrument_type\"] == opt].sort_values([\"dist\",\"delta_score\"]).head(3)\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        picks.append(sub.iloc[0])\n",
    "    if len(picks) < 2:\n",
    "        return {\"legs\": []}\n",
    "    ce_row, pe_row = (picks[0], picks[1]) if picks[0][\"instrument_type\"]==\"CE\" else (picks[1], picks[0])\n",
    "\n",
    "    ce_ok, ce_reason, ce_ex = eligible_entry(ce_row, side=\"SELL\")\n",
    "    pe_ok, pe_reason, pe_ex = eligible_entry(pe_row, side=\"SELL\")\n",
    "    if not ce_ok or not pe_ok:\n",
    "        return {\"legs\": []}\n",
    "\n",
    "    context = {\n",
    "        \"spot\": float(spot_ltp_current),\n",
    "        \"ce\": _compact_row(ce_row),\n",
    "        \"pe\": _compact_row(pe_row),\n",
    "        \"position\": [],\n",
    "        \"rules\": {\n",
    "            \"absDelta\": [DELTA_MIN, DELTA_MAX],\n",
    "            \"spreadMax\": SPREAD_MAX,\n",
    "            \"depthImbMin\": DEPTH_IMB_MIN,\n",
    "            \"ivZMax\": IV_Z_MAX\n",
    "        }\n",
    "    }\n",
    "    score = _llm_score(context) if use_mock else _llm_score(context)  # both paths use scorer; set USE_LLM to disable gating\n",
    "    if score < LLM_SCORE_THRESHOLD and USE_LLM:\n",
    "        return {\"legs\": []}\n",
    "\n",
    "    legs = []\n",
    "    for r in (ce_row, pe_row):\n",
    "        lot = int(r.get(\"lot_size\") or 0) or 50\n",
    "        legs.append({\"token\": str(r[\"Token\"]), \"side\": \"SELL\", \"qty\": lot, \"product\": DEFAULT_PRODUCT, \"order_type\": \"LIMIT\"})\n",
    "    return {\"legs\": legs, \"meta\": {\"score\": score}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de34a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Orders, throttle, latency, exits ----\n",
    "open_positions = {}  # token -> dict(side, qty, avg_price)\n",
    "\n",
    "def record_fill(fill: Dict[str, Any]):\n",
    "    token = str(fill[\"token\"])\n",
    "    side = fill[\"side\"].upper()\n",
    "    qty = int(fill[\"qty\"])\n",
    "    price = float(fill.get(\"price\", 0.0))\n",
    "    pos = open_positions.get(token, {\"qty\": 0, \"side\": side, \"avg_price\": 0.0})\n",
    "    if pos[\"qty\"] == 0:\n",
    "        pos = {\"qty\": qty, \"side\": side, \"avg_price\": price}\n",
    "    else:\n",
    "        new_qty = pos[\"qty\"] + qty if side == pos[\"side\"] else pos[\"qty\"] - qty\n",
    "        if new_qty <= 0:\n",
    "            pos = {\"qty\": 0, \"side\": side, \"avg_price\": 0.0}\n",
    "        else:\n",
    "            pos = {\"qty\": new_qty, \"side\": side, \"avg_price\": (pos[\"avg_price\"]*pos[\"qty\"] + price*qty)/max(new_qty,1)}\n",
    "    open_positions[token] = pos\n",
    "\n",
    "@dataclass\n",
    "class ExitConfig:\n",
    "    dry_run: bool = True\n",
    "    target_pct: float = 0.2\n",
    "    stop_pct: float = 0.4\n",
    "    check_interval_s: float = 1.0\n",
    "\n",
    "_exit_thread = None\n",
    "_exit_stop_evt = threading.Event()\n",
    "\n",
    "def should_exit_position(token: str, row: pd.Series, pos: Dict[str, Any], cfg: ExitConfig) -> Optional[Dict[str, Any]]:\n",
    "    px = row.get(\"Mid\", np.nan)\n",
    "    if np.isnan(px):\n",
    "        px = row.get(\"Ltp\", np.nan)\n",
    "    if np.isnan(px) or pos[\"qty\"] <= 0:\n",
    "        return None\n",
    "    entry = pos[\"avg_price\"]\n",
    "    side = pos[\"side\"]\n",
    "    pnl = (px - entry) if side==\"BUY\" else (entry - px)\n",
    "    if entry <= 0:\n",
    "        return None\n",
    "    pnl_pct = pnl / entry\n",
    "    if pnl_pct >= cfg.target_pct:\n",
    "        return {\"action\":\"EXIT\",\"reason\":\"target\",\"token\":token,\"qty\":pos[\"qty\"],\"side\": \"SELL\" if side==\"BUY\" else \"BUY\"}\n",
    "    if pnl_pct <= -cfg.stop_pct:\n",
    "        return {\"action\":\"EXIT\",\"reason\":\"stop\",\"token\":token,\"qty\":pos[\"qty\"],\"side\": \"SELL\" if side==\"BUY\" else \"BUY\"}\n",
    "    return None\n",
    "\n",
    "def _exit_worker(cfg: ExitConfig):\n",
    "    while not _exit_stop_evt.is_set():\n",
    "        time.sleep(cfg.check_interval_s)\n",
    "        with _df_lock:\n",
    "            snapshot = df_feed_enriched.copy()\n",
    "        for token, pos in list(open_positions.items()):\n",
    "            if pos[\"qty\"] <= 0:\n",
    "                continue\n",
    "            row = snapshot.loc[snapshot[\"Token\"]==token]\n",
    "            if row.empty:\n",
    "                continue\n",
    "            row = row.iloc[0]\n",
    "            signal = should_exit_position(token, row, pos, cfg)\n",
    "            if signal:\n",
    "                if cfg.dry_run:\n",
    "                    print(f\"[EXIT-SIM] {signal}\")\n",
    "                else:\n",
    "                    print(f\"[EXIT-LIVE] Would place exit for {token}: {signal}\")\n",
    "                open_positions[token] = {\"qty\": 0, \"side\": pos[\"side\"], \"avg_price\": pos[\"avg_price\"]}\n",
    "\n",
    "def start_exit_manager(cfg: ExitConfig):\n",
    "    global _exit_thread, _exit_stop_evt\n",
    "    _exit_stop_evt = threading.Event()\n",
    "    _exit_thread = threading.Thread(target=_exit_worker, args=(cfg,), daemon=True)\n",
    "    _exit_thread.start()\n",
    "\n",
    "def stop_exit_manager():\n",
    "    global _exit_thread, _exit_stop_evt\n",
    "    _exit_stop_evt.set()\n",
    "    if _exit_thread is not None:\n",
    "        _exit_thread.join(timeout=5)\n",
    "\n",
    "_last_order_ts = 0.0\n",
    "\n",
    "def _to_tick(price: float, tick: float, side: str):\n",
    "    if not np.isfinite(price) or not np.isfinite(tick) or tick <= 0:\n",
    "        return float(price)\n",
    "    if side.upper() == \"BUY\":\n",
    "        return round(math.ceil(price / tick) * tick, 2)\n",
    "    else:\n",
    "        return round(math.floor(price / tick) * tick, 2)\n",
    "\n",
    "def _marketable_limit(row: pd.Series, side: str, buf_ticks: int = LIMIT_BUFFER_TICKS):\n",
    "    tick = float(row.get(\"tick_size\") or 0.05)\n",
    "    bid = float(row.get(\"BidP1\") or np.nan)\n",
    "    ask = float(row.get(\"AskP1\") or np.nan)\n",
    "    if side.upper() == \"BUY\":\n",
    "        base = ask if np.isfinite(ask) else float(row.get(\"Mid\", 0.0))\n",
    "        return _to_tick(base + buf_ticks*tick, tick, \"BUY\")\n",
    "    else:\n",
    "        base = bid if np.isfinite(bid) else float(row.get(\"Mid\", 0.0))\n",
    "        px = base - buf_ticks*tick\n",
    "        return _to_tick(px, tick, \"SELL\")\n",
    "\n",
    "def _lat_log(event: str, **kwargs):\n",
    "    ts = time.perf_counter()\n",
    "    LATENCY_LOG.append({\"t\": ts, \"event\": event, **kwargs})\n",
    "    if len(LATENCY_LOG) > LATENCY_LOG_MAX:\n",
    "        del LATENCY_LOG[: len(LATENCY_LOG) - LATENCY_LOG_MAX]\n",
    "\n",
    "def place_orders(plan: Dict[str, Any], df_enriched: pd.DataFrame, dry_run: bool = True) -> List[Dict[str, Any]]:\n",
    "    results = []\n",
    "    if not plan or \"legs\" not in plan:\n",
    "        return results\n",
    "\n",
    "    order_api = None\n",
    "    if not dry_run:\n",
    "        if not UPSDK_AVAILABLE:\n",
    "            raise RuntimeError(\"Upstox SDK not available for live orders\")\n",
    "        if not CredentialUpstox.ACCESS_TOKEN:\n",
    "            raise RuntimeError(\"ACCESS_TOKEN missing for live orders\")\n",
    "        configuration = upstox_client.Configuration()\n",
    "        configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n",
    "        api_client = upstox_client.ApiClient(configuration)\n",
    "        order_api = upstox_client.OrderApi(api_client)\n",
    "\n",
    "    global _last_order_ts\n",
    "    for leg in plan[\"legs\"]:\n",
    "        token = str(leg[\"token\"])\n",
    "        row = df_enriched.loc[df_enriched[\"Token\"]==token]\n",
    "        if row.empty:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":\"token_not_found\",\"leg\":leg})\n",
    "            continue\n",
    "        row = row.iloc[0]\n",
    "        lot = int(row.get(\"lot_size\") or 0)\n",
    "        qty = int(leg.get(\"qty\", 0))\n",
    "        if lot and qty % lot != 0:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":f\"qty_not_multiple_of_lot({lot})\",\"leg\":leg}); continue\n",
    "        if qty <= 0 or qty > MAX_QTY_PER_LEG:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":\"qty_bounds\",\"leg\":leg}); continue\n",
    "\n",
    "        side = leg[\"side\"].upper()\n",
    "        product_code = PRODUCT_MAP.get(leg.get(\"product\", DEFAULT_PRODUCT), PRODUCT_MAP[DEFAULT_PRODUCT])\n",
    "\n",
    "        order_type = leg.get(\"order_type\",\"MARKET\").upper()\n",
    "        px = None\n",
    "        if USE_MARKETABLE_LIMITS:\n",
    "            px = _marketable_limit(row, side)\n",
    "            order_type = \"LIMIT\"\n",
    "        else:\n",
    "            px = float(leg.get(\"price\") or 0.0)\n",
    "\n",
    "        now = time.perf_counter()\n",
    "        delay_ms = ORDER_MIN_GAP_MS - (now - _last_order_ts) * 1000.0\n",
    "        if delay_ms > 0:\n",
    "            time.sleep(delay_ms / 1000.0)\n",
    "        _last_order_ts = time.perf_counter()\n",
    "\n",
    "        _lat_log(\"order_send\", token=token, side=side, qty=qty, px=px, order_type=order_type)\n",
    "        if dry_run:\n",
    "            fill = float(row.get(\"Mid\")) if np.isfinite(row.get(\"Mid\", np.nan)) else float(row.get(\"Ltp\", 0.0))\n",
    "            results.append({\"status\":\"simulated\",\"token\":token,\"qty\":qty,\"side\":side,\"product\":product_code,\"order_type\":order_type,\"limit_price\":px,\"fill_price\":fill})\n",
    "            record_fill({\"token\": token, \"side\": side, \"qty\": qty, \"price\": fill})\n",
    "            _lat_log(\"order_ack\", token=token)\n",
    "        else:\n",
    "            req = upstox_client.PlaceOrderRequest(\n",
    "                quantity=str(qty),\n",
    "                product=product_code,\n",
    "                validity=\"DAY\",\n",
    "                price=float(px) if order_type==\"LIMIT\" else 0.0,\n",
    "                tag=\"LLM-STRATEGY\",\n",
    "                instrument_token=token,\n",
    "                order_type=order_type,\n",
    "                transaction_type=side,\n",
    "                disclosed_quantity=0,\n",
    "                trigger_price=0.0,\n",
    "                is_amo=False\n",
    "            )\n",
    "            resp = order_api.place_order(body=req, api_version=\"3.0\")\n",
    "            results.append({\"status\":\"placed\",\"order_id\":resp.data.order_id,\"token\":token,\"qty\":qty,\"side\":side,\"limit_price\":px})\n",
    "            record_fill({\"token\": token, \"side\": side, \"qty\": qty, \"price\": float(row.get(\"Mid\") or row.get(\"Ltp\") or 0.0)})\n",
    "            _lat_log(\"order_ack\", token=token)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32a9817c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MarketDataStreamerV3.__init__() got an unexpected keyword argument 'instrument_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThis notebook is live-first. Set SIMULATION_MODE=False to proceed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m tokens_with_spot = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mdict\u001b[39m.fromkeys(token_list + [UNDERLYING_SPOT_TOKEN]))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m streamer = \u001b[43mstart_live_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens_with_spot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWEBSOCKET_MODE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m time.sleep(\u001b[32m3.0\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _df_lock:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mstart_live_stream\u001b[39m\u001b[34m(tokens, mode)\u001b[39m\n\u001b[32m     10\u001b[39m configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n\u001b[32m     11\u001b[39m api_client = upstox_client.ApiClient(configuration)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m streamer = \u001b[43mupstox_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMarketDataStreamerV3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstrument_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_on_message\u001b[39m(msg):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mglobal\u001b[39;00m df_feed, df_feed_enriched, spot_ltp_current\n",
      "\u001b[31mTypeError\u001b[39m: MarketDataStreamerV3.__init__() got an unexpected keyword argument 'instrument_key'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Orchestration (live-first) ----\n",
    "if SIMULATION_MODE:\n",
    "    raise RuntimeError(\"This notebook is live-first. Set SIMULATION_MODE=False to proceed.\")\n",
    "\n",
    "tokens_with_spot = list(dict.fromkeys(token_list + [UNDERLYING_SPOT_TOKEN]))\n",
    "streamer = start_live_stream(tokens_with_spot, mode=WEBSOCKET_MODE)\n",
    "\n",
    "time.sleep(3.0)\n",
    "\n",
    "with _df_lock:\n",
    "    snapshot = df_feed_enriched.copy()\n",
    "print(\"Feed snapshot rows:\", len(snapshot))\n",
    "display(snapshot.tail(6))\n",
    "\n",
    "LATENCY_LOG.clear()\n",
    "def _lat_log(event: str, **kwargs):\n",
    "    ts = time.perf_counter()\n",
    "    LATENCY_LOG.append({\"t\": ts, \"event\": event, **kwargs})\n",
    "    if len(LATENCY_LOG) > LATENCY_LOG_MAX:\n",
    "        del LATENCY_LOG[: len(LATENCY_LOG) - LATENCY_LOG_MAX]\n",
    "\n",
    "_lat_log(\"decision_start\", rows=len(snapshot))\n",
    "plan = ask_llm_for_strategy(snapshot, use_mock=USE_LLM)  # USE_LLM gates by threshold internally\n",
    "_lat_log(\"decision_end\", legs=len(plan.get(\"legs\", [])))\n",
    "\n",
    "try:\n",
    "    _lat_log(\"validate_start\")\n",
    "    validated = validate_strategy(plan, snapshot)\n",
    "    _lat_log(\"validate_end\", ok=True)\n",
    "except Exception as e:\n",
    "    validated = None\n",
    "    _lat_log(\"validate_end\", ok=False, err=str(e))\n",
    "    print(\"Validation failed:\", e)\n",
    "\n",
    "orders = []\n",
    "if validated:\n",
    "    _lat_log(\"place_start\", nlegs=len(validated[\"legs\"]))\n",
    "    orders = place_orders(validated, snapshot, dry_run=(not ORDERS_LIVE))\n",
    "    _lat_log(\"place_end\", norders=len(orders))\n",
    "    print(\"Order results:\")\n",
    "    print(json.dumps(orders, indent=2))\n",
    "\n",
    "cfg = ExitConfig(dry_run=(not EXIT_MANAGER_LIVE))\n",
    "start_exit_manager(cfg)\n",
    "\n",
    "_recenter_thread = threading.Thread(target=recenter_daemon, daemon=True)\n",
    "_recenter_thread.start()\n",
    "\n",
    "print(\"Live scalper pipeline running. Use the Stop cell to close sockets and exit manager.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86244771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Monitor + diagnostics ----\n",
    "with _df_lock:\n",
    "    mon = df_feed_enriched.copy()\n",
    "display(mon.tail(12))\n",
    "\n",
    "if not mon.empty:\n",
    "    mon[\"dist\"] = (mon[\"Mid\"] - mon[\"strike_price\"]).abs()\n",
    "    picks = mon.sort_values([\"dist\"]).groupby(\"instrument_type\").head(2)\n",
    "    rows = []\n",
    "    for _, r in picks.iterrows():\n",
    "        ok_sell, why_sell, ex = eligible_entry(r, side=\"SELL\")\n",
    "        rows.append({\n",
    "            \"tsym\": r.get(\"trading_symbol\",\"\"),\n",
    "            \"type\": r.get(\"instrument_type\",\"\"),\n",
    "            \"mid\": r.get(\"Mid\"),\n",
    "            \"spread\": r.get(\"Spread\"),\n",
    "            \"depthImb\": r.get(\"DepthImb\"),\n",
    "            \"delta\": r.get(\"Delta\"),\n",
    "            \"iv\": r.get(\"Iv\"),\n",
    "            \"ok_sell\": ok_sell,\n",
    "            \"why_sell\": why_sell,\n",
    "            \"iv_z\": ex.get(\"iv_z\")\n",
    "        })\n",
    "    df_check = pd.DataFrame(rows)\n",
    "    display(df_check)\n",
    "else:\n",
    "    print(\"No feed yet.\")\n",
    "\n",
    "# Latency\n",
    "def latency_report(n_tail: int = 50) -> pd.DataFrame:\n",
    "    df = pd.DataFrame(LATENCY_LOG[-n_tail:])\n",
    "    return df\n",
    "\n",
    "display(latency_report(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a630ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Stop streaming & exit manager ----\n",
    "stop_exit_manager()\n",
    "stop_live_stream()\n",
    "print(\"Shutdown requested.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
