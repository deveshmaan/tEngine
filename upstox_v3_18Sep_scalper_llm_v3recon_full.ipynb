{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "242cff35",
   "metadata": {},
   "source": [
    "\n",
    "# `upstox_v3_18Sep_scalper_llm_v3recon_full.ipynb`\n",
    "**NIFTY Intraday Scalper (Live‑First)** — Spot‑Anchored + Greeks + IV‑Z + Marketable‑Limit + Recenter + Latency + **LLM Router** + **PnL Ledger** + **Multi‑Entry** + **V3 Exec & Live Reconciler**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01949226",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, time, threading, math, traceback, uuid, re\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "# Upstox SDK\n",
    "try:\n",
    "    import upstox_client\n",
    "    from upstox_client.rest import ApiException\n",
    "    UPSDK_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    UPSDK_AVAILABLE = False\n",
    "    print(\"Upstox SDK not available. Install it to run live streaming and orders.\")\n",
    "    print(\"Example: pip install upstox-python-sdk   # confirm exact name per Upstox docs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f29195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Toggles & constants ----\n",
    "SIMULATION_MODE = False        # This is live-first; set to True only for offline tests\n",
    "USE_LLM = True\n",
    "USE_ROUTER = True\n",
    "\n",
    "ORDERS_LIVE = False            # If True, use V3 place/modify/cancel\n",
    "EXIT_MANAGER_LIVE = False      # If True, send exits via V3\n",
    "RECONCILE_LIVE_PNL = True      # Start Portfolio Stream Feed reconciler\n",
    "\n",
    "UNDERLYING = \"NIFTY\"\n",
    "UNDERLYING_SPOT_TOKEN = \"NSE_INDEX|Nifty 50\"\n",
    "SPAN_STRIKES = 2\n",
    "WEBSOCKET_MODE = \"full_d30\"\n",
    "IST = \"Asia/Kolkata\"\n",
    "\n",
    "STRIKE_STEP = {\"NIFTY\": 50, \"BANKNIFTY\": 100, \"FINNIFTY\": 50}\n",
    "MAX_QTY_PER_LEG = 300\n",
    "MAX_OPEN_LEGS = 6\n",
    "\n",
    "RECENTER_COOLDOWN_S = 60.0\n",
    "RECENTER_LOG = True\n",
    "\n",
    "# Scalper gates\n",
    "DELTA_MIN, DELTA_MAX = 0.45, 0.55\n",
    "SPREAD_MAX = 0.20\n",
    "DEPTH_IMB_MIN = 0.15\n",
    "IV_Z_MAX = 2.0\n",
    "IV_Z_MIN_COUNT = 30\n",
    "\n",
    "# Execution\n",
    "USE_MARKETABLE_LIMITS = True\n",
    "LIMIT_BUFFER_TICKS = 1\n",
    "ORDER_MIN_GAP_MS = 200\n",
    "\n",
    "# LLM + Router\n",
    "LLM_ENDPOINT = os.getenv(\"LLM_ENDPOINT\", \"\")  # fast stub endpoint\n",
    "LLM_TIMEOUT_S = float(os.getenv(\"LLM_TIMEOUT_S\", \"0.12\"))\n",
    "OLLAMA_HOST = os.getenv(\"OLLAMA_HOST\", \"http://127.0.0.1:11434\")\n",
    "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"\")  # e.g., \"mistral\"\n",
    "OLLAMA_TIMEOUT_S = float(os.getenv(\"OLLAMA_TIMEOUT_S\", \"0.20\"))\n",
    "OLLAMA_NUM_PREDICT = int(os.getenv(\"OLLAMA_NUM_PREDICT\", \"16\"))\n",
    "LLM_SCORE_THRESHOLD = 0.55\n",
    "STUB_LOWER, STUB_UPPER = 0.35, 0.75\n",
    "\n",
    "# Latency logs\n",
    "LATENCY_LOG = []; LATENCY_LOG_MAX = 5000\n",
    "ROUTER_LOG = []; ROUTER_LOG_MAX = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d90d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CredentialUpstox:\n",
    "    ACCESS_TOKEN = os.getenv(\"UPSTOX_ACCESS_TOKEN\", \"\")\n",
    "\n",
    "PRODUCT_MAP = {\"MIS\": \"I\", \"NRML\": \"D\"}\n",
    "DEFAULT_PRODUCT = \"MIS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428dda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_ist_ms(ms) -> pd.Timestamp:\n",
    "    try:\n",
    "        return pd.to_datetime(int(ms), unit=\"ms\", utc=True).tz_convert(IST)\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def resolve_next_listed_expiry(df_instruments: pd.DataFrame, underlying: str, today=None) -> str:\n",
    "    t = pd.Timestamp.now(IST).normalize() if today is None else pd.Timestamp(today, tz=IST).normalize()\n",
    "    dfx = df_instruments[(df_instruments[\"segment\"] == \"NSE_FO\") &\n",
    "                         (df_instruments[\"name\"].str.upper() == underlying.upper()) &\n",
    "                         (df_instruments[\"instrument_type\"].isin([\"CE\",\"PE\"]))].copy()\n",
    "    if dfx.empty: raise ValueError(f\"No derivatives found for {underlying} in instruments master\")\n",
    "    dfx[\"_exp\"] = pd.to_datetime(dfx[\"expiry\"], errors=\"coerce\")\n",
    "    dfx = dfx[dfx[\"_exp\"] >= t.tz_localize(None)]\n",
    "    if dfx.empty: raise ValueError(f\"No upcoming expiry >= {t.date()} for {underlying}\")\n",
    "    return dfx[\"_exp\"].min().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def nearest_strikes_from_spot(spot_ltp: float, underlying: str, span: int = 2):\n",
    "    step = STRIKE_STEP.get(underlying.upper(), 50)\n",
    "    nearest = int(step * math.floor((spot_ltp + step/2) / step))\n",
    "    return [nearest + i * step for i in range(-span, span+1)]\n",
    "\n",
    "def get_upstox_quote_client():\n",
    "    if not UPSDK_AVAILABLE: raise RuntimeError(\"Upstox SDK is not available.\")\n",
    "    if not CredentialUpstox.ACCESS_TOKEN: raise RuntimeError(\"ACCESS_TOKEN missing. Set UPSTOX_ACCESS_TOKEN.\")\n",
    "    configuration = upstox_client.Configuration(); configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n",
    "    return upstox_client.MarketQuoteV3Api(upstox_client.ApiClient(configuration))\n",
    "\n",
    "def _extract_ltp_from_entry(entry: dict) -> float:\n",
    "    if not isinstance(entry, dict): raise KeyError(\"Invalid LTP entry\")\n",
    "    for k in (\"ltp\",\"last_traded_price\",\"last\",\"close\",\"price\"):\n",
    "        if k in entry and entry[k] is not None: return float(entry[k])\n",
    "    if \"ltpc\" in entry and isinstance(entry[\"ltpc\"], dict) and \"ltp\" in entry[\"ltpc\"]:\n",
    "        return float(entry[\"ltpc\"][\"ltp\"])\n",
    "    raise KeyError(f\"No LTP field found in entry keys={list(entry.keys())}\")\n",
    "\n",
    "def get_index_spot_ltp(instrument_key: str = None) -> float:\n",
    "    instrument_key = instrument_key or UNDERLYING_SPOT_TOKEN\n",
    "    api = get_upstox_quote_client()\n",
    "    try:\n",
    "        api_response = api.get_ltp(instrument_key=[instrument_key] if not isinstance(instrument_key, list) else instrument_key)\n",
    "        data_dict = api_response.to_dict() if hasattr(api_response, \"to_dict\") else dict(api_response)\n",
    "        data = data_dict.get(\"data\", {})\n",
    "        entry = data.get(instrument_key) or (next(iter(data.values())) if data else {})\n",
    "        ltp = _extract_ltp_from_entry(entry)\n",
    "        if not np.isfinite(ltp): raise RuntimeError(f\"LTP non-finite: {ltp}\")\n",
    "        return float(ltp)\n",
    "    except ApiException as e:\n",
    "        raise RuntimeError(f\"Upstox get_ltp ApiException: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e97d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_instruments_live() -> pd.DataFrame:\n",
    "    url = \"https://assets.upstox.com/market-quote/instruments/exchange/NSE.json.gz\"\n",
    "    try:\n",
    "        df = pd.read_json(url)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load instruments from {url}: {e}\")\n",
    "    if \"expiry\" in df:\n",
    "        exp = pd.to_datetime(df[\"expiry\"], unit=\"ms\", errors=\"coerce\")\n",
    "        mask = exp.isna() & df[\"expiry\"].notna()\n",
    "        if mask.any():\n",
    "            exp2 = pd.to_datetime(df.loc[mask, \"expiry\"], errors=\"coerce\")\n",
    "            exp.loc[mask] = exp2\n",
    "        df[\"expiry\"] = exp.dt.strftime(\"%Y-%m-%d\")\n",
    "    for col in (\"strike_price\",\"lot_size\",\"tick_size\",\"minimum_lot\"):\n",
    "        if col in df: df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "df_futureOptions = load_instruments_live()\n",
    "expiry_target = resolve_next_listed_expiry(df_futureOptions, UNDERLYING)\n",
    "df_chain = df_futureOptions[(df_futureOptions[\"segment\"]==\"NSE_FO\") &\n",
    "                            (df_futureOptions[\"name\"].str.upper()==UNDERLYING.upper()) &\n",
    "                            (df_futureOptions[\"instrument_type\"].isin([\"CE\",\"PE\"])) &\n",
    "                            (df_futureOptions[\"expiry\"]==expiry_target)].copy()\n",
    "assert not df_chain.empty, f\"No options for {UNDERLYING} {expiry_target}\"\n",
    "\n",
    "try:\n",
    "    spot_ltp_initial = get_index_spot_ltp(UNDERLYING_SPOT_TOKEN)\n",
    "    print(f\"NIFTY 50 spot LTP: {spot_ltp_initial:.2f}\")\n",
    "except Exception as e:\n",
    "    print(\"Spot LTP lookup failed; fallback to chain median:\", e)\n",
    "    spot_ltp_initial = float(df_chain[\"strike_price\"].median())\n",
    "\n",
    "strike_list = nearest_strikes_from_spot(spot_ltp_initial, UNDERLYING, span=SPAN_STRIKES)\n",
    "df_chain_sel = df_chain[df_chain[\"strike_price\"].isin(strike_list)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "token_list = df_chain_sel[\"instrument_key\"].dropna().astype(str).unique().tolist()\n",
    "print(f\"Selected strikes from spot {spot_ltp_initial:.2f}: {sorted(set(strike_list))}\")\n",
    "display(df_chain_sel.head(8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1147ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_feed = pd.DataFrame(columns=[\n",
    "    \"Token\",\"Ltp\",\"Ltq\",\"Cp\",\n",
    "    \"BidP1\",\"BidQ1\",\"AskP1\",\"AskQ1\",\n",
    "    \"Ltt\",\"Oi\",\"Iv\",\"Atp\",\"Tbq\",\"Tsq\",\n",
    "    \"Delta\",\"Theta\",\"Gamma\",\"Vega\",\"Rho\"\n",
    "])\n",
    "df_feed_enriched = pd.DataFrame()\n",
    "_df_lock = threading.Lock()\n",
    "\n",
    "def enrich_feed(_df_feed: pd.DataFrame, _df_meta: pd.DataFrame, cols_to_add=None) -> pd.DataFrame:\n",
    "    if cols_to_add is None:\n",
    "        cols_to_add = [\"lot_size\",\"trading_symbol\",\"strike_price\",\"tick_size\",\"instrument_type\",\"expiry\",\"name\"]\n",
    "    left = _df_feed.copy()\n",
    "    right = _df_meta[[\"instrument_key\"] + [c for c in cols_to_add if c in _df_meta.columns]].drop_duplicates(\"instrument_key\")\n",
    "    out = left.merge(right, left_on=\"Token\", right_on=\"instrument_key\", how=\"left\", validate=\"m:1\")\n",
    "    out[\"Mid\"] = np.where(out[\"BidP1\"].notna() & out[\"AskP1\"].notna(), (out[\"BidP1\"] + out[\"AskP1\"])/2.0, out[\"Ltp\"])\n",
    "    out[\"Spread\"] = np.where(out[\"BidP1\"].notna() & out[\"AskP1\"].notna(), (out[\"AskP1\"] - out[\"BidP1\"]), np.nan)\n",
    "    out[\"DepthImb\"] = np.where(\n",
    "        (out[\"BidQ1\"].notna() & out[\"AskQ1\"].notna() & ((out[\"BidQ1\"] + out[\"AskQ1\"]) > 0)),\n",
    "        (out[\"BidQ1\"] - out[\"AskQ1\"]) / (out[\"BidQ1\"] + out[\"AskQ1\"]),\n",
    "        np.nan,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# IV z-score stats (Welford)\n",
    "from collections import defaultdict\n",
    "_iv_stats = defaultdict(lambda: {\"n\":0, \"mean\":0.0, \"M2\":0.0})\n",
    "def update_iv_stats(token: str, iv_value: float):\n",
    "    if iv_value is None or not np.isfinite(iv_value): return\n",
    "    s = _iv_stats[token]\n",
    "    n1 = s[\"n\"] + 1\n",
    "    delta = iv_value - s[\"mean\"]\n",
    "    mean = s[\"mean\"] + delta / n1\n",
    "    delta2 = iv_value - mean\n",
    "    M2 = s[\"M2\"] + delta * delta2\n",
    "    s[\"n\"], s[\"mean\"], s[\"M2\"] = n1, mean, M2\n",
    "\n",
    "def iv_zscore_for(token: str, iv_value: float):\n",
    "    s = _iv_stats[token]\n",
    "    if s[\"n\"] < max(IV_Z_MIN_COUNT, 2):\n",
    "        return 0.0, True\n",
    "    var = s[\"M2\"] / max(s[\"n\"] - 1, 1)\n",
    "    std = math.sqrt(max(var, 1e-12))\n",
    "    z = (iv_value - s[\"mean\"]) / std if std > 0 else 0.0\n",
    "    return z, (abs(z) <= IV_Z_MAX)\n",
    "\n",
    "# Streaming globals\n",
    "live_streamer = None\n",
    "current_tokens = list(token_list)\n",
    "spot_ltp_current = spot_ltp_initial\n",
    "last_center_nearest = int(STRIKE_STEP[UNDERLYING] * math.floor((spot_ltp_initial + STRIKE_STEP[UNDERLYING]/2)/STRIKE_STEP[UNDERLYING]))\n",
    "_last_recenter_ts = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d586e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start_live_stream(tokens: List[str], mode: str = \"full_d30\"):\n",
    "    global live_streamer\n",
    "    if not UPSDK_AVAILABLE: raise RuntimeError(\"Upstox SDK not installed.\")\n",
    "    if not CredentialUpstox.ACCESS_TOKEN: raise RuntimeError(\"ACCESS_TOKEN missing.\")\n",
    "\n",
    "    configuration = upstox_client.Configuration()\n",
    "    configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n",
    "    api_client = upstox_client.ApiClient(configuration)\n",
    "    streamer = upstox_client.MarketDataStreamerV3(api_client, instrument_key=tokens, mode=mode)\n",
    "\n",
    "    def _on_message(msg):\n",
    "        global df_feed, df_feed_enriched, spot_ltp_current\n",
    "        feeds = msg.get(\"feeds\", {})\n",
    "        for token, payload in feeds.items():\n",
    "            ff = payload.get(\"fullFeed\",{}).get(\"marketFF\",{})\n",
    "            ltpc = ff.get(\"ltpc\",{})\n",
    "            level = ff.get(\"marketLevel\",{}).get(\"bidAskQuote\",[{}])\n",
    "            greeks = ff.get(\"optionGreeks\",{}) or {}\n",
    "            if token == UNDERLYING_SPOT_TOKEN:\n",
    "                try:\n",
    "                    if ltpc.get(\"ltp\") is not None:\n",
    "                        spot_ltp_current = float(ltpc.get(\"ltp\"))\n",
    "                except Exception: pass\n",
    "                continue\n",
    "            try:\n",
    "                iv_val = ff.get(\"iv\")\n",
    "                if iv_val is not None:\n",
    "                    update_iv_stats(token, float(iv_val))\n",
    "            except Exception: pass\n",
    "            row = {\n",
    "                \"Token\": token,\n",
    "                \"Ltp\": float(ltpc.get(\"ltp\")) if ltpc.get(\"ltp\") is not None else np.nan,\n",
    "                \"Ltq\": float(ltpc.get(\"ltq\")) if ltpc.get(\"ltq\") is not None else np.nan,\n",
    "                \"Cp\": float(ltpc.get(\"cp\")) if ltpc.get(\"cp\") is not None else np.nan,\n",
    "                \"BidP1\": float(level[0].get(\"bidP\")) if level and level[0].get(\"bidP\") is not None else np.nan,\n",
    "                \"BidQ1\": float(level[0].get(\"bidQ\")) if level and level[0].get(\"bidQ\") is not None else np.nan,\n",
    "                \"AskP1\": float(level[0].get(\"askP\")) if level and level[0].get(\"askP\") is not None else np.nan,\n",
    "                \"AskQ1\": float(level[0].get(\"askQ\")) if level and level[0].get(\"askQ\") is not None else np.nan,\n",
    "                \"Ltt\": to_ist_ms(ltpc.get(\"ltt\")),\n",
    "                \"Oi\": float(ff.get(\"oi\")) if ff.get(\"oi\") is not None else np.nan,\n",
    "                \"Iv\": float(ff.get(\"iv\")) if ff.get(\"iv\") is not None else np.nan,\n",
    "                \"Atp\": float(ff.get(\"atp\")) if ff.get(\"atp\") is not None else np.nan,\n",
    "                \"Tbq\": float(ff.get(\"tbq\")) if ff.get(\"tbq\") is not None else np.nan,\n",
    "                \"Tsq\": float(ff.get(\"tsq\")) if ff.get(\"tsq\") is not None else np.nan,\n",
    "                \"Delta\": float(greeks.get(\"delta\")) if greeks.get(\"delta\") is not None else np.nan,\n",
    "                \"Theta\": float(greeks.get(\"theta\")) if greeks.get(\"theta\") is not None else np.nan,\n",
    "                \"Gamma\": float(greeks.get(\"gamma\")) if greeks.get(\"gamma\") is not None else np.nan,\n",
    "                \"Vega\":  float(greeks.get(\"vega\"))  if greeks.get(\"vega\")  is not None else np.nan,\n",
    "                \"Rho\":   float(greeks.get(\"rho\"))   if greeks.get(\"rho\")   is not None else np.nan,\n",
    "            }\n",
    "            with _df_lock:\n",
    "                if token in df_feed[\"Token\"].values:\n",
    "                    for k,v in row.items(): df_feed.loc[df_feed[\"Token\"]==token, k] = v\n",
    "                else:\n",
    "                    df_feed = pd.concat([df_feed, pd.DataFrame([row])], ignore_index=True)\n",
    "                df_feed_enriched = enrich_feed(df_feed, df_chain)\n",
    "\n",
    "    streamer.on_message = _on_message\n",
    "    streamer.on_open = lambda: print(\"Market WS opened\")\n",
    "    streamer.on_error = lambda e: print(\"Market WS error:\", e)\n",
    "    streamer.on_close = lambda: print(\"Market WS closed\")\n",
    "    streamer.connect()\n",
    "    live_streamer = streamer\n",
    "    return streamer\n",
    "\n",
    "def stop_live_stream():\n",
    "    global live_streamer\n",
    "    try:\n",
    "        if live_streamer is not None:\n",
    "            if hasattr(live_streamer, \"close\"): live_streamer.close()\n",
    "            elif hasattr(live_streamer, \"disconnect\"): live_streamer.disconnect()\n",
    "            elif hasattr(live_streamer, \"ws\"): live_streamer.ws.close()\n",
    "            print(\"Market stream stop requested.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error stopping stream:\", e)\n",
    "    finally:\n",
    "        live_streamer = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72347722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_token_list_for_spot(spot_ltp: float):\n",
    "    strikes = nearest_strikes_from_spot(spot_ltp, UNDERLYING, span=SPAN_STRIKES)\n",
    "    df_sel = df_chain[df_chain[\"strike_price\"].isin(strikes)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "    tokens = df_sel[\"instrument_key\"].dropna().astype(str).unique().tolist()\n",
    "    return tokens\n",
    "\n",
    "def maybe_recenter_tokens():\n",
    "    global last_center_nearest, _last_recenter_ts, current_tokens, df_chain_sel\n",
    "    step = STRIKE_STEP.get(UNDERLYING.upper(), 50)\n",
    "    nearest = int(step * math.floor((spot_ltp_current + step/2)/step))\n",
    "    now = time.time()\n",
    "    if abs(nearest - last_center_nearest) >= step and (now - _last_recenter_ts) >= RECENTER_COOLDOWN_S:\n",
    "        try:\n",
    "            new_tokens = compute_token_list_for_spot(spot_ltp_current)\n",
    "            if not new_tokens: return False\n",
    "            tokens_with_spot = list(dict.fromkeys(new_tokens + [UNDERLYING_SPOT_TOKEN]))\n",
    "            if RECENTER_LOG:\n",
    "                print(f\"[RECENTER] spot={spot_ltp_current:.2f}, nearest={nearest}, old_center={last_center_nearest}\")\n",
    "                print(f\"[RECENTER] tokens: {len(current_tokens)} → {len(new_tokens)}\")\n",
    "            stop_live_stream(); start_live_stream(tokens_with_spot, mode=WEBSOCKET_MODE)\n",
    "            last_center_nearest = nearest; _last_recenter_ts = now; current_tokens = new_tokens\n",
    "            df_chain_sel = df_chain[df_chain[\"instrument_key\"].isin(new_tokens)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(\"Recenter failed:\", e); traceback.print_exc()\n",
    "    return False\n",
    "\n",
    "def recenter_daemon():\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(1.0); maybe_recenter_tokens()\n",
    "        except Exception:\n",
    "            time.sleep(2.0); continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3670d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eligible_entry(row: pd.Series, side: str):\n",
    "    reasons = []\n",
    "    delta = row.get(\"Delta\")\n",
    "    if delta is None or not np.isfinite(delta):\n",
    "        reasons.append(\"no_delta\")\n",
    "    else:\n",
    "        if not (DELTA_MIN <= abs(float(delta)) <= DELTA_MAX):\n",
    "            reasons.append(f\"absΔ={abs(float(delta)):.2f}∉[{DELTA_MIN},{DELTA_MAX}]\")\n",
    "    spread = row.get(\"Spread\")\n",
    "    if (spread is None) or (not np.isfinite(spread)) or (float(spread) > SPREAD_MAX):\n",
    "        reasons.append(f\"spread={spread} > {SPREAD_MAX}\")\n",
    "    imb = row.get(\"DepthImb\")\n",
    "    if imb is None or not np.isfinite(imb):\n",
    "        reasons.append(\"no_depthimb\")\n",
    "    else:\n",
    "        imb = float(imb)\n",
    "        if side.upper() == \"BUY\" and imb < +DEPTH_IMB_MIN:\n",
    "            reasons.append(f\"imb={imb:.2f} < +{DEPTH_IMB_MIN}\")\n",
    "        if side.upper() == \"SELL\" and imb > -DEPTH_IMB_MIN:\n",
    "            reasons.append(f\"imb={imb:.2f} > -{DEPTH_IMB_MIN}\")\n",
    "    iv = row.get(\"Iv\")\n",
    "    z, iv_ok = (0.0, True)\n",
    "    try:\n",
    "        if iv is not None and np.isfinite(iv):\n",
    "            z, iv_ok = iv_zscore_for(row[\"Token\"], float(iv))\n",
    "            if not iv_ok: reasons.append(f\"|z_IV|={abs(z):.2f} > {IV_Z_MAX}\")\n",
    "    except Exception: pass\n",
    "    ok = len(reasons) == 0\n",
    "    return ok, \";\".join(reasons), {\"iv_z\": z}\n",
    "\n",
    "def _compact_row(r: pd.Series):\n",
    "    return {\n",
    "        \"token\": str(r[\"Token\"]),\n",
    "        \"tsym\": str(r.get(\"trading_symbol\", \"\")),\n",
    "        \"mid\": float(r.get(\"Mid\", np.nan)),\n",
    "        \"spread\": float(r.get(\"Spread\", np.nan)),\n",
    "        \"delta\": float(r.get(\"Delta\", np.nan)),\n",
    "        \"gamma\": float(r.get(\"Gamma\", np.nan)),\n",
    "        \"theta\": float(r.get(\"Theta\", np.nan)),\n",
    "        \"iv\": float(r.get(\"Iv\", np.nan)),\n",
    "        \"depthImb\": float(r.get(\"DepthImb\", np.nan)),\n",
    "        \"strike\": float(r.get(\"strike_price\", np.nan)),\n",
    "        \"type\": str(r.get(\"instrument_type\",\"\")),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _build_ollama_prompt(context: dict) -> str:\n",
    "    rules = context.get(\"rules\", {})\n",
    "    ce, pe = context.get(\"ce\", {}), context.get(\"pe\", {})\n",
    "    spot = context.get(\"spot\", 0.0)\n",
    "    return (\n",
    "        \"You are a scalping trade scorer. Return a single JSON object with 'score' in [0,1].\\n\"\n",
    "        \"No explanation.\\n\\n\"\n",
    "        f\"spot: {spot}\\n\"\n",
    "        f\"ce: mid={ce.get('mid')}, spread={ce.get('spread')}, delta={ce.get('delta')}, gamma={ce.get('gamma')}, theta={ce.get('theta')}, iv={ce.get('iv')}, depthImb={ce.get('depthImb')}\\n\"\n",
    "        f\"pe: mid={pe.get('mid')}, spread={pe.get('spread')}, delta={pe.get('delta')}, gamma={pe.get('gamma')}, theta={pe.get('theta')}, iv={pe.get('iv')}, depthImb={pe.get('depthImb')}\\n\"\n",
    "        f\"rules: absDelta={rules.get('absDelta')}, spreadMax={rules.get('spreadMax')}, depthImbMin={rules.get('depthImbMin')}, ivZMax={rules.get('ivZMax')}\\n\\n\"\n",
    "        \"Return strictly: {\\\"score\\\": <float>}\"\n",
    "    )\n",
    "\n",
    "def _router_log(entry: dict):\n",
    "    entry = dict(entry); entry.setdefault(\"t\", time.perf_counter())\n",
    "    ROUTER_LOG.append(entry)\n",
    "    if len(ROUTER_LOG) > ROUTER_LOG_MAX:\n",
    "        del ROUTER_LOG[: len(ROUTER_LOG) - ROUTER_LOG_MAX]\n",
    "\n",
    "def _post_stub(context: dict):\n",
    "    t0 = time.perf_counter()\n",
    "    if not LLM_ENDPOINT:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.post(LLM_ENDPOINT, json=context, timeout=LLM_TIMEOUT_S)\n",
    "        s = float(r.json().get(\"score\", 0.6)) if r.ok else 0.6\n",
    "        return max(0.0, min(1.0, s)), (time.perf_counter() - t0)*1000.0, True\n",
    "    except Exception:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False\n",
    "\n",
    "def _post_ollama(context: dict):\n",
    "    t0 = time.perf_counter()\n",
    "    if not OLLAMA_MODEL:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False\n",
    "    try:\n",
    "        import requests\n",
    "        payload = {\"model\": OLLAMA_MODEL, \"prompt\": _build_ollama_prompt(context), \"stream\": False,\n",
    "                   \"options\": {\"temperature\": 0.1, \"num_predict\": OLLAMA_NUM_PREDICT}, \"format\": \"json\"}\n",
    "        r = requests.post(f\"{OLLAMA_HOST}/api/generate\", json=payload, timeout=OLLAMA_TIMEOUT_S)\n",
    "        if not r.ok:\n",
    "            payload.pop(\"format\", None)\n",
    "            r = requests.post(f\"{OLLAMA_HOST}/api/generate\", json=payload, timeout=OLLAMA_TIMEOUT_S)\n",
    "        txt = r.json().get(\"response\", \"\") if r.ok else \"\"\n",
    "        try:\n",
    "            s = float(json.loads(txt).get(\"score\", 0.6))\n",
    "        except Exception:\n",
    "            m = re.search(r\"([01](?:\\.\\d+)?)\", txt)\n",
    "            s = float(m.group(1)) if m else 0.6\n",
    "        return max(0.0, min(1.0, s)), (time.perf_counter() - t0)*1000.0, True\n",
    "    except Exception:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False\n",
    "\n",
    "def score_with_router_and_meta(context: dict):\n",
    "    thr = LLM_SCORE_THRESHOLD\n",
    "    stub_score, stub_ms, stub_ok = _post_stub(context)\n",
    "    stub_decision = (stub_score >= thr)\n",
    "    route = \"no_stub\"; ollama_score, ollama_ms, used_ollama = (None, 0.0, False)\n",
    "\n",
    "    if stub_ok:\n",
    "        if stub_score >= STUB_UPPER:\n",
    "            final_score = stub_score; route = \"stub_high\"\n",
    "        elif stub_score <= STUB_LOWER:\n",
    "            final_score = stub_score; route = \"stub_low\"\n",
    "        else:\n",
    "            o_score, o_ms, o_ok = _post_ollama(context)\n",
    "            used_ollama = True; ollama_score, ollama_ms = (o_score, o_ms)\n",
    "            if o_ok: final_score = o_score; route = \"gray_ollama\"\n",
    "            else:    final_score = stub_score; route = \"gray_fallback_stub\"\n",
    "    else:\n",
    "        o_score, o_ms, o_ok = _post_ollama(context)\n",
    "        used_ollama = True if o_ok else False; ollama_score, ollama_ms = (o_score, o_ms)\n",
    "        final_score = o_score if o_ok else 0.6\n",
    "        route = \"no_stub_ollama\" if o_ok else \"neutral\"\n",
    "\n",
    "    final_decision = (final_score >= thr)\n",
    "    entry = {\"route\": route, \"stub_score\": stub_score, \"stub_ms\": round(stub_ms, 2),\n",
    "             \"ollama_score\": ollama_score, \"ollama_ms\": round(ollama_ms, 2),\n",
    "             \"final_score\": final_score, \"stub_decision\": stub_decision,\n",
    "             \"final_decision\": final_decision, \"used_ollama\": used_ollama}\n",
    "    _router_log(entry)\n",
    "    return float(final_score), entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a74283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_llm_for_strategy(df_snapshot: pd.DataFrame, use_mock: bool = True) -> Dict[str, Any]:\n",
    "    if df_snapshot.empty: return {\"legs\": []}\n",
    "    snap = df_snapshot.dropna(subset=[\"Mid\",\"strike_price\",\"instrument_type\"]).copy()\n",
    "    if snap.empty: return {\"legs\": []}\n",
    "\n",
    "    snap[\"dist\"] = (snap[\"Mid\"] - snap[\"strike_price\"]).abs()\n",
    "    def delta_score(d):\n",
    "        try:\n",
    "            d = abs(float(d)); return abs(0.5 - d) if np.isfinite(d) else 0.5\n",
    "        except Exception: return 0.5\n",
    "    snap[\"delta_score\"] = snap[\"Delta\"].apply(delta_score)\n",
    "\n",
    "    picks = []\n",
    "    for opt in (\"CE\",\"PE\"):\n",
    "        sub = snap[snap[\"instrument_type\"] == opt].sort_values([\"dist\",\"delta_score\"]).head(3)\n",
    "        if sub.empty: continue\n",
    "        picks.append(sub.iloc[0])\n",
    "    if len(picks) < 2: return {\"legs\": []}\n",
    "    ce_row, pe_row = (picks[0], picks[1]) if picks[0][\"instrument_type\"]==\"CE\" else (picks[1], picks[0])\n",
    "\n",
    "    ce_ok, _, _ = eligible_entry(ce_row, side=\"SELL\")\n",
    "    pe_ok, _, _ = eligible_entry(pe_row, side=\"SELL\")\n",
    "    if not ce_ok or not pe_ok: return {\"legs\": []}\n",
    "\n",
    "    context = {\"spot\": float(spot_ltp_current),\n",
    "               \"ce\": _compact_row(ce_row),\n",
    "               \"pe\": _compact_row(pe_row),\n",
    "               \"position\": [],\n",
    "               \"rules\": {\"absDelta\":[DELTA_MIN, DELTA_MAX], \"spreadMax\":SPREAD_MAX, \"depthImbMin\":DEPTH_IMB_MIN, \"ivZMax\":IV_Z_MAX}}\n",
    "    score, router_meta = score_with_router_and_meta(context)\n",
    "    if USE_LLM and (score < LLM_SCORE_THRESHOLD): return {\"legs\": [], \"meta\": router_meta}\n",
    "\n",
    "    legs = []\n",
    "    for r in (ce_row, pe_row):\n",
    "        lot = int(r.get(\"lot_size\") or 0) or 50\n",
    "        legs.append({\"token\": str(r[\"Token\"]), \"side\": \"SELL\", \"qty\": lot, \"product\": DEFAULT_PRODUCT, \"order_type\": \"LIMIT\",\n",
    "                     \"_row\": r.to_dict()})\n",
    "    return {\"legs\": legs, \"meta\": {\"score\": score, **router_meta}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84221ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "open_positions = {}  # token -> {qty, side, avg_price}\n",
    "\n",
    "# === Multi-entry controls ===\n",
    "MULTI_ENTRY_PER_TOKEN = True\n",
    "MAX_OPEN_TRADES_PER_TOKEN = 3\n",
    "MAX_NET_QTY_PER_TOKEN = 3 * 50  # example if lot=50\n",
    "ENTRY_COOLDOWN_S = 5.0\n",
    "ADD_REQUIRES_IMPROVEMENT = True\n",
    "\n",
    "_last_entry_ts = {}\n",
    "_last_entry_micro = {}\n",
    "\n",
    "# --- Ledger ---\n",
    "TRADE_LOG = []                 # append-only\n",
    "TRADE_OPEN_STACK = {}          # token -> list[int] (open entry indices)\n",
    "\n",
    "def _open_count(token: str) -> int:\n",
    "    return len([i for i in TRADE_OPEN_STACK.get(token, []) if TRADE_LOG[i].get(\"exit_ts\") is None])\n",
    "\n",
    "def _net_open_qty(token: str) -> int:\n",
    "    total = 0\n",
    "    for i in TRADE_OPEN_STACK.get(token, []):\n",
    "        rec = TRADE_LOG[i]\n",
    "        if rec.get(\"exit_ts\") is None:\n",
    "            total += int(rec.get(\"remaining_qty\", rec.get(\"qty\", 0)))\n",
    "    return total\n",
    "\n",
    "def _iv_z_for_row(r):\n",
    "    try:\n",
    "        z, _ok = iv_zscore_for(r[\"Token\"], float(r.get(\"Iv\", np.nan)))\n",
    "        return z\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def _micro_snapshot(r):\n",
    "    return {\"Spread\": float(r.get(\"Spread\", np.nan)),\n",
    "            \"DepthImb\": float(r.get(\"DepthImb\", np.nan)),\n",
    "            \"IvZ\": _iv_z_for_row(r)}\n",
    "\n",
    "def _micro_improved(token: str, r) -> bool:\n",
    "    last = _last_entry_micro.get(token)\n",
    "    now = _micro_snapshot(r)\n",
    "    _last_entry_micro[token] = now\n",
    "    if not ADD_REQUIRES_IMPROVEMENT or not last:\n",
    "        return True\n",
    "    return (\n",
    "        (np.isfinite(now[\"Spread\"]) and np.isfinite(last[\"Spread\"]) and now[\"Spread\"] <= last[\"Spread\"]) and\n",
    "        (np.isfinite(now[\"DepthImb\"]) and np.isfinite(last[\"DepthImb\"]) and now[\"DepthImb\"] <= last[\"DepthImb\"]) and\n",
    "        (np.isfinite(now[\"IvZ\"]) and np.isfinite(last[\"IvZ\"]) and abs(now[\"IvZ\"]) <= abs(last[\"IvZ\"]) + 1e-9)\n",
    "    )\n",
    "\n",
    "def _can_open_more(token: str, add_qty: int) -> (bool, str):\n",
    "    if not MULTI_ENTRY_PER_TOKEN:\n",
    "        return (_open_count(token) == 0, \"multi_disabled\")\n",
    "    if _open_count(token) >= MAX_OPEN_TRADES_PER_TOKEN:\n",
    "        return (False, \"max_open_trades\")\n",
    "    if (_net_open_qty(token) + add_qty) > MAX_NET_QTY_PER_TOKEN:\n",
    "        return (False, \"net_qty_cap\")\n",
    "    if time.time() - _last_entry_ts.get(token, 0) < ENTRY_COOLDOWN_S:\n",
    "        return (False, \"entry_cooldown\")\n",
    "    return (True, \"ok\")\n",
    "\n",
    "def _now_ts():\n",
    "    return pd.Timestamp.now(tz=IST)\n",
    "\n",
    "def log_trade_open(token: str, side: str, qty: int, price: float, plan_meta: dict, row_data: dict,\n",
    "                   target_pct=None, stop_pct=None, order_id: Optional[str]=None):\n",
    "    micro = _micro_snapshot(row_data or {})\n",
    "    rec = {\n",
    "        \"token\": token, \"side\": side, \"qty\": int(qty),\n",
    "        \"remaining_qty\": int(qty),\n",
    "        \"entry_price\": float(price), \"entry_ts\": _now_ts(),\n",
    "        \"entry_spread\": micro[\"Spread\"], \"entry_depthimb\": micro[\"DepthImb\"], \"entry_iv_z\": micro[\"IvZ\"],\n",
    "        \"target_pct\": float(target_pct if target_pct is not None else 0.20),\n",
    "        \"stop_pct\": float(stop_pct if stop_pct is not None else 0.40),\n",
    "        \"router_route\": plan_meta.get(\"route\") if plan_meta else None,\n",
    "        \"score_final\": plan_meta.get(\"final_score\") if plan_meta else None,\n",
    "        \"score_stub\": plan_meta.get(\"stub_score\") if plan_meta else None,\n",
    "        \"score_ollama\": plan_meta.get(\"ollama_score\") if plan_meta else None,\n",
    "        \"stub_ms\": plan_meta.get(\"stub_ms\"), \"ollama_ms\": plan_meta.get(\"ollama_ms\"),\n",
    "        \"order_id\": order_id,\n",
    "        \"exit_reason\": None, \"exit_price\": None, \"exit_ts\": None,\n",
    "        \"pnl_abs\": None, \"pnl_pct\": None, \"hold_s\": None,\n",
    "    }\n",
    "    TRADE_LOG.append(rec)\n",
    "    idx = len(TRADE_LOG) - 1\n",
    "    TRADE_OPEN_STACK.setdefault(token, []).append(idx)\n",
    "    _last_entry_ts[token] = time.time()\n",
    "    return idx\n",
    "\n",
    "def log_trade_exit(token: str, reason: str, exit_price: float, match=\"LIFO\", exit_qty=None):\n",
    "    stack = TRADE_OPEN_STACK.get(token, [])\n",
    "    if not stack: return None\n",
    "    idx = stack[-1] if match == \"LIFO\" else stack[0]\n",
    "    rec = TRADE_LOG[idx]\n",
    "    if rec.get(\"exit_ts\") is not None:\n",
    "        stack.pop(-1 if match==\"LIFO\" else 0)\n",
    "        return log_trade_exit(token, reason, exit_price, match, exit_qty)\n",
    "    rem = int(rec.get(\"remaining_qty\", rec[\"qty\"])); take = rem if (exit_qty is None or exit_qty >= rem) else int(exit_qty)\n",
    "    new_rem = rem - take\n",
    "    side = rec[\"side\"].upper(); entry = rec[\"entry_price\"]\n",
    "    pnl_leg = (exit_price - entry) if side==\"BUY\" else (entry - exit_price)\n",
    "    realized_pct = pnl_leg / entry if entry else 0.0\n",
    "    if new_rem <= 0:\n",
    "        rec[\"remaining_qty\"] = 0; rec[\"exit_reason\"] = reason; rec[\"exit_price\"] = float(exit_price); rec[\"exit_ts\"] = _now_ts()\n",
    "        rec[\"pnl_abs\"] = float(pnl_leg); rec[\"pnl_pct\"] = float(realized_pct); rec[\"hold_s\"] = float((rec[\"exit_ts\"] - rec[\"entry_ts\"]).total_seconds())\n",
    "        stack.pop(-1 if match==\"LIFO\" else 0)\n",
    "        return idx\n",
    "    else:\n",
    "        rec[\"remaining_qty\"] = new_rem\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2698048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class ExitConfig:\n",
    "    dry_run: bool = True\n",
    "    target_pct: float = 0.2\n",
    "    stop_pct: float = 0.4\n",
    "    check_interval_s: float = 1.0\n",
    "\n",
    "_exit_thread = None; _exit_stop_evt = threading.Event()\n",
    "\n",
    "def eval_exits_for_token(token: str, row: pd.Series) -> list:\n",
    "    out = []\n",
    "    for idx in list(TRADE_OPEN_STACK.get(token, [])):\n",
    "        rec = TRADE_LOG[idx]\n",
    "        if rec.get(\"exit_ts\") is not None: continue\n",
    "        rem = int(rec.get(\"remaining_qty\", rec[\"qty\"]))\n",
    "        if rem <= 0: continue\n",
    "        side = rec[\"side\"].upper(); entry = float(rec[\"entry_price\"])\n",
    "        px = float(row.get(\"Mid\") if np.isfinite(row.get(\"Mid\", np.nan)) else row.get(\"Ltp\"))\n",
    "        if not np.isfinite(px) or entry <= 0: continue\n",
    "        pnl_pct = (px - entry)/entry if side==\"BUY\" else (entry - px)/entry\n",
    "        if pnl_pct >= rec[\"target_pct\"]:\n",
    "            out.append({\"action\":\"EXIT\",\"reason\":\"target\",\"token\":token,\"qty\":rem,\"side\":\"SELL\" if side==\"BUY\" else \"BUY\",\"exit_price\":px,\"idx\":idx})\n",
    "        elif pnl_pct <= -rec[\"stop_pct\"]:\n",
    "            out.append({\"action\":\"EXIT\",\"reason\":\"stop\",\"token\":token,\"qty\":rem,\"side\":\"SELL\" if side==\"BUY\" else \"BUY\",\"exit_price\":px,\"idx\":idx})\n",
    "    return out\n",
    "\n",
    "def _exit_worker(cfg: ExitConfig):\n",
    "    while not _exit_stop_evt.is_set():\n",
    "        time.sleep(cfg.check_interval_s)\n",
    "        with _df_lock:\n",
    "            snapshot = df_feed_enriched.copy()\n",
    "        for token, pos in list(open_positions.items()):\n",
    "            row = snapshot.loc[snapshot[\"Token\"]==token]\n",
    "            if row.empty: continue\n",
    "            row = row.iloc[0]\n",
    "            signals = eval_exits_for_token(token, row)\n",
    "            for sig in signals:\n",
    "                # Log PnL immediately (live-first); reconciler will refine via fills if needed\n",
    "                log_trade_exit(token, sig[\"reason\"], sig[\"exit_price\"], match=\"LIFO\", exit_qty=sig[\"qty\"])\n",
    "                if cfg.dry_run or (exec_v3 is None):\n",
    "                    print(f\"[EXIT-SIM] {sig}\")\n",
    "                else:\n",
    "                    # Place live exit via V3 (marketable-limit around BBO)\n",
    "                    best_bid = float(row.get(\"BidP1\")) if np.isfinite(row.get(\"BidP1\", np.nan)) else float(row.get(\"Mid\", 0.0))\n",
    "                    best_ask = float(row.get(\"AskP1\")) if np.isfinite(row.get(\"AskP1\", np.nan)) else float(row.get(\"Mid\", 0.0))\n",
    "                    tick = float(row.get(\"tick_size\") or 0.05)\n",
    "                    info = exec_v3.place_order_v3(\n",
    "                        instrument_token=token, side=sig[\"side\"], quantity=int(sig[\"qty\"]),\n",
    "                        best_bid=best_bid, best_ask=best_ask, tick_size=tick, product=PRODUCT_MAP.get(DEFAULT_PRODUCT,\"I\"),\n",
    "                        marketable_limit=True, buffer_ticks=LIMIT_BUFFER_TICKS, tag=\"LLM-EXIT\"\n",
    "                    )\n",
    "                    print(\"[EXIT-LIVE] sent:\", info)\n",
    "            if signals:\n",
    "                open_positions[token] = {\"qty\": 0, \"side\": pos.get(\"side\",\"SELL\"), \"avg_price\": pos.get(\"avg_price\", 0.0)}\n",
    "\n",
    "def start_exit_manager(cfg: ExitConfig):\n",
    "    global _exit_thread, _exit_stop_evt\n",
    "    _exit_stop_evt = threading.Event()\n",
    "    _exit_thread = threading.Thread(target=_exit_worker, args=(cfg,), daemon=True)\n",
    "    _exit_thread.start()\n",
    "\n",
    "def stop_exit_manager():\n",
    "    global _exit_thread, _exit_stop_evt\n",
    "    _exit_stop_evt.set()\n",
    "    if _exit_thread is not None:\n",
    "        _exit_thread.join(timeout=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_last_order_ts = 0.0\n",
    "\n",
    "def _lat_log(event: str, **kwargs):\n",
    "    ts = time.perf_counter()\n",
    "    LATENCY_LOG.append({\"t\": ts, \"event\": event, **kwargs})\n",
    "    if len(LATENCY_LOG) > LATENCY_LOG_MAX:\n",
    "        del LATENCY_LOG[: len(LATENCY_LOG) - LATENCY_LOG_MAX]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326c9d7",
   "metadata": {},
   "source": [
    "\n",
    "## Upstox **V3** Execution & Live Reconciliation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UPSTOX_DOCS_BASE = 'https://upstox.com/developer/api-documentation/orders'\n",
    "UPSTOX_WS_DOCS = 'https://upstox.com/developer/api-documentation/get-portfolio-stream-feed/'\n",
    "VERBOSE_EXEC  = True\n",
    "VERBOSE_RECON = True\n",
    "\n",
    "class UpstoxV3Exec:\n",
    "    def __init__(self, access_token: str):\n",
    "        self.access_token = access_token\n",
    "        configuration = upstox_client.Configuration(); configuration.access_token = self.access_token\n",
    "        self._api_client = upstox_client.ApiClient(configuration)\n",
    "        self.order_api_v3 = upstox_client.OrderApiV3(self._api_client)\n",
    "\n",
    "    @staticmethod\n",
    "    def _now_ms():\n",
    "        return int(time.time() * 1000)\n",
    "\n",
    "    def marketable_limit(self, best_bid: float, best_ask: float, side: str, tick_size: float, buffer_ticks: int = 1) -> float:\n",
    "        px = (best_ask + buffer_ticks * tick_size) if side.upper()==\"BUY\" else (best_bid - buffer_ticks * tick_size)\n",
    "        ticks = round(px / max(tick_size, 1e-6))\n",
    "        return float(ticks * max(tick_size, 1e-6))\n",
    "\n",
    "    def place_order_v3(self, *, instrument_token: str, side: str, quantity: int,\n",
    "                       best_bid: float, best_ask: float, price: float = None,\n",
    "                       product: str = \"I\", validity: str = \"DAY\", disclosed_quantity: int = 0,\n",
    "                       trigger_price: float = 0.0, is_amo: bool = False,\n",
    "                       marketable_limit: bool = True, buffer_ticks: int = 1,\n",
    "                       tick_size: float = 0.05, tag: str = None) -> dict:\n",
    "        if tag is None:\n",
    "            tag = f\"router-{uuid.uuid4().hex[:8]}\"\n",
    "        if price is None and marketable_limit:\n",
    "            price = self.marketable_limit(best_bid, best_ask, side, tick_size, buffer_ticks)\n",
    "        req = upstox_client.PlaceOrderV3Request(\n",
    "            quantity=int(quantity), product=product, validity=validity, price=float(price if price is not None else 0.0),\n",
    "            tag=tag, instrument_token=instrument_token,\n",
    "            order_type='LIMIT' if price else 'MARKET', transaction_type=side.upper(),\n",
    "            disclosed_quantity=int(disclosed_quantity), trigger_price=float(trigger_price), is_amo=bool(is_amo), slice=False\n",
    "        )\n",
    "        t0 = self._now_ms()\n",
    "        try:\n",
    "            resp = self.order_api_v3.place_order(req)\n",
    "            t1 = self._now_ms()\n",
    "            order_id = None\n",
    "            if hasattr(resp, \"data\") and resp.data:\n",
    "                if isinstance(resp.data, dict) and \"order_id\" in resp.data: order_id = resp.data[\"order_id\"]\n",
    "                elif isinstance(resp.data, dict) and \"order_ids\" in resp.data: \n",
    "                    order_ids = resp.data.get(\"order_ids\") or []; order_id = order_ids[0] if order_ids else None\n",
    "            info = {\"ok\": True, \"order_id\": order_id, \"sent_ts\": t0, \"ack_ts\": t1, \"broker_latency_ms\": (t1 - t0)}\n",
    "            if VERBOSE_EXEC: print(\"[V3/place] ok\", info)\n",
    "            return info\n",
    "        except ApiException as e:\n",
    "            t1 = self._now_ms()\n",
    "            err = {\"ok\": False, \"error\": str(e), \"sent_ts\": t0, \"ack_ts\": t1}\n",
    "            print(\"[V3/place] ERROR\", err); return err\n",
    "\n",
    "exec_v3 = UpstoxV3Exec(CredentialUpstox.ACCESS_TOKEN) if (UPSDK_AVAILABLE and CredentialUpstox.ACCESS_TOKEN) else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "FILL_LOG_COLS = ['ts', 'order_id', 'status', 'filled_qty', 'avg_price', 'trading_symbol', 'instrument_token', 'transaction_type', 'raw']\n",
    "FILL_LOG = pd.DataFrame(columns=FILL_LOG_COLS)\n",
    "\n",
    "class UpstoxPortfolioReconciler:\n",
    "    def __init__(self, access_token: str):\n",
    "        configuration = upstox_client.Configuration(); configuration.access_token = access_token\n",
    "        api_client = upstox_client.ApiClient(configuration)\n",
    "        self.streamer = upstox_client.PortfolioDataStreamer(api_client, order_update=True, position_update=False, holding_update=False, gtt_update=False)\n",
    "        self.order_meta = {}; self.last_seen_fill_qty = defaultdict(int)\n",
    "\n",
    "    def attach_meta(self, order_id: str, meta: dict):\n",
    "        self.order_meta[order_id] = meta or {}\n",
    "\n",
    "    def _append_fill_log(self, record: dict):\n",
    "        global FILL_LOG\n",
    "        FILL_LOG.loc[len(FILL_LOG)] = [\n",
    "            record.get('ts'), record.get('order_id'), record.get('status'), record.get('filled_quantity'),\n",
    "            record.get('average_price'), record.get('trading_symbol'), record.get('instrument_token'),\n",
    "            record.get('transaction_type'), json.dumps(record)\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_update(message) -> dict:\n",
    "        try:\n",
    "            data = message\n",
    "            if isinstance(message, (bytes, str)): data = json.loads(message)\n",
    "        except Exception: data = message\n",
    "        d = data.get('data') if isinstance(data, dict) and isinstance(data.get('data'), dict) else (data if isinstance(data, dict) else {})\n",
    "        flat = {\n",
    "            'ts': d.get('order_timestamp') or d.get('exchange_timestamp') or int(time.time()*1000),\n",
    "            'order_id': d.get('order_id') or d.get('id') or d.get('orderId'),\n",
    "            'status': (d.get('status') or '').lower(),\n",
    "            'filled_quantity': d.get('filled_quantity') or d.get('filledQuantity') or d.get('quantity') or 0,\n",
    "            'average_price': d.get('average_price') or d.get('avg_price') or d.get('averagePrice') or None,\n",
    "            'trading_symbol': d.get('trading_symbol') or d.get('tradingsymbol') or d.get('symbol'),\n",
    "            'instrument_token': d.get('instrument_token') or d.get('instrumentKey') or d.get('instrument'),\n",
    "            'transaction_type': d.get('transaction_type') or d.get('side') or d.get('transactionType')\n",
    "        }\n",
    "        return flat\n",
    "\n",
    "    def _on_message(self, message):\n",
    "        upd = self._extract_update(message)\n",
    "        oid = upd.get('order_id'); \n",
    "        if not oid: \n",
    "            if VERBOSE_RECON: print(\"[recon] no order_id:\", message); \n",
    "            return\n",
    "        prev = self.last_seen_fill_qty.get(oid, 0); cur = int(upd.get('filled_quantity') or 0)\n",
    "        self._append_fill_log(upd)\n",
    "        if cur > prev and VERBOSE_RECON: print(f\"[recon] FILL {oid} {prev}->{cur} @ {upd.get('average_price')} status={upd.get('status')}\")\n",
    "        self.last_seen_fill_qty[oid] = max(prev, cur)\n",
    "        cb = globals().get(\"on_upstox_order_update\")\n",
    "        if callable(cb):\n",
    "            try: cb(upd, self.order_meta.get(oid, {}))\n",
    "            except Exception as e: \n",
    "                if VERBOSE_RECON: print(\"[ledger-hook] error:\", e)\n",
    "\n",
    "    def start(self):\n",
    "        self.streamer.on('message', self._on_message)\n",
    "        self.streamer.auto_reconnect(True, 5, 20)\n",
    "        self.streamer.connect()\n",
    "\n",
    "recon = UpstoxPortfolioReconciler(CredentialUpstox.ACCESS_TOKEN) if (UPSDK_AVAILABLE and CredentialUpstox.ACCESS_TOKEN) else None\n",
    "\n",
    "def start_reconciler():\n",
    "    if recon is None:\n",
    "        print(\"Reconciler not initialized (SDK/token missing).\"); return\n",
    "    print(\"Starting Portfolio Stream Feed reconciler…\"); recon.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8123b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def on_upstox_order_update(update: dict, meta: dict):\n",
    "    oid = update.get(\"order_id\")\n",
    "    status = (update.get(\"status\") or \"\").lower()\n",
    "    avg_px = update.get(\"average_price\")\n",
    "    token = meta.get(\"token\") or update.get(\"instrument_token\")\n",
    "    entry_idx = meta.get(\"entry_idx\")\n",
    "    if entry_idx is not None and 0 <= entry_idx < len(TRADE_LOG):\n",
    "        rec = TRADE_LOG[entry_idx]\n",
    "        if rec.get(\"exit_ts\") is None and rec.get(\"entry_price\") and avg_px and status in (\"complete\",\"completed\"):\n",
    "            try: rec[\"entry_price\"] = float(avg_px)\n",
    "            except Exception: pass\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def place_orders(plan: Dict[str, Any], df_enriched: pd.DataFrame, dry_run: bool = True) -> List[Dict[str, Any]]:\n",
    "    results = []\n",
    "    if not plan or \"legs\" not in plan:\n",
    "        return results\n",
    "    plan_meta = plan.get(\"meta\", {})\n",
    "\n",
    "    global _last_order_ts\n",
    "    for leg in plan[\"legs\"]:\n",
    "        token = str(leg[\"token\"])\n",
    "        row = df_enriched.loc[df_enriched[\"Token\"]==token]\n",
    "        if row.empty:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":\"token_not_found\",\"leg\":leg}); continue\n",
    "        row = row.iloc[0]\n",
    "        lot = int(row.get(\"lot_size\") or 0); qty = int(leg.get(\"qty\", 0))\n",
    "        if lot and qty % lot != 0:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":f\"qty_not_multiple_of_lot({lot})\",\"leg\":leg}); continue\n",
    "        if qty <= 0 or qty > MAX_QTY_PER_LEG:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":\"qty_bounds\",\"leg\":leg}); continue\n",
    "\n",
    "        ok_open, reason = _can_open_more(token, qty)\n",
    "        if not ok_open:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":f\"multi_entry_gate:{reason}\",\"leg\":leg}); continue\n",
    "        if ADD_REQUIRES_IMPROVEMENT and not _micro_improved(token, row):\n",
    "            results.append({\"status\":\"rejected\",\"reason\":\"micro_not_improved\",\"leg\":leg}); continue\n",
    "\n",
    "        side = leg[\"side\"].upper()\n",
    "        product_code = PRODUCT_MAP.get(leg.get(\"product\", DEFAULT_PRODUCT), PRODUCT_MAP[DEFAULT_PRODUCT])\n",
    "        best_bid = float(row.get(\"BidP1\")) if np.isfinite(row.get(\"BidP1\", np.nan)) else float(row.get(\"Mid\", 0.0))\n",
    "        best_ask = float(row.get(\"AskP1\")) if np.isfinite(row.get(\"AskP1\", np.nan)) else float(row.get(\"Mid\", 0.0))\n",
    "        tick = float(row.get(\"tick_size\") or 0.05)\n",
    "\n",
    "        now = time.perf_counter()\n",
    "        delay_ms = ORDER_MIN_GAP_MS - (now - _last_order_ts) * 1000.0\n",
    "        if delay_ms > 0: time.sleep(delay_ms / 1000.0)\n",
    "        _last_order_ts = time.perf_counter()\n",
    "        _lat_log(\"order_send\", token=token, side=side, qty=qty, order_type=\"LIMIT\")\n",
    "\n",
    "        if dry_run or (exec_v3 is None):\n",
    "            fill = float(row.get(\"Mid\")) if np.isfinite(row.get(\"Mid\", np.nan)) else float(row.get(\"Ltp\", 0.0))\n",
    "            results.append({\"status\":\"simulated\",\"token\":token,\"qty\":qty,\"side\":side,\"product\":product_code,\n",
    "                            \"order_type\":\"LIMIT\",\"limit_price\":fill, \"fill_price\":fill, \"router_meta\": plan_meta})\n",
    "            pos = open_positions.get(token, {\"qty\": 0, \"side\": side, \"avg_price\": 0.0})\n",
    "            new_qty = pos[\"qty\"] + qty if side == pos[\"side\"] else pos[\"qty\"] - qty\n",
    "            new_avg = (pos[\"avg_price\"]*pos[\"qty\"] + fill*qty)/max(new_qty,1) if new_qty>0 and side==pos[\"side\"] else fill\n",
    "            open_positions[token] = {\"qty\": max(new_qty,0), \"side\": side, \"avg_price\": new_avg}\n",
    "            log_trade_open(token, side, qty, fill, plan_meta, leg.get(\"_row\", {}), order_id=None)\n",
    "            _lat_log(\"order_ack\", token=token)\n",
    "        else:\n",
    "            info = exec_v3.place_order_v3(\n",
    "                instrument_token=token, side=side, quantity=qty,\n",
    "                best_bid=best_bid, best_ask=best_ask, tick_size=tick,\n",
    "                product=PRODUCT_MAP.get(DEFAULT_PRODUCT,\"I\"), validity=\"DAY\",\n",
    "                marketable_limit=True, buffer_ticks=LIMIT_BUFFER_TICKS, tag=\"LLM-ENTRY\"\n",
    "            )\n",
    "            if not info.get(\"ok\"):\n",
    "                results.append({\"status\":\"rejected\",\"reason\":\"v3_place_error\",\"detail\":info}); continue\n",
    "            order_id = info.get(\"order_id\")\n",
    "            fill = float(row.get(\"Mid\") or row.get(\"Ltp\") or 0.0)\n",
    "            pos = open_positions.get(token, {\"qty\": 0, \"side\": side, \"avg_price\": 0.0})\n",
    "            new_qty = pos[\"qty\"] + qty if side == pos[\"side\"] else pos[\"qty\"] - qty\n",
    "            new_avg = (pos[\"avg_price\"]*pos[\"qty\"] + fill*qty)/max(new_qty,1) if new_qty>0 and side==pos[\"side\"] else fill\n",
    "            open_positions[token] = {\"qty\": max(new_qty,0), \"side\": side, \"avg_price\": new_avg}\n",
    "            entry_idx = log_trade_open(token, side, qty, fill, plan_meta, leg.get(\"_row\", {}), order_id=str(order_id))\n",
    "            if recon is not None and order_id:\n",
    "                recon.attach_meta(order_id, {\"entry_idx\": entry_idx, \"token\": token, \"side\": side, \"qty\": qty,\n",
    "                                             \"sent_ts\": info.get(\"sent_ts\"), \"ack_ts\": info.get(\"ack_ts\"), \"tag\": info.get(\"tag\")})\n",
    "            results.append({\"status\":\"placed\",\"order_id\":order_id,\"token\":token,\"qty\":qty,\"side\":side,\"limit_price\":None, \"router_meta\": plan_meta})\n",
    "            _lat_log(\"order_ack\", token=token)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4666d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_strategy(plan: Dict[str, Any], df_enriched: pd.DataFrame) -> Optional[Dict[str, Any]]:\n",
    "    if not plan or not plan.get(\"legs\"): return None\n",
    "    if len(plan[\"legs\"]) > MAX_OPEN_LEGS: return None\n",
    "    for leg in plan[\"legs\"]:\n",
    "        t = str(leg[\"token\"])\n",
    "        if df_enriched.loc[df_enriched[\"Token\"]==t].empty: return None\n",
    "    return plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2502b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if SIMULATION_MODE:\n",
    "    raise RuntimeError(\"This notebook is live-first. Set SIMULATION_MODE=False to proceed.\")\n",
    "\n",
    "tokens_with_spot = list(dict.fromkeys(token_list + [UNDERLYING_SPOT_TOKEN]))\n",
    "streamer = start_live_stream(tokens_with_spot, mode=WEBSOCKET_MODE)\n",
    "time.sleep(3.0)\n",
    "\n",
    "with _df_lock:\n",
    "    snapshot = df_feed_enriched.copy()\n",
    "print(\"Feed snapshot rows:\", len(snapshot))\n",
    "display(snapshot.tail(6))\n",
    "\n",
    "# Start reconciler (non-blocking)\n",
    "try:\n",
    "    if RECONCILE_LIVE_PNL: start_reconciler()\n",
    "except Exception as _e:\n",
    "    print(\"Reconciler start skipped:\", _e)\n",
    "\n",
    "def latency_report(n_tail: int = 50) -> pd.DataFrame:\n",
    "    return pd.DataFrame(LATENCY_LOG[-n_tail:])\n",
    "\n",
    "def router_report(n_tail: int = 200):\n",
    "    tail = ROUTER_LOG[-n_tail:]\n",
    "    df = pd.DataFrame(tail)\n",
    "    if df.empty: return df, {}\n",
    "    agree = (df[\"stub_decision\"] == df[\"final_decision\"]).mean()\n",
    "    used_ollama_rate = df[\"used_ollama\"].mean()\n",
    "    avg_stub = df[\"stub_ms\"].mean()\n",
    "    avg_ollama = df.loc[df[\"used_ollama\"], \"ollama_ms\"].mean() if (df[\"used_ollama\"].any()) else float(\"nan\")\n",
    "    routes = df[\"route\"].value_counts().to_dict()\n",
    "    summary = {\"n\": int(len(df)), \"agreement_rate\": float(round(agree, 4)), \"used_ollama_rate\": float(round(used_ollama_rate, 4)),\n",
    "               \"avg_stub_ms\": float(round(avg_stub, 2)), \"avg_ollama_ms\": float(round(avg_ollama, 2)) if avg_ollama == avg_ollama else None, \"routes\": routes}\n",
    "    return df, summary\n",
    "\n",
    "_lat_log(\"decision_start\", rows=len(snapshot))\n",
    "plan = ask_llm_for_strategy(snapshot, use_mock=True)  # router inside\n",
    "_lat_log(\"decision_end\", legs=len(plan.get(\"legs\", [])))\n",
    "\n",
    "try:\n",
    "    _lat_log(\"validate_start\")\n",
    "    validated = validate_strategy(plan, snapshot)\n",
    "    _lat_log(\"validate_end\", ok=True)\n",
    "except Exception as e:\n",
    "    validated = None; _lat_log(\"validate_end\", ok=False, err=str(e)); print(\"Validation failed:\", e)\n",
    "\n",
    "orders = []\n",
    "if validated:\n",
    "    _lat_log(\"place_start\", nlegs=len(validated[\"legs\"]))\n",
    "    orders = place_orders(validated, snapshot, dry_run=(not ORDERS_LIVE))\n",
    "    _lat_log(\"place_end\", norders=len(orders))\n",
    "    print(\"Order results:\"); print(json.dumps(orders, indent=2))\n",
    "\n",
    "cfg = ExitConfig(dry_run=(not EXIT_MANAGER_LIVE))\n",
    "start_exit_manager(cfg)\n",
    "\n",
    "_recenter_thread = threading.Thread(target=recenter_daemon, daemon=True); _recenter_thread.start()\n",
    "\n",
    "print(\"Live scalper pipeline running. Use the Stop cell to close sockets and exit manager.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f86adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with _df_lock:\n",
    "    mon = df_feed_enriched.copy()\n",
    "display(mon.tail(12))\n",
    "\n",
    "if not mon.empty:\n",
    "    mon[\"dist\"] = (mon[\"Mid\"] - mon[\"strike_price\"]).abs()\n",
    "    picks = mon.sort_values([\"dist\"]).groupby(\"instrument_type\").head(2)\n",
    "    rows = []\n",
    "    for _, r in picks.iterrows():\n",
    "        ok_sell, why_sell, ex = eligible_entry(r, side=\"SELL\")\n",
    "        rows.append({\"tsym\": r.get(\"trading_symbol\",\"\"), \"type\": r.get(\"instrument_type\",\"\"), \"mid\": r.get(\"Mid\"),\n",
    "                     \"spread\": r.get(\"Spread\"), \"depthImb\": r.get(\"DepthImb\"), \"delta\": r.get(\"Delta\"),\n",
    "                     \"iv\": r.get(\"Iv\"), \"ok_sell\": ok_sell, \"why_sell\": why_sell, \"iv_z\": ex.get(\"iv_z\")})\n",
    "    display(pd.DataFrame(rows))\n",
    "else:\n",
    "    print(\"No feed yet.\")\n",
    "\n",
    "df_router, router_summary = router_report(500)\n",
    "display(df_router.tail(10))\n",
    "print(\"Router summary:\", router_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca470a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def router_performance_report():\n",
    "    df = pd.DataFrame([r for r in TRADE_LOG if r.get(\"exit_ts\") is not None])\n",
    "    if df.empty:\n",
    "        return df, {}, pd.DataFrame(), {}\n",
    "    df[\"hit\"] = (df[\"exit_reason\"]==\"target\").astype(int)\n",
    "    df[\"pnl_pct\"] = df[\"pnl_pct\"].astype(float)\n",
    "    grp = df.groupby(\"router_route\", dropna=False)\n",
    "\n",
    "    def _agg_expect(g):\n",
    "        win = g[g[\"pnl_pct\"]>0][\"pnl_pct\"].mean()\n",
    "        loss = (-g[g[\"pnl_pct\"]<0][\"pnl_pct\"]).mean()\n",
    "        win_rate = (g[\"pnl_pct\"]>0).mean()\n",
    "        exp = g[\"pnl_pct\"].mean()\n",
    "        return pd.Series({\n",
    "            \"n\": len(g),\n",
    "            \"hit_rate\": g[\"hit\"].mean(),\n",
    "            \"win_rate\": win_rate,\n",
    "            \"avg_win_pct\": win if pd.notna(win) else 0.0,\n",
    "            \"avg_loss_pct\": loss if pd.notna(loss) else 0.0,\n",
    "            \"expectancy_pct\": exp,\n",
    "            \"volatility_pct\": g[\"pnl_pct\"].std(),\n",
    "            \"avg_hold_s\": g[\"hold_s\"].mean()\n",
    "        })\n",
    "\n",
    "    perf = grp.apply(_agg_expect).reset_index()\n",
    "\n",
    "    def _max_drawdown(series):\n",
    "        if series.empty: return 0.0\n",
    "        cum = series.cumsum()\n",
    "        peak = cum.cummax()\n",
    "        dd = (cum - peak)\n",
    "        return float(dd.min())\n",
    "\n",
    "    df_sorted = df.sort_values(\"exit_ts\")\n",
    "    df_sorted[\"pnl_pct\"].fillna(0.0, inplace=True)\n",
    "    overall_mdd = _max_drawdown(df_sorted[\"pnl_pct\"])\n",
    "    route_mdd = df_sorted.groupby(\"router_route\")[\"pnl_pct\"].apply(_max_drawdown).to_dict()\n",
    "\n",
    "    dd_summary = {\"overall_max_drawdown_pct\": overall_mdd, \"per_route_max_drawdown_pct\": route_mdd}\n",
    "    return df, perf, df_sorted, dd_summary\n",
    "\n",
    "def _time_bucket(ts):\n",
    "    if pd.isna(ts): return \"unknown\"\n",
    "    t = ts.tz_convert(IST).time() if ts.tzinfo else ts.tz_localize(IST).time()\n",
    "    if t >= pd.to_datetime(\"09:15\").time() and t < pd.to_datetime(\"10:00\").time():\n",
    "        return \"open\"\n",
    "    if t >= pd.to_datetime(\"14:30\").time() and t <= pd.to_datetime(\"15:30\").time():\n",
    "        return \"close\"\n",
    "    return \"mid\"\n",
    "\n",
    "def _iv_regime(z):\n",
    "    if pd.isna(z): return \"unknown\"\n",
    "    a = abs(float(z))\n",
    "    if a <= 1.0: return \"stable\"\n",
    "    if a <= 2.0: return \"elevated\"\n",
    "    return \"spike\"\n",
    "\n",
    "def regime_report():\n",
    "    df = pd.DataFrame([r for r in TRADE_LOG if r.get(\"exit_ts\") is not None])\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    df[\"time_bucket\"] = df[\"entry_ts\"].apply(_time_bucket)\n",
    "    df[\"iv_regime\"] = df[\"entry_iv_z\"].apply(_iv_regime)\n",
    "    df[\"hit\"] = (df[\"exit_reason\"]==\"target\").astype(int)\n",
    "    grp = df.groupby([\"router_route\",\"time_bucket\",\"iv_regime\"], dropna=False)\n",
    "    out = grp.agg(n=(\"hit\",\"count\"),\n",
    "                  hit_rate=(\"hit\",\"mean\"),\n",
    "                  expectancy_pct=(\"pnl_pct\",\"mean\"),\n",
    "                  volatility_pct=(\"pnl_pct\",\"std\")).reset_index().sort_values([\"router_route\",\"time_bucket\",\"iv_regime\"])\n",
    "    return out\n",
    "\n",
    "df_trades, perf, df_sorted, dd = router_performance_report()\n",
    "display(df_trades.tail(10))\n",
    "print(\"Performance by route:\"); display(perf)\n",
    "print(\"Drawdown summary:\", dd)\n",
    "\n",
    "regime_perf = regime_report()\n",
    "print(\"Regime segmentation (route × time × IV-regime):\"); display(regime_perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_exit_manager()\n",
    "stop_live_stream()\n",
    "print(\"Shutdown requested.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
