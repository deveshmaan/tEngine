{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d84dcf",
   "metadata": {},
   "source": [
    "\n",
    "# `upstox_19sep_v4.ipynb` — **Buy-Only NIFTY Intraday Scalper**\n",
    "Live‑first engine with NIFTY spot anchor, Greeks, IV‑z gating, marketable‑limit **V3**, live reconciliation, HTTP backfill, **buy‑only planner**, and **protective broker‑resident stops**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, time, threading, math, traceback, uuid, re\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "try:\n",
    "    import upstox_client\n",
    "    from upstox_client.rest import ApiException\n",
    "    UPSDK_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    UPSDK_AVAILABLE = False\n",
    "    print(\"Upstox SDK not available. Install to run live streaming and orders.\")\n",
    "    print(\"pip install upstox-python-sdk  # confirm exact package per Upstox docs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Toggles & constants ----\n",
    "SIMULATION_MODE = False\n",
    "USE_LLM = True\n",
    "USE_ROUTER = True\n",
    "\n",
    "ORDERS_LIVE = False\n",
    "EXIT_MANAGER_LIVE = False\n",
    "RECONCILE_LIVE_PNL = True\n",
    "BACKFILL_ENABLED = True\n",
    "\n",
    "UNDERLYING = \"NIFTY\"\n",
    "UNDERLYING_SPOT_TOKEN = \"NSE_INDEX|Nifty 50\"\n",
    "SPAN_STRIKES = 2\n",
    "WEBSOCKET_MODE = \"full_d30\"\n",
    "IST = \"Asia/Kolkata\"\n",
    "\n",
    "STRIKE_STEP = {\"NIFTY\": 50, \"BANKNIFTY\": 100, \"FINNIFTY\": 50}\n",
    "MAX_QTY_PER_LEG = 300\n",
    "MAX_OPEN_LEGS = 3\n",
    "\n",
    "RECENTER_COOLDOWN_S = 60.0\n",
    "RECENTER_LOG = True\n",
    "\n",
    "# Buy-only scalper gates\n",
    "DELTA_MIN, DELTA_MAX = 0.35, 0.55\n",
    "DEPTH_IMB_MIN = 0.15\n",
    "IV_Z_MAX = 2.0\n",
    "IV_Z_MIN_COUNT = 30\n",
    "\n",
    "# Execution\n",
    "USE_MARKETABLE_LIMITS = True\n",
    "LIMIT_BUFFER_TICKS = 1\n",
    "ORDER_MIN_GAP_MS = 200\n",
    "\n",
    "# LLM + Router (optional)\n",
    "LLM_ENDPOINT = os.getenv(\"LLM_ENDPOINT\", \"\")  # stub\n",
    "LLM_TIMEOUT_S = float(os.getenv(\"LLM_TIMEOUT_S\", \"0.12\"))\n",
    "OLLAMA_HOST = os.getenv(\"OLLAMA_HOST\", \"http://127.0.0.1:11434\")\n",
    "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"\")\n",
    "OLLAMA_TIMEOUT_S = float(os.getenv(\"OLLAMA_TIMEOUT_S\", \"0.20\"))\n",
    "OLLAMA_NUM_PREDICT = int(os.getenv(\"OLLAMA_NUM_PREDICT\", \"16\"))\n",
    "LLM_SCORE_THRESHOLD = 0.55\n",
    "STUB_LOWER, STUB_UPPER = 0.35, 0.75\n",
    "\n",
    "LATENCY_LOG = []; LATENCY_LOG_MAX = 5000\n",
    "ROUTER_LOG = []; ROUTER_LOG_MAX = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CredentialUpstox:\n",
    "    ACCESS_TOKEN = os.getenv(\"UPSTOX_ACCESS_TOKEN\", \"\")\n",
    "\n",
    "PRODUCT_MAP = {\"MIS\": \"I\", \"NRML\": \"D\"}\n",
    "DEFAULT_PRODUCT = \"MIS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_ist_ms(ms) -> pd.Timestamp:\n",
    "    try:\n",
    "        return pd.to_datetime(int(ms), unit=\"ms\", utc=True).tz_convert(IST)\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def resolve_next_listed_expiry(df_instruments: pd.DataFrame, underlying: str, today=None) -> str:\n",
    "    t = pd.Timestamp.now(IST).normalize() if today is None else pd.Timestamp(today, tz=IST).normalize()\n",
    "    dfx = df_instruments[(df_instruments[\"segment\"] == \"NSE_FO\") &\n",
    "                         (df_instruments[\"name\"].str.upper() == underlying.upper()) &\n",
    "                         (df_instruments[\"instrument_type\"].isin([\"CE\",\"PE\"]))].copy()\n",
    "    if dfx.empty: raise ValueError(f\"No derivatives found for {underlying} in instruments master\")\n",
    "    dfx[\"_exp\"] = pd.to_datetime(dfx[\"expiry\"], errors=\"coerce\")\n",
    "    dfx = dfx[dfx[\"_exp\"] >= t.tz_localize(None)]\n",
    "    if dfx.empty: raise ValueError(f\"No upcoming expiry >= {t.date()} for {underlying}\")\n",
    "    return dfx[\"_exp\"].min().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def nearest_strikes_from_spot(spot_ltp: float, underlying: str, span: int = 2):\n",
    "    step = STRIKE_STEP.get(underlying.upper(), 50)\n",
    "    nearest = int(step * math.floor((spot_ltp + step/2) / step))\n",
    "    return [nearest + i * step for i in range(-span, span+1)]\n",
    "\n",
    "def get_upstox_quote_client():\n",
    "    if not UPSDK_AVAILABLE: raise RuntimeError(\"Upstox SDK is not available.\")\n",
    "    if not CredentialUpstox.ACCESS_TOKEN: raise RuntimeError(\"ACCESS_TOKEN missing. Set UPSTOX_ACCESS_TOKEN.\")\n",
    "    configuration = upstox_client.Configuration(); configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n",
    "    return upstox_client.MarketQuoteV3Api(upstox_client.ApiClient(configuration))\n",
    "\n",
    "def _extract_ltp_from_entry(entry: dict) -> float:\n",
    "    if not isinstance(entry, dict): raise KeyError(\"Invalid LTP entry\")\n",
    "    for k in (\"ltp\",\"last_traded_price\",\"last\",\"close\",\"price\"):\n",
    "        if k in entry and entry[k] is not None: return float(entry[k])\n",
    "    if \"ltpc\" in entry and isinstance(entry[\"ltpc\"], dict) and \"ltp\" in entry[\"ltpc\"]:\n",
    "        return float(entry[\"ltpc\"][\"ltp\"])\n",
    "    raise KeyError(f\"No LTP field found in entry keys={list(entry.keys())}\")\n",
    "\n",
    "def get_index_spot_ltp(instrument_key: str = None) -> float:\n",
    "    instrument_key = instrument_key or UNDERLYING_SPOT_TOKEN\n",
    "    api = get_upstox_quote_client()\n",
    "    try:\n",
    "        api_response = api.get_ltp(instrument_key=[instrument_key] if not isinstance(instrument_key, list) else instrument_key)\n",
    "        data_dict = api_response.to_dict() if hasattr(api_response, \"to_dict\") else dict(api_response)\n",
    "        data = data_dict.get(\"data\", {})\n",
    "        entry = data.get(instrument_key) or (next(iter(data.values())) if data else {})\n",
    "        ltp = _extract_ltp_from_entry(entry)\n",
    "        if not np.isfinite(ltp): raise RuntimeError(f\"LTP non-finite: {ltp}\")\n",
    "        return float(ltp)\n",
    "    except ApiException as e:\n",
    "        raise RuntimeError(f\"Upstox get_ltp ApiException: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2149c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_instruments_live() -> pd.DataFrame:\n",
    "    url = \"https://assets.upstox.com/market-quote/instruments/exchange/NSE.json.gz\"\n",
    "    df = pd.read_json(url)\n",
    "    if \"expiry\" in df:\n",
    "        exp = pd.to_datetime(df[\"expiry\"], unit=\"ms\", errors=\"coerce\")\n",
    "        mask = exp.isna() & df[\"expiry\"].notna()\n",
    "        if mask.any():\n",
    "            exp2 = pd.to_datetime(df.loc[mask, \"expiry\"], errors=\"coerce\")\n",
    "            exp.loc[mask] = exp2\n",
    "        df[\"expiry\"] = exp.dt.strftime(\"%Y-%m-%d\")\n",
    "    for col in (\"strike_price\",\"lot_size\",\"tick_size\",\"minimum_lot\"):\n",
    "        if col in df: df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "df_futureOptions = load_instruments_live()\n",
    "expiry_target = resolve_next_listed_expiry(df_futureOptions, UNDERLYING)\n",
    "df_chain = df_futureOptions[(df_futureOptions[\"segment\"]==\"NSE_FO\") &\n",
    "                            (df_futureOptions[\"name\"].str.upper()==UNDERLYING.upper()) &\n",
    "                            (df_futureOptions[\"instrument_type\"].isin([\"CE\",\"PE\"])) &\n",
    "                            (df_futureOptions[\"expiry\"]==expiry_target)].copy()\n",
    "assert not df_chain.empty, f\"No options for {UNDERLYING} {expiry_target}\"\n",
    "\n",
    "try:\n",
    "    spot_ltp_initial = get_index_spot_ltp(UNDERLYING_SPOT_TOKEN)\n",
    "    print(f\"NIFTY 50 spot LTP: {spot_ltp_initial:.2f}\")\n",
    "except Exception as e:\n",
    "    print(\"Spot LTP lookup failed; fallback to chain median:\", e)\n",
    "    spot_ltp_initial = float(df_chain[\"strike_price\"].median())\n",
    "\n",
    "strike_list = nearest_strikes_from_spot(spot_ltp_initial, UNDERLYING, span=SPAN_STRIKES)\n",
    "df_chain_sel = df_chain[df_chain[\"strike_price\"].isin(strike_list)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "token_list = df_chain_sel[\"instrument_key\"].dropna().astype(str).unique().tolist()\n",
    "print(f\"Selected strikes from spot {spot_ltp_initial:.2f}: {sorted(set(strike_list))}\")\n",
    "display(df_chain_sel.head(8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_feed = pd.DataFrame(columns=[\n",
    "    \"Token\",\"Ltp\",\"Ltq\",\"Cp\",\n",
    "    \"BidP1\",\"BidQ1\",\"AskP1\",\"AskQ1\",\n",
    "    \"Ltt\",\"Oi\",\"Iv\",\"Atp\",\"Tbq\",\"Tsq\",\n",
    "    \"Delta\",\"Theta\",\"Gamma\",\"Vega\",\"Rho\"\n",
    "])\n",
    "df_feed_enriched = pd.DataFrame()\n",
    "_df_lock = threading.Lock()\n",
    "\n",
    "def enrich_feed(_df_feed: pd.DataFrame, _df_meta: pd.DataFrame, cols_to_add=None) -> pd.DataFrame:\n",
    "    if cols_to_add is None:\n",
    "        cols_to_add = [\"lot_size\",\"trading_symbol\",\"strike_price\",\"tick_size\",\"instrument_type\",\"expiry\",\"name\"]\n",
    "    left = _df_feed.copy()\n",
    "    right = _df_meta[[\"instrument_key\"] + [c for c in cols_to_add if c in _df_meta.columns]].drop_duplicates(\"instrument_key\")\n",
    "    out = left.merge(right, left_on=\"Token\", right_on=\"instrument_key\", how=\"left\", validate=\"m:1\")\n",
    "    out[\"Mid\"] = np.where(out[\"BidP1\"].notna() & out[\"AskP1\"].notna(), (out[\"BidP1\"] + out[\"AskP1\"])/2.0, out[\"Ltp\"])\n",
    "    out[\"Spread\"] = np.where(out[\"BidP1\"].notna() & out[\"AskP1\"].notna(), (out[\"AskP1\"] - out[\"BidP1\"]), np.nan)\n",
    "    out[\"DepthImb\"] = np.where(\n",
    "        (out[\"BidQ1\"].notna() & out[\"AskQ1\"].notna() & ((out[\"BidQ1\"] + out[\"AskQ1\"]) > 0)),\n",
    "        (out[\"BidQ1\"] - out[\"AskQ1\"]) / (out[\"BidQ1\"] + out[\"AskQ1\"]),\n",
    "        np.nan,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "from collections import defaultdict\n",
    "_iv_stats = defaultdict(lambda: {\"n\":0, \"mean\":0.0, \"M2\":0.0})\n",
    "def update_iv_stats(token: str, iv_value: float):\n",
    "    if iv_value is None or not np.isfinite(iv_value): return\n",
    "    s = _iv_stats[token]\n",
    "    n1 = s[\"n\"] + 1\n",
    "    delta = iv_value - s[\"mean\"]\n",
    "    mean = s[\"mean\"] + delta / n1\n",
    "    delta2 = iv_value - mean\n",
    "    M2 = s[\"M2\"] + delta * delta2\n",
    "    s[\"n\"], s[\"mean\"], s[\"M2\"] = n1, mean, M2\n",
    "\n",
    "def iv_zscore_for(token: str, iv_value: float):\n",
    "    s = _iv_stats[token]\n",
    "    if s[\"n\"] < max(IV_Z_MIN_COUNT, 2):\n",
    "        return 0.0, True\n",
    "    var = s[\"M2\"] / max(s[\"n\"] - 1, 1)\n",
    "    std = math.sqrt(max(var, 1e-12))\n",
    "    z = (iv_value - s[\"mean\"]) / std if std > 0 else 0.0\n",
    "    return z, (abs(z) <= IV_Z_MAX)\n",
    "\n",
    "live_streamer = None\n",
    "current_tokens = list(token_list)\n",
    "spot_ltp_current = spot_ltp_initial\n",
    "last_center_nearest = int(STRIKE_STEP[UNDERLYING] * math.floor((spot_ltp_initial + STRIKE_STEP[UNDERLYING]/2)/STRIKE_STEP[UNDERLYING]))\n",
    "_last_recenter_ts = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start_live_stream(tokens: List[str], mode: str = \"full_d30\"):\n",
    "    global live_streamer\n",
    "    if not UPSDK_AVAILABLE: raise RuntimeError(\"Upstox SDK not installed.\")\n",
    "    if not CredentialUpstox.ACCESS_TOKEN: raise RuntimeError(\"ACCESS_TOKEN missing.\")\n",
    "\n",
    "    configuration = upstox_client.Configuration()\n",
    "    configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n",
    "    api_client = upstox_client.ApiClient(configuration)\n",
    "    streamer = upstox_client.MarketDataStreamerV3(api_client, instrument_key=tokens, mode=mode)\n",
    "\n",
    "    def _on_message(msg):\n",
    "        global df_feed, df_feed_enriched, spot_ltp_current\n",
    "        feeds = msg.get(\"feeds\", {})\n",
    "        for token, payload in feeds.items():\n",
    "            ff = payload.get(\"fullFeed\",{}).get(\"marketFF\",{})\n",
    "            ltpc = ff.get(\"ltpc\",{})\n",
    "            level = ff.get(\"marketLevel\",{}).get(\"bidAskQuote\",[{}])\n",
    "            greeks = ff.get(\"optionGreeks\",{}) or {}\n",
    "            if token == UNDERLYING_SPOT_TOKEN:\n",
    "                try:\n",
    "                    if ltpc.get(\"ltp\") is not None:\n",
    "                        spot_ltp_current = float(ltpc.get(\"ltp\"))\n",
    "                except Exception: pass\n",
    "                continue\n",
    "            try:\n",
    "                iv_val = ff.get(\"iv\")\n",
    "                if iv_val is not None:\n",
    "                    update_iv_stats(token, float(iv_val))\n",
    "            except Exception: pass\n",
    "            row = {\n",
    "                \"Token\": token,\n",
    "                \"Ltp\": float(ltpc.get(\"ltp\")) if ltpc.get(\"ltp\") is not None else np.nan,\n",
    "                \"Ltq\": float(ltpc.get(\"ltq\")) if ltpc.get(\"ltq\") is not None else np.nan,\n",
    "                \"Cp\": float(ltpc.get(\"cp\")) if ltpc.get(\"cp\") is not None else np.nan,\n",
    "                \"BidP1\": float(level[0].get(\"bidP\")) if level and level[0].get(\"bidP\") is not None else np.nan,\n",
    "                \"BidQ1\": float(level[0].get(\"bidQ\")) if level and level[0].get(\"bidQ\") is not None else np.nan,\n",
    "                \"AskP1\": float(level[0].get(\"askP\")) if level and level[0].get(\"askP\") is not None else np.nan,\n",
    "                \"AskQ1\": float(level[0].get(\"askQ\")) if level and level[0].get(\"askQ\") is not None else np.nan,\n",
    "                \"Ltt\": to_ist_ms(ltpc.get(\"ltt\")),\n",
    "                \"Oi\": float(ff.get(\"oi\")) if ff.get(\"oi\") is not None else np.nan,\n",
    "                \"Iv\": float(ff.get(\"iv\")) if ff.get(\"iv\") is not None else np.nan,\n",
    "                \"Atp\": float(ff.get(\"atp\")) if ff.get(\"atp\") is not None else np.nan,\n",
    "                \"Tbq\": float(ff.get(\"tbq\")) if ff.get(\"tbq\") is not None else np.nan,\n",
    "                \"Tsq\": float(ff.get(\"tsq\")) if ff.get(\"tsq\") is not None else np.nan,\n",
    "                \"Delta\": float(greeks.get(\"delta\")) if greeks.get(\"delta\") is not None else np.nan,\n",
    "                \"Theta\": float(greeks.get(\"theta\")) if greeks.get(\"theta\") is not None else np.nan,\n",
    "                \"Gamma\": float(greeks.get(\"gamma\")) if greeks.get(\"gamma\") is not None else np.nan,\n",
    "                \"Vega\":  float(greeks.get(\"vega\"))  if greeks.get(\"vega\")  is not None else np.nan,\n",
    "                \"Rho\":   float(greeks.get(\"rho\"))   if greeks.get(\"rho\")   is not None else np.nan,\n",
    "            }\n",
    "            with _df_lock:\n",
    "                if token in df_feed[\"Token\"].values:\n",
    "                    for k,v in row.items(): df_feed.loc[df_feed[\"Token\"]==token, k] = v\n",
    "                else:\n",
    "                    df_feed = pd.concat([df_feed, pd.DataFrame([row])], ignore_index=True)\n",
    "                df_feed_enriched = enrich_feed(df_feed, df_chain)\n",
    "\n",
    "    streamer.on_message = _on_message\n",
    "    streamer.on_open = lambda: print(\"Market WS opened\")\n",
    "    streamer.on_error = lambda e: print(\"Market WS error:\", e)\n",
    "    streamer.on_close = lambda: print(\"Market WS closed\")\n",
    "    streamer.connect()\n",
    "    live_streamer = streamer\n",
    "    return streamer\n",
    "\n",
    "def stop_live_stream():\n",
    "    global live_streamer\n",
    "    try:\n",
    "        if live_streamer is not None:\n",
    "            if hasattr(live_streamer, \"close\"): live_streamer.close()\n",
    "            elif hasattr(live_streamer, \"disconnect\"): live_streamer.disconnect()\n",
    "            elif hasattr(live_streamer, \"ws\"): live_streamer.ws.close()\n",
    "            print(\"Market stream stop requested.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error stopping stream:\", e)\n",
    "    finally:\n",
    "        live_streamer = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67221a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_token_list_for_spot(spot_ltp: float):\n",
    "    strikes = nearest_strikes_from_spot(spot_ltp, UNDERLYING, span=SPAN_STRIKES)\n",
    "    df_sel = df_chain[df_chain[\"strike_price\"].isin(strikes)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "    tokens = df_sel[\"instrument_key\"].dropna().astype(str).unique().tolist()\n",
    "    return tokens\n",
    "\n",
    "def maybe_recenter_tokens():\n",
    "    global last_center_nearest, _last_recenter_ts, current_tokens, df_chain_sel\n",
    "    # Defer recenter while positions are open to avoid churn during risk\n",
    "    try:\n",
    "        if any(v.get(\"qty\",0)>0 for v in open_positions.values()):\n",
    "            return False\n",
    "    except Exception:\n",
    "        pass\n",
    "    step = STRIKE_STEP.get(UNDERLYING.upper(), 50)\n",
    "    nearest = int(step * math.floor((spot_ltp_current + step/2)/step))\n",
    "    now = time.time()\n",
    "    if abs(nearest - last_center_nearest) >= step and (now - _last_recenter_ts) >= RECENTER_COOLDOWN_S:\n",
    "        try:\n",
    "            new_tokens = compute_token_list_for_spot(spot_ltp_current)\n",
    "            if not new_tokens: return False\n",
    "            tokens_with_spot = list(dict.fromkeys(new_tokens + [UNDERLYING_SPOT_TOKEN]))\n",
    "            if RECENTER_LOG:\n",
    "                print(f\"[RECENTER] spot={spot_ltp_current:.2f}, nearest={nearest}, old_center={last_center_nearest}\")\n",
    "                print(f\"[RECENTER] tokens: {len(current_tokens)} → {len(new_tokens)}\")\n",
    "            stop_live_stream(); start_live_stream(tokens_with_spot, mode=WEBSOCKET_MODE)\n",
    "            last_center_nearest = nearest; _last_recenter_ts = now; current_tokens = new_tokens\n",
    "            df_chain_sel = df_chain[df_chain[\"instrument_key\"].isin(new_tokens)].sort_values([\"strike_price\",\"instrument_type\"])\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(\"Recenter failed:\", e); traceback.print_exc()\n",
    "    return False\n",
    "\n",
    "def recenter_daemon():\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(1.0); maybe_recenter_tokens()\n",
    "        except Exception:\n",
    "            time.sleep(2.0); continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _compact_row(r: pd.Series):\n",
    "    return {\n",
    "        \"token\": str(r[\"Token\"]),\n",
    "        \"tsym\": str(r.get(\"trading_symbol\", \"\")),\n",
    "        \"mid\": float(r.get(\"Mid\", np.nan)),\n",
    "        \"spread\": float(r.get(\"Spread\", np.nan)),\n",
    "        \"delta\": float(r.get(\"Delta\", np.nan)),\n",
    "        \"gamma\": float(r.get(\"Gamma\", np.nan)),\n",
    "        \"theta\": float(r.get(\"Theta\", np.nan)),\n",
    "        \"iv\": float(r.get(\"Iv\", np.nan)),\n",
    "        \"depthImb\": float(r.get(\"DepthImb\", np.nan)),\n",
    "        \"strike\": float(r.get(\"strike_price\", np.nan)),\n",
    "        \"type\": str(r.get(\"instrument_type\",\"\")),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _router_log(entry: dict):\n",
    "    entry = dict(entry); entry.setdefault(\"t\", time.perf_counter())\n",
    "    ROUTER_LOG.append(entry)\n",
    "    if len(ROUTER_LOG) > ROUTER_LOG_MAX:\n",
    "        del ROUTER_LOG[: len(ROUTER_LOG) - ROUTER_LOG_MAX]\n",
    "\n",
    "def _post_stub(context: dict):\n",
    "    t0 = time.perf_counter()\n",
    "    if not LLM_ENDPOINT:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.post(LLM_ENDPOINT, json=context, timeout=LLM_TIMEOUT_S)\n",
    "        s = float(r.json().get(\"score\", 0.6)) if r.ok else 0.6\n",
    "        return max(0.0, min(1.0, s)), (time.perf_counter() - t0)*1000.0, True\n",
    "    except Exception:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False\n",
    "\n",
    "def _post_ollama(context: dict):\n",
    "    t0 = time.perf_counter()\n",
    "    if not OLLAMA_MODEL:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False\n",
    "    try:\n",
    "        import requests\n",
    "        prompt = (\n",
    "           \"You are a buy-only NIFTY options scalping scorer. Return JSON {\"decision\": one of ['buy_ce','buy_pe','pass'], \"score\": [0,1]}\\n\"\n",
    "           \"No explanation. Focus on mid/spread/Δ/Γ/Θ/iv/depthImb + spot trend.\\n\"\n",
    "        )\n",
    "        payload = {\"model\": OLLAMA_MODEL, \"prompt\": prompt + json.dumps(context), \"stream\": False,\n",
    "                   \"options\": {\"temperature\": 0.1, \"num_predict\": OLLAMA_NUM_PREDICT}, \"format\": \"json\"}\n",
    "        r = requests.post(f\"{OLLAMA_HOST}/api/generate\", json=payload, timeout=OLLAMA_TIMEOUT_S)\n",
    "        txt = r.json().get(\"response\",\"\") if r.ok else \"\"\n",
    "        try:\n",
    "            obj = json.loads(txt)\n",
    "            s = float(obj.get(\"score\", 0.6))\n",
    "            d = str(obj.get(\"decision\",\"pass\"))\n",
    "        except Exception:\n",
    "            s, d = 0.6, \"pass\"\n",
    "        return max(0.0, min(1.0, s)), (time.perf_counter() - t0)*1000.0, True, d\n",
    "    except Exception:\n",
    "        return 0.6, (time.perf_counter() - t0)*1000.0, False, \"pass\"\n",
    "\n",
    "def score_with_router_and_meta_long_only(context: dict):\n",
    "    thr = LLM_SCORE_THRESHOLD\n",
    "    context[\"mode\"] = \"long_only\"\n",
    "    stub_score, stub_ms, stub_ok = _post_stub(context)\n",
    "    route = \"no_stub\"; ollama_score = None; ollama_ms = 0.0; decision = \"pass\"\n",
    "\n",
    "    if stub_ok and (STUB_LOWER < stub_score < STUB_UPPER):\n",
    "        o_score, o_ms, o_ok, decision = _post_ollama(context)\n",
    "        if o_ok:\n",
    "            final_score = o_score; route = \"gray_ollama\"\n",
    "        else:\n",
    "            final_score = stub_score; route = \"gray_fallback_stub\"; decision = \"pass\"\n",
    "        ollama_score, ollama_ms = o_score, o_ms\n",
    "    else:\n",
    "        final_score = stub_score\n",
    "        route = \"stub_high\" if stub_score >= STUB_UPPER else (\"stub_low\" if stub_score <= STUB_LOWER else \"stub_neutral\")\n",
    "        decision = \"pass\"\n",
    "\n",
    "    final_decision = (final_score >= thr)\n",
    "    entry = {\"route\": route, \"stub_score\": stub_score, \"stub_ms\": round(stub_ms, 2),\n",
    "             \"ollama_score\": ollama_score, \"ollama_ms\": round(ollama_ms, 2),\n",
    "             \"final_score\": final_score, \"final_decision\": final_decision, \"used_ollama\": (route==\"gray_ollama\"),\n",
    "             \"decision\": decision}\n",
    "    _router_log(entry)\n",
    "    return float(final_score), entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_llm_for_strategy_buy_only(df_snapshot: pd.DataFrame) -> Dict[str, Any]:\n",
    "    if df_snapshot.empty:\n",
    "        return {\"legs\": [], \"meta\": {\"reason\": \"empty_snapshot\"}}\n",
    "\n",
    "    cols = [\"Mid\",\"strike_price\",\"instrument_type\",\"Delta\",\"Spread\",\"tick_size\",\"DepthImb\",\"Iv\",\"Token\",\"lot_size\"]\n",
    "    miss = [c for c in cols if c not in df_snapshot.columns]\n",
    "    if miss:\n",
    "        return {\"legs\": [], \"meta\": {\"reason\": f\"missing_columns:{miss}\"}}\n",
    "\n",
    "    snap = df_snapshot.dropna(subset=[\"Mid\",\"strike_price\",\"instrument_type\",\"Delta\"]).copy()\n",
    "    if snap.empty:\n",
    "        return {\"legs\": [], \"meta\": {\"reason\": \"no_valid_rows\"}}\n",
    "\n",
    "    snap[\"absDeltaGap\"] = (snap[\"Delta\"].abs() - 0.50).abs()\n",
    "\n",
    "    def _spread_ok(r):\n",
    "        tick = float(r.get(\"tick_size\") or 0.05)\n",
    "        spread = float(r.get(\"Spread\") or np.inf)\n",
    "        mid = float(r.get(\"Mid\") or np.nan)\n",
    "        ticks_spread = spread / max(tick,1e-6)\n",
    "        rel_spread = spread / max(mid,1e-9) if np.isfinite(mid) else np.inf\n",
    "        return (ticks_spread <= 3) and (rel_spread <= 0.004)\n",
    "\n",
    "    def _ok_buy_row(r):\n",
    "        if not _spread_ok(r):\n",
    "            return False\n",
    "        if not (DELTA_MIN <= abs(float(r[\"Delta\"])) <= DELTA_MAX):\n",
    "            return False\n",
    "        imb = float(r.get(\"DepthImb\") or 0.0)\n",
    "        if r[\"instrument_type\"]==\"CE\" and imb < +DEPTH_IMB_MIN: return False\n",
    "        if r[\"instrument_type\"]==\"PE\" and imb > -DEPTH_IMB_MIN: return False\n",
    "        z, iv_ok = iv_zscore_for(r[\"Token\"], float(r.get(\"Iv\") or np.nan))\n",
    "        return iv_ok\n",
    "\n",
    "    ce = snap[(snap[\"instrument_type\"]==\"CE\")]\n",
    "    pe = snap[(snap[\"instrument_type\"]==\"PE\")]\n",
    "    ce_ok = ce[ce.apply(_ok_buy_row, axis=1)].sort_values([\"absDeltaGap\",\"Spread\"]).head(1)\n",
    "    pe_ok = pe[pe.apply(_ok_buy_row, axis=1)].sort_values([\"absDeltaGap\",\"Spread\"]).head(1)\n",
    "\n",
    "    pick = None\n",
    "    if not ce_ok.empty and not pe_ok.empty:\n",
    "        pick = ce_ok.iloc[0] if abs(float(ce_ok.iloc[0][\"DepthImb\"])) >= abs(float(pe_ok.iloc[0][\"DepthImb\"])) else pe_ok.iloc[0]\n",
    "    elif not ce_ok.empty:\n",
    "        pick = ce_ok.iloc[0]\n",
    "    elif not pe_ok.empty:\n",
    "        pick = pe_ok.iloc[0]\n",
    "    else:\n",
    "        return {\"legs\": [], \"meta\": {\"reason\": \"no_candidate_passed_filters\"}}\n",
    "\n",
    "    lot = int(pick.get(\"lot_size\") or 50)\n",
    "    leg = {\"token\": str(pick[\"Token\"]), \"side\": \"BUY\", \"qty\": lot, \"product\": DEFAULT_PRODUCT, \"order_type\": \"LIMIT\", \"_row\": pick.to_dict()}\n",
    "    meta = {\"mode\": \"long_only\", \"picked\": pick[\"instrument_type\"]}\n",
    "\n",
    "    # Optional: route with LLM (long-only semantics)\n",
    "    context = {\"spot\": float(spot_ltp_current), \"row\": _compact_row(pick), \"rules\": {\"delta\":[DELTA_MIN, DELTA_MAX], \"ivZmax\":IV_Z_MAX}}\n",
    "    score, router_meta = score_with_router_and_meta_long_only(context)\n",
    "    meta.update({\"score\": score, **router_meta})\n",
    "\n",
    "    if USE_LLM and (score < LLM_SCORE_THRESHOLD):\n",
    "        return {\"legs\": [], \"meta\": meta}\n",
    "    return {\"legs\": [leg], \"meta\": meta}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee355d",
   "metadata": {},
   "source": [
    "## Upstox V3 Execution & Live Reconciliation (buy-only + protective stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e045c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UPSTOX_DOCS_BASE = 'https://upstox.com/developer/api-documentation/orders'\n",
    "UPSTOX_WS_DOCS = 'https://upstox.com/developer/api-documentation/get-portfolio-stream-feed/'\n",
    "VERBOSE_EXEC  = True\n",
    "VERBOSE_RECON = True\n",
    "ORDER_WS_LAST_TS = time.time()\n",
    "\n",
    "class UpstoxV3Exec:\n",
    "    def __init__(self, access_token: str):\n",
    "        self.access_token = access_token\n",
    "        configuration = upstox_client.Configuration(); configuration.access_token = self.access_token\n",
    "        self._api_client = upstox_client.ApiClient(configuration)\n",
    "        self.order_api_v3 = upstox_client.OrderApiV3(self._api_client)\n",
    "\n",
    "    @staticmethod\n",
    "    def _now_ms():\n",
    "        return int(time.time() * 1000)\n",
    "\n",
    "    def marketable_limit(self, best_bid: float, best_ask: float, side: str, tick_size: float, buffer_ticks: int = 1) -> float:\n",
    "        # BUY: ceil; SELL (to close): floor\n",
    "        ts = max(tick_size, 1e-6)\n",
    "        if side.upper() == \"BUY\":\n",
    "            raw = (best_ask + buffer_ticks * ts); ticks = math.ceil(raw/ts)\n",
    "        else:\n",
    "            raw = (best_bid - buffer_ticks * ts); ticks = math.floor(raw/ts)\n",
    "        return float(ticks * ts)\n",
    "\n",
    "    def place_order_v3(self, *, instrument_token: str, side: str, quantity: int,\n",
    "                       best_bid: float, best_ask: float, price: float = None,\n",
    "                       product: str = \"I\", validity: str = \"DAY\", disclosed_quantity: int = 0,\n",
    "                       trigger_price: float = 0.0, is_amo: bool = False,\n",
    "                       marketable_limit: bool = True, buffer_ticks: int = 1,\n",
    "                       tick_size: float = 0.05, tag: str = None) -> dict:\n",
    "        if tag is None:\n",
    "            tag = f\"router-{uuid.uuid4().hex[:8]}\"\n",
    "        if price is None and marketable_limit:\n",
    "            price = self.marketable_limit(best_bid, best_ask, side, tick_size, buffer_ticks)\n",
    "        req = upstox_client.PlaceOrderV3Request(\n",
    "            quantity=int(quantity), product=product, validity=validity, price=float(price if price is not None else 0.0),\n",
    "            tag=tag, instrument_token=instrument_token,\n",
    "            order_type='LIMIT' if price else 'MARKET', transaction_type=side.upper(),\n",
    "            disclosed_quantity=int(disclosed_quantity), trigger_price=float(trigger_price), is_amo=bool(is_amo), slice=False\n",
    "        )\n",
    "        t0 = self._now_ms()\n",
    "        try:\n",
    "            resp = self.order_api_v3.place_order(req)\n",
    "            t1 = self._now_ms()\n",
    "            order_id = None\n",
    "            if hasattr(resp, \"data\") and resp.data:\n",
    "                if isinstance(resp.data, dict) and \"order_id\" in resp.data: order_id = resp.data[\"order_id\"]\n",
    "                elif isinstance(resp.data, dict) and \"order_ids\" in resp.data: \n",
    "                    order_ids = resp.data.get(\"order_ids\") or []; order_id = order_ids[0] if order_ids else None\n",
    "            info = {\"ok\": True, \"order_id\": order_id, \"sent_ts\": t0, \"ack_ts\": t1, \"broker_latency_ms\": (t1 - t0), \"tag\": tag}\n",
    "            if VERBOSE_EXEC: print(\"[V3/place] ok\", info)\n",
    "            return info\n",
    "        except ApiException as e:\n",
    "            t1 = self._now_ms()\n",
    "            err = {\"ok\": False, \"error\": str(e), \"sent_ts\": t0, \"ack_ts\": t1}\n",
    "            print(\"[V3/place] ERROR\", err); return err\n",
    "\n",
    "# Protective stop & cancel helpers\n",
    "def place_stop_exit_v3(self, *, instrument_token: str, exit_side: str, trigger_price: float,\n",
    "                       quantity: int, product: str = \"I\", validity: str = \"DAY\", tag: str = None) -> dict:\n",
    "    req = upstox_client.PlaceOrderV3Request(\n",
    "        quantity=int(quantity), product=product, validity=validity, order_type='SL-M',\n",
    "        trigger_price=float(trigger_price), instrument_token=instrument_token,\n",
    "        transaction_type=exit_side.upper(), tag=(tag or f\"prot-stop-{uuid.uuid4().hex[:8]}\"),\n",
    "        slice=False, is_amo=False\n",
    "    )\n",
    "    t0 = int(time.time()*1000)\n",
    "    try:\n",
    "        resp = self.order_api_v3.place_order(req)\n",
    "        oid = (resp.data or {}).get(\"order_id\") if hasattr(resp, \"data\") else None\n",
    "        return {\"ok\": True, \"order_id\": oid, \"sent_ts\": t0}\n",
    "    except ApiException as e:\n",
    "        return {\"ok\": False, \"error\": str(e), \"sent_ts\": t0}\n",
    "\n",
    "def cancel_order_v3(self, order_id: str) -> dict:\n",
    "    t0 = int(time.time()*1000)\n",
    "    try:\n",
    "        if hasattr(self.order_api_v3, \"cancel_order\"):\n",
    "            resp = self.order_api_v3.cancel_order(order_id)\n",
    "        elif hasattr(self.order_api_v3, \"cancelOrder\"):\n",
    "            resp = self.order_api_v3.cancelOrder(order_id)\n",
    "        else:\n",
    "            raise RuntimeError(\"cancel_order method not found in SDK\")\n",
    "        return {\"ok\": True, \"order_id\": order_id, \"sent_ts\": t0}\n",
    "    except Exception as e:\n",
    "        return {\"ok\": False, \"error\": str(e), \"sent_ts\": t0}\n",
    "\n",
    "UpstoxV3Exec.place_stop_exit_v3 = place_stop_exit_v3\n",
    "UpstoxV3Exec.cancel_order_v3 = cancel_order_v3\n",
    "\n",
    "exec_v3 = UpstoxV3Exec(CredentialUpstox.ACCESS_TOKEN) if (UPSDK_AVAILABLE and CredentialUpstox.ACCESS_TOKEN) else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97baa1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "FILL_LOG_COLS = ['ts', 'order_id', 'status', 'filled_qty', 'avg_price', 'trading_symbol', 'instrument_token', 'transaction_type', 'raw']\n",
    "FILL_LOG = pd.DataFrame(columns=FILL_LOG_COLS)\n",
    "\n",
    "open_positions = {}\n",
    "\n",
    "class UpstoxPortfolioReconciler:\n",
    "    def __init__(self, access_token: str):\n",
    "        configuration = upstox_client.Configuration(); configuration.access_token = access_token\n",
    "        api_client = upstox_client.ApiClient(configuration)\n",
    "        self.streamer = upstox_client.PortfolioDataStreamer(api_client, order_update=True, position_update=False, holding_update=False, gtt_update=False)\n",
    "\n",
    "        self.order_meta = {}\n",
    "        self.last_seen_fill_qty = defaultdict(int)\n",
    "        self.last_seen_fill_val = defaultdict(float)\n",
    "        self.exit_wap = defaultdict(lambda: {\"num\": 0.0, \"den\": 0, \"orders\": {}})\n",
    "\n",
    "    def attach_meta(self, order_id: str, meta: dict):\n",
    "        self.order_meta[order_id] = meta or {}\n",
    "\n",
    "    def _append_fill_log(self, record: dict):\n",
    "        global FILL_LOG\n",
    "        FILL_LOG.loc[len(FILL_LOG)] = [\n",
    "            record.get('ts'), record.get('order_id'), record.get('status'), record.get('filled_quantity'),\n",
    "            record.get('average_price'), record.get('trading_symbol'), record.get('instrument_token'),\n",
    "            record.get('transaction_type'), json.dumps(record)\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_update(message) -> dict:\n",
    "        try:\n",
    "            data = message\n",
    "            if isinstance(message, (bytes, str)): data = json.loads(message)\n",
    "        except Exception: data = message\n",
    "        d = data.get('data') if isinstance(data, dict) and isinstance(data.get('data'), dict) else (data if isinstance(data, dict) else {})\n",
    "        flat = {\n",
    "            'ts': d.get('order_timestamp') or d.get('exchange_timestamp') or int(time.time()*1000),\n",
    "            'order_id': d.get('order_id') or d.get('id') or d.get('orderId'),\n",
    "            'status': (d.get('status') or '').lower(),\n",
    "            'filled_quantity': d.get('filled_quantity') or d.get('filledQuantity') or d.get('quantity') or 0,\n",
    "            'average_price': d.get('average_price') or d.get('avg_price') or d.get('averagePrice') or None,\n",
    "            'trading_symbol': d.get('trading_symbol') or d.get('tradingsymbol') or d.get('symbol'),\n",
    "            'instrument_token': d.get('instrument_token') or d.get('instrumentKey') or d.get('instrument'),\n",
    "            'transaction_type': d.get('transaction_type') or d.get('side') or d.get('transactionType')\n",
    "        }\n",
    "        return flat\n",
    "\n",
    "    def _on_message(self, message):\n",
    "        global ORDER_WS_LAST_TS\n",
    "        ORDER_WS_LAST_TS = time.time()\n",
    "\n",
    "        upd = self._extract_update(message)\n",
    "        oid = upd.get('order_id')\n",
    "        if not oid:\n",
    "            if VERBOSE_RECON: print(\"[recon] no order_id:\", message)\n",
    "            return\n",
    "\n",
    "        cur_qty = int(upd.get('filled_quantity') or 0)\n",
    "        cur_avg = float(upd.get('average_price') or 0.0)\n",
    "        cur_val = cur_qty * cur_avg\n",
    "        prev_qty = self.last_seen_fill_qty[oid]\n",
    "        prev_val = self.last_seen_fill_val[oid]\n",
    "        d_qty = max(cur_qty - prev_qty, 0)\n",
    "        d_val = max(cur_val - prev_val, 0.0)\n",
    "        self.last_seen_fill_qty[oid] = cur_qty\n",
    "        self.last_seen_fill_val[oid] = cur_val\n",
    "\n",
    "        self._append_fill_log(upd)\n",
    "        if d_qty > 0 and VERBOSE_RECON:\n",
    "            print(f\"[recon] FILL {oid} Δqty={d_qty} cum={cur_qty} @ {cur_avg}\")\n",
    "\n",
    "        meta = self.order_meta.get(oid, {})\n",
    "        eidx = meta.get(\"exit_of_entry_idx\")\n",
    "\n",
    "        # Protective stop fill finalization\n",
    "        sidx = meta.get(\"stop_for_entry_idx\")\n",
    "        if sidx is not None:\n",
    "            status = (upd.get(\"status\") or \"\").lower()\n",
    "            if status in (\"complete\",\"completed\"):\n",
    "                try:\n",
    "                    rec = TRADE_LOG[sidx]\n",
    "                    avg_px = float(upd.get(\"average_price\") or rec.get(\"exit_price\") or 0.0)\n",
    "                    rec[\"exit_reason\"] = rec.get(\"exit_reason\") or \"stop\"\n",
    "                    rec[\"exit_price\"] = float(avg_px) if avg_px else rec.get(\"exit_price\")\n",
    "                    rec[\"exit_ts\"] = pd.Timestamp.now(tz=IST)\n",
    "                    entry = float(rec.get(\"entry_price\") or 0.0)\n",
    "                    side  = str(rec.get(\"side\") or \"BUY\").upper()\n",
    "                    pnl_leg = (avg_px - entry) if side==\"BUY\" else (entry - avg_px)\n",
    "                    rec[\"pnl_abs\"] = float(pnl_leg)\n",
    "                    rec[\"pnl_pct\"] = float(pnl_leg / entry) if entry else rec.get(\"pnl_pct\")\n",
    "                    rec[\"remaining_qty\"] = 0\n",
    "                    stk = TRADE_OPEN_STACK.get(rec[\"token\"], [])\n",
    "                    if stk and sidx in stk:\n",
    "                        try:\n",
    "                            stk.remove(sidx)\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "                    rec[\"stop_active\"] = False\n",
    "                except Exception as e:\n",
    "                    if VERBOSE_RECON: print(\"[recon] stop finalize error:\", e)\n",
    "\n",
    "        if eidx is not None:\n",
    "            agg = self.exit_wap[eidx]\n",
    "            ostate = agg[\"orders\"].setdefault(oid, {\"cum_qty\": 0, \"cum_val\": 0.0})\n",
    "            ostate[\"cum_qty\"] = cur_qty\n",
    "            ostate[\"cum_val\"] = cur_val\n",
    "\n",
    "            if d_qty > 0 and d_val > 0:\n",
    "                agg[\"num\"] += d_val\n",
    "                agg[\"den\"] += d_qty\n",
    "                exit_wap = agg[\"num\"] / max(agg[\"den\"], 1)\n",
    "                try:\n",
    "                    rec = TRADE_LOG[eidx]\n",
    "                    rec[\"exit_price\"] = float(exit_wap)\n",
    "                    rec[\"exit_filled_qty\"] = int(agg[\"den\"])\n",
    "                    entry = float(rec.get(\"entry_price\") or 0.0)\n",
    "                    side  = str(rec.get(\"side\") or \"SELL\").upper()\n",
    "                    pnl_leg = (exit_wap - entry) if side==\"BUY\" else (entry - exit_wap)\n",
    "                    rec[\"pnl_abs\"] = float(pnl_leg)\n",
    "                    rec[\"pnl_pct\"] = float(pnl_leg / entry) if entry else None\n",
    "                except Exception as e:\n",
    "                    if VERBOSE_RECON: print(\"[recon] ledger update error:\", e)\n",
    "\n",
    "            status = (upd.get(\"status\") or \"\").lower()\n",
    "            if status in (\"complete\", \"completed\", \"cancelled\", \"rejected\"):\n",
    "                try:\n",
    "                    rec = TRADE_LOG[eidx]\n",
    "                    rec[\"exit_fill_ts\"] = pd.Timestamp.now(tz=IST)\n",
    "                    # Cancel protective stop if still active\n",
    "                    stop_id = rec.get(\"stop_order_id\")\n",
    "                    if stop_id and rec.get(\"stop_active\"):\n",
    "                        if 'exec_v3' in globals() and exec_v3 is not None:\n",
    "                            exec_v3.cancel_order_v3(stop_id)\n",
    "                        rec[\"stop_active\"] = False\n",
    "                except Exception as e:\n",
    "                    if VERBOSE_RECON: print(\"[recon] stop cancel error:\", e)\n",
    "\n",
    "        cb = globals().get(\"on_upstox_order_update\")\n",
    "        if callable(cb):\n",
    "            try: cb(upd, meta)\n",
    "            except Exception as e:\n",
    "                if VERBOSE_RECON: print(\"[ledger-hook] error:\", e)\n",
    "\n",
    "    def start(self):\n",
    "        self.streamer.on('message', self._on_message)\n",
    "        self.streamer.auto_reconnect(True, 5, 20)\n",
    "        self.streamer.connect()\n",
    "\n",
    "recon = UpstoxPortfolioReconciler(CredentialUpstox.ACCESS_TOKEN) if (UPSDK_AVAILABLE and CredentialUpstox.ACCESS_TOKEN) else None\n",
    "\n",
    "def start_reconciler():\n",
    "    if recon is None:\n",
    "        print(\"Reconciler not initialized (SDK/token missing).\"); return\n",
    "    print(\"Starting Portfolio Stream Feed reconciler…\"); recon.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de44b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ledger & multi-entry (still supported, but BUY-only for entries)\n",
    "TRADE_LOG = []\n",
    "TRADE_OPEN_STACK = {}\n",
    "\n",
    "def _now_ts():\n",
    "    return pd.Timestamp.now(tz=IST)\n",
    "\n",
    "def _open_count(token: str) -> int:\n",
    "    return len([i for i in TRADE_OPEN_STACK.get(token, []) if TRADE_LOG[i].get(\"exit_ts\") is None])\n",
    "\n",
    "def log_trade_open(token: str, side: str, qty: int, price: float, plan_meta: dict, row_data: dict,\n",
    "                   target_pct=None, stop_pct=None, order_id: Optional[str]=None):\n",
    "    rec = {\n",
    "        \"token\": token, \"side\": side, \"qty\": int(qty),\n",
    "        \"remaining_qty\": int(qty),\n",
    "        \"entry_price\": float(price), \"entry_ts\": _now_ts(),\n",
    "        \"target_pct\": float(target_pct if target_pct is not None else 0.20),\n",
    "        \"stop_pct\": float(stop_pct if stop_pct is not None else 0.40),\n",
    "        \"router_route\": plan_meta.get(\"route\") if plan_meta else None,\n",
    "        \"score_final\": plan_meta.get(\"final_score\") if plan_meta else None,\n",
    "        \"score_stub\": plan_meta.get(\"stub_score\") if plan_meta else None,\n",
    "        \"score_ollama\": plan_meta.get(\"ollama_score\") if plan_meta else None,\n",
    "        \"stub_ms\": plan_meta.get(\"stub_ms\"), \"ollama_ms\": plan_meta.get(\"ollama_ms\"),\n",
    "        \"order_id\": order_id,\n",
    "        \"stop_order_id\": None, \"stop_active\": False,\n",
    "        \"exit_reason\": None, \"exit_price\": None, \"exit_ts\": None,\n",
    "        \"pnl_abs\": None, \"pnl_pct\": None, \"hold_s\": None,\n",
    "    }\n",
    "    TRADE_LOG.append(rec)\n",
    "    idx = len(TRADE_LOG) - 1\n",
    "    TRADE_OPEN_STACK.setdefault(token, []).append(idx)\n",
    "    return idx\n",
    "\n",
    "def log_trade_exit(token: str, reason: str, exit_price: float, match=\"LIFO\", exit_qty=None):\n",
    "    stack = TRADE_OPEN_STACK.get(token, [])\n",
    "    if not stack: return None\n",
    "    idx = stack[-1] if match == \"LIFO\" else stack[0]\n",
    "    rec = TRADE_LOG[idx]\n",
    "    if rec.get(\"exit_ts\") is not None:\n",
    "        stack.pop(-1 if match==\"LIFO\" else 0)\n",
    "        return log_trade_exit(token, reason, exit_price, match, exit_qty)\n",
    "    rem = int(rec.get(\"remaining_qty\", rec[\"qty\"])); take = rem if (exit_qty is None or exit_qty >= rem) else int(exit_qty)\n",
    "    new_rem = rem - take\n",
    "    side = rec[\"side\"].upper(); entry = rec[\"entry_price\"]\n",
    "    pnl_leg = (exit_price - entry) if side==\"BUY\" else (entry - exit_price)\n",
    "    realized_pct = pnl_leg / entry if entry else 0.0\n",
    "    if new_rem <= 0:\n",
    "        rec[\"remaining_qty\"] = 0; rec[\"exit_reason\"] = reason; rec[\"exit_price\"] = float(exit_price); rec[\"exit_ts\"] = _now_ts()\n",
    "        rec[\"pnl_abs\"] = float(pnl_leg); rec[\"pnl_pct\"] = float(realized_pct); rec[\"hold_s\"] = float((rec[\"exit_ts\"] - rec[\"entry_ts\"]).total_seconds())\n",
    "        stack.pop(-1 if match==\"LIFO\" else 0)\n",
    "        return idx\n",
    "    else:\n",
    "        rec[\"remaining_qty\"] = new_rem\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c0f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class ExitConfig:\n",
    "    dry_run: bool = True\n",
    "    target_pct: float = 0.2\n",
    "    stop_pct: float = 0.4\n",
    "    check_interval_s: float = 1.0\n",
    "\n",
    "_exit_thread = None; _exit_stop_evt = threading.Event()\n",
    "\n",
    "def eval_exits_for_token(token: str, row: pd.Series) -> list:\n",
    "    out = []\n",
    "    for idx in list(TRADE_OPEN_STACK.get(token, [])):\n",
    "        rec = TRADE_LOG[idx]\n",
    "        if rec.get(\"exit_ts\") is not None: continue\n",
    "        rem = int(rec.get(\"remaining_qty\", rec[\"qty\"]))\n",
    "        if rem <= 0: continue\n",
    "        side = rec[\"side\"].upper(); entry = float(rec[\"entry_price\"])\n",
    "        px = float(row.get(\"Mid\") if np.isfinite(row.get(\"Mid\", np.nan)) else row.get(\"Ltp\"))\n",
    "        if not np.isfinite(px) or entry <= 0: continue\n",
    "        pnl_pct = (px - entry)/entry if side==\"BUY\" else (entry - px)/entry\n",
    "        if pnl_pct >= rec[\"target_pct\"]:\n",
    "            out.append({\"action\":\"EXIT\",\"reason\":\"target\",\"token\":token,\"qty\":rem,\"side\":\"SELL\",\"exit_price\":px,\"idx\":idx})\n",
    "        elif pnl_pct <= -rec[\"stop_pct\"]:\n",
    "            out.append({\"action\":\"EXIT\",\"reason\":\"stop\",\"token\":token,\"qty\":rem,\"side\":\"SELL\",\"exit_price\":px,\"idx\":idx})\n",
    "    return out\n",
    "\n",
    "def _exit_worker(cfg: ExitConfig):\n",
    "    while not _exit_stop_evt.is_set():\n",
    "        time.sleep(cfg.check_interval_s)\n",
    "        with _df_lock:\n",
    "            snapshot = df_feed_enriched.copy()\n",
    "        for token, pos in list(open_positions.items()):\n",
    "            row = snapshot.loc[snapshot[\"Token\"]==token]\n",
    "            if row.empty: \n",
    "                continue\n",
    "            row = row.iloc[0]\n",
    "            signals = eval_exits_for_token(token, row)\n",
    "            for sig in signals:\n",
    "                # Decision-time logging\n",
    "                log_trade_exit(token, sig[\"reason\"], sig[\"exit_price\"], match=\"LIFO\", exit_qty= sig[\"qty\"])\n",
    "                if cfg.dry_run or (exec_v3 is None):\n",
    "                    print(f\"[EXIT-SIM] {sig}\")\n",
    "                else:\n",
    "                    best_bid = float(row.get(\"BidP1\")) if np.isfinite(row.get(\"BidP1\", np.nan)) else float(row.get(\"Mid\", 0.0))\n",
    "                    best_ask = float(row.get(\"AskP1\")) if np.isfinite(row.get(\"AskP1\", np.nan)) else float(row.get(\"Mid\", 0.0))\n",
    "                    tick = float(row.get(\"tick_size\") or 0.05)\n",
    "                    tag = f\"LLM-EXIT-e{sig['idx']}\"\n",
    "                    info = exec_v3.place_order_v3(\n",
    "                        instrument_token=token, side=sig[\"side\"], quantity=int(sig[\"qty\"]),\n",
    "                        best_bid=best_bid, best_ask=best_ask, tick_size=tick, product=PRODUCT_MAP.get(DEFAULT_PRODUCT,\"I\"),\n",
    "                        marketable_limit=True, buffer_ticks=LIMIT_BUFFER_TICKS, tag=tag\n",
    "                    )\n",
    "                    print(\"[EXIT-LIVE] sent:\", info)\n",
    "                    if recon is not None and info.get(\"ok\") and info.get(\"order_id\"):\n",
    "                        recon.attach_meta(info[\"order_id\"], {\n",
    "                            \"exit_of_entry_idx\": sig[\"idx\"],\n",
    "                            \"planned_qty\": int(sig[\"qty\"]),\n",
    "                            \"token\": token,\n",
    "                            \"side\": sig[\"side\"],\n",
    "                            \"tag\": tag,\n",
    "                            \"sent_ts\": info.get(\"sent_ts\"),\n",
    "                            \"ack_ts\": info.get(\"ack_ts\"),\n",
    "                        })\n",
    "            if signals:\n",
    "                open_positions[token] = {\"qty\": 0, \"side\": pos.get(\"side\",\"BUY\"), \"avg_price\": pos.get(\"avg_price\", 0.0)}\n",
    "\n",
    "def start_exit_manager(cfg: ExitConfig):\n",
    "    global _exit_thread, _exit_stop_evt\n",
    "    _exit_stop_evt = threading.Event()\n",
    "    _exit_thread = threading.Thread(target=_exit_worker, args=(cfg,), daemon=True)\n",
    "    _exit_thread.start()\n",
    "\n",
    "def stop_exit_manager():\n",
    "    global _exit_thread, _exit_stop_evt\n",
    "    _exit_stop_evt.set()\n",
    "    if _exit_thread is not None:\n",
    "        _exit_thread.join(timeout=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec525d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_last_order_ts = 0.0\n",
    "def _lat_log(event: str, **kwargs):\n",
    "    ts = time.perf_counter()\n",
    "    LATENCY_LOG.append({\"t\": ts, \"event\": event, **kwargs})\n",
    "    if len(LATENCY_LOG) > LATENCY_LOG_MAX:\n",
    "        del LATENCY_LOG[: len(LATENCY_LOG) - LATENCY_LOG_MAX]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79143f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def place_orders(plan: Dict[str, Any], df_enriched: pd.DataFrame, dry_run: bool = True) -> List[Dict[str, Any]]:\n",
    "    results = []\n",
    "    if not plan or \"legs\" not in plan:\n",
    "        return results\n",
    "    plan_meta = plan.get(\"meta\", {})\n",
    "\n",
    "    global _last_order_ts\n",
    "    for leg in plan[\"legs\"]:\n",
    "        token = str(leg[\"token\"])\n",
    "        row = df_enriched.loc[df_enriched[\"Token\"]==token]\n",
    "        if row.empty:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":\"token_not_found\",\"leg\":leg}); continue\n",
    "        row = row.iloc[0]\n",
    "        lot = int(row.get(\"lot_size\") or 0); qty = int(leg.get(\"qty\", 0))\n",
    "        if lot and qty % lot != 0:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":f\"qty_not_multiple_of_lot({lot})\",\"leg\":leg}); continue\n",
    "        if qty <= 0 or qty > MAX_QTY_PER_LEG:\n",
    "            results.append({\"status\":\"rejected\",\"reason\":\"qty_bounds\",\"leg\":leg}); continue\n",
    "\n",
    "        side = leg[\"side\"].upper()\n",
    "        if side != \"BUY\":\n",
    "            results.append({\"status\":\"rejected\",\"reason\":\"buy_only_guard\"}); continue\n",
    "\n",
    "        product_code = PRODUCT_MAP.get(leg.get(\"product\", DEFAULT_PRODUCT), PRODUCT_MAP[DEFAULT_PRODUCT])\n",
    "        best_bid = float(row.get(\"BidP1\")) if np.isfinite(row.get(\"BidP1\", np.nan)) else float(row.get(\"Mid\", 0.0))\n",
    "        best_ask = float(row.get(\"AskP1\")) if np.isfinite(row.get(\"AskP1\", np.nan)) else float(row.get(\"Mid\", 0.0))\n",
    "        tick = float(row.get(\"tick_size\") or 0.05)\n",
    "\n",
    "        now = time.perf_counter()\n",
    "        delay_ms = ORDER_MIN_GAP_MS - (now - _last_order_ts) * 1000.0\n",
    "        if delay_ms > 0: time.sleep(delay_ms / 1000.0)\n",
    "        _last_order_ts = time.perf_counter()\n",
    "        _lat_log(\"order_send\", token=token, side=side, qty=qty, order_type=\"LIMIT\")\n",
    "\n",
    "        if dry_run or (exec_v3 is None):\n",
    "            fill = float(row.get(\"Mid\")) if np.isfinite(row.get(\"Mid\", np.nan)) else float(row.get(\"Ltp\", 0.0))\n",
    "            results.append({\"status\":\"simulated\",\"token\":token,\"qty\":qty,\"side\":side,\"product\":product_code,\n",
    "                            \"order_type\":\"LIMIT\",\"limit_price\":fill, \"fill_price\":fill, \"router_meta\": plan_meta})\n",
    "            pos = open_positions.get(token, {\"qty\": 0, \"side\": side, \"avg_price\": 0.0})\n",
    "            new_qty = pos[\"qty\"] + qty if side == pos[\"side\"] else pos[\"qty\"] - qty\n",
    "            new_avg = (pos[\"avg_price\"]*pos[\"qty\"] + fill*qty)/max(new_qty,1) if new_qty>0 and side==pos[\"side\"] else fill\n",
    "            open_positions[token] = {\"qty\": max(new_qty,0), \"side\": side, \"avg_price\": new_avg}\n",
    "            entry_idx = log_trade_open(token, side, qty, fill, plan_meta, leg.get(\"_row\", {}), order_id=None)\n",
    "            _lat_log(\"order_ack\", token=token)\n",
    "        else:\n",
    "            info = exec_v3.place_order_v3(\n",
    "                instrument_token=token, side=side, quantity=qty,\n",
    "                best_bid=best_bid, best_ask=best_ask, tick_size=tick,\n",
    "                product=PRODUCT_MAP.get(DEFAULT_PRODUCT,\"I\"), validity=\"DAY\",\n",
    "                marketable_limit=True, buffer_ticks=LIMIT_BUFFER_TICKS, tag=\"BUY-ENTRY\"\n",
    "            )\n",
    "            if not info.get(\"ok\"):\n",
    "                results.append({\"status\":\"rejected\",\"reason\":\"v3_place_error\",\"detail\":info}); continue\n",
    "            order_id = info.get(\"order_id\")\n",
    "            fill = float(row.get(\"Mid\") or row.get(\"Ltp\") or 0.0)\n",
    "            pos = open_positions.get(token, {\"qty\": 0, \"side\": side, \"avg_price\": 0.0})\n",
    "            new_qty = pos[\"qty\"] + qty if side == pos[\"side\"] else pos[\"qty\"] - qty\n",
    "            new_avg = (pos[\"avg_price\"]*pos[\"qty\"] + fill*qty)/max(new_qty,1) if new_qty>0 and side==pos[\"side\"] else fill\n",
    "            open_positions[token] = {\"qty\": max(new_qty,0), \"side\": side, \"avg_price\": new_avg}\n",
    "            entry_idx = log_trade_open(token, side, qty, fill, plan_meta, leg.get(\"_row\", {}), order_id=str(order_id))\n",
    "            if recon is not None and order_id:\n",
    "                recon.attach_meta(order_id, {\"entry_idx\": entry_idx, \"token\": token, \"side\": side, \"qty\": qty,\n",
    "                                             \"sent_ts\": info.get(\"sent_ts\"), \"ack_ts\": info.get(\"ack_ts\"), \"tag\": info.get(\"tag\")})\n",
    "            # --- Protective SELL stop (SL-M) to close the long ---\n",
    "            entry_price = float(fill)\n",
    "            stop_trig = entry_price * (1 - float(TRADE_LOG[entry_idx][\"stop_pct\"]))\n",
    "            stop_trig = math.floor(stop_trig / max(tick,1e-6)) * max(tick,1e-6)\n",
    "            stop_info = exec_v3.place_stop_exit_v3(\n",
    "                instrument_token=token, exit_side=\"SELL\", trigger_price=stop_trig,\n",
    "                quantity=qty, product=PRODUCT_MAP.get(DEFAULT_PRODUCT,\"I\"),\n",
    "                tag=f\"STOP-e{entry_idx}\"\n",
    "            )\n",
    "            if stop_info.get(\"ok\"):\n",
    "                TRADE_LOG[entry_idx][\"stop_order_id\"] = stop_info[\"order_id\"]\n",
    "                TRADE_LOG[entry_idx][\"stop_active\"] = True\n",
    "                if recon is not None:\n",
    "                    recon.attach_meta(stop_info[\"order_id\"], {\"stop_for_entry_idx\": entry_idx, \"token\": token})\n",
    "            results.append({\"status\":\"placed\",\"order_id\":order_id,\"token\":token,\"qty\":qty,\"side\":side,\"limit_price\":None, \"router_meta\": plan_meta})\n",
    "            _lat_log(\"order_ack\", token=token)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_strategy(plan: Dict[str, Any], df_enriched: pd.DataFrame) -> Optional[Dict[str, Any]]:\n",
    "    if not plan or not plan.get(\"legs\"): return None\n",
    "    if len(plan[\"legs\"]) > MAX_OPEN_LEGS: return None\n",
    "    for leg in plan[\"legs\"]:\n",
    "        if leg.get(\"side\",\"BUY\").upper() != \"BUY\": return None  # buy-only guard\n",
    "        t = str(leg[\"token\"])\n",
    "        if df_enriched.loc[df_enriched[\"Token\"]==t].empty: return None\n",
    "    return plan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a1312",
   "metadata": {},
   "source": [
    "### HTTP Backfill Daemon (Order Book + Trades + Positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BACKFILL_MIN_INTERVAL_S = 90.0\n",
    "BACKFILL_TRIGGER_NO_WS_S = 15.0\n",
    "BACKFILL_EOD_GUARD = True\n",
    "BACKFILL_WINDOW_MIN = 6\n",
    "UPSTOX_API_BASE = os.getenv(\"UPSTOX_API_BASE\", \"https://api.upstox.com/v2\")\n",
    "\n",
    "_last_backfill_ts = 0.0\n",
    "_backfill_thread = None\n",
    "_backfill_stop_evt = threading.Event()\n",
    "\n",
    "def _http_get_json(url: str, params=None, timeout=2.5):\n",
    "    try:\n",
    "        import requests\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"Install 'requests' for backfill.\") from e\n",
    "    headers = {\"Accept\": \"application/json\", \"Authorization\": f\"Bearer {CredentialUpstox.ACCESS_TOKEN}\"}\n",
    "    r = requests.get(url, headers=headers, params=params, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def fetch_order_book_today():\n",
    "    url = f\"{UPSTOX_API_BASE}/order/retrieve-all\"\n",
    "    return _http_get_json(url)\n",
    "\n",
    "def fetch_trades_today():\n",
    "    url = f\"{UPSTOX_API_BASE}/order/trades/get-trades-for-day\"\n",
    "    return _http_get_json(url)\n",
    "\n",
    "def fetch_positions():\n",
    "    url = f\"{UPSTOX_API_BASE}/portfolio/short-term-positions\"\n",
    "    return _http_get_json(url)\n",
    "\n",
    "def _parse_epoch_ms(v):\n",
    "    try: return int(float(v))\n",
    "    except Exception: return None\n",
    "\n",
    "def reconcile_via_http():\n",
    "    global open_positions\n",
    "    ob = fetch_order_book_today()\n",
    "    tr = fetch_trades_today()\n",
    "    pos = fetch_positions()\n",
    "\n",
    "    trades = tr.get(\"data\") or tr.get(\"trades\") or []\n",
    "    trades_by_tok_side = {}\n",
    "    for t in trades:\n",
    "        tok = str(t.get(\"instrument_token\") or t.get(\"instrumentKey\") or \"\")\n",
    "        side = str(t.get(\"transaction_type\") or t.get(\"transactionType\") or \"\").upper()\n",
    "        trades_by_tok_side.setdefault((tok, side), []).append({\n",
    "            \"quantity\": int(t.get(\"quantity\") or 0),\n",
    "            \"price\": float(t.get(\"average_price\") or t.get(\"price\") or 0.0),\n",
    "            \"ts\": _parse_epoch_ms(t.get(\"exchange_timestamp\") or t.get(\"timestamp\"))\n",
    "        })\n",
    "\n",
    "    def _wap(lst, cap_qty=None):\n",
    "        if not lst: return None\n",
    "        num, den = 0.0, 0\n",
    "        rem = cap_qty if cap_qty is not None else None\n",
    "        for x in sorted(lst, key=lambda z: z[\"ts\"] or 0):\n",
    "            q = int(x[\"quantity\"]); p = float(x[\"price\"])\n",
    "            if rem is None:\n",
    "                num += p*q; den += q\n",
    "            else:\n",
    "                take = min(q, max(rem, 0))\n",
    "                if take <= 0: break\n",
    "                num += p*take; den += take; rem -= take\n",
    "                if rem <= 0: break\n",
    "        return (num/den) if den>0 else None\n",
    "\n",
    "    n_entry_adj, n_exit_adj = 0, 0\n",
    "    for rec in TRADE_LOG:\n",
    "        tok = str(rec.get(\"token\"))\n",
    "        side = str(rec.get(\"side\") or \"BUY\").upper()\n",
    "        qty  = int(rec.get(\"qty\") or 0)\n",
    "\n",
    "        ent = _wap(trades_by_tok_side.get((tok, side), []), cap_qty=qty)\n",
    "        if ent and rec.get(\"entry_price\") != float(ent):\n",
    "            rec[\"entry_price\"] = float(ent); n_entry_adj += 1\n",
    "\n",
    "        if rec.get(\"exit_ts\") is not None:\n",
    "            opp = \"SELL\"  # closing a buy\n",
    "            lst = trades_by_tok_side.get((tok, opp), [])\n",
    "            if not lst: continue\n",
    "            exit_ts_ms = int(rec[\"exit_ts\"].value/1e6) if hasattr(rec[\"exit_ts\"], \"value\") else None\n",
    "            if exit_ts_ms is None: continue\n",
    "            win_ms = BACKFILL_WINDOW_MIN*60*1000\n",
    "            filt = [x for x in lst if x[\"ts\"] is not None and abs(x[\"ts\"] - exit_ts_ms) <= win_ms]\n",
    "            ex_wap = _wap(filt, cap_qty=qty)\n",
    "            if ex_wap and rec.get(\"exit_price\") != float(ex_wap):\n",
    "                rec[\"exit_price\"] = float(ex_wap)\n",
    "                entry = float(rec.get(\"entry_price\") or 0.0)\n",
    "                pnl_leg = (ex_wap - entry)\n",
    "                rec[\"pnl_abs\"] = float(pnl_leg)\n",
    "                rec[\"pnl_pct\"] = float(pnl_leg / entry) if entry else None\n",
    "                n_exit_adj += 1\n",
    "\n",
    "    try:\n",
    "        pdata = pos.get(\"data\") or pos.get(\"positions\") or []\n",
    "        broker_net = {}\n",
    "        for p in pdata:\n",
    "            tk = str(p.get(\"instrument_token\") or p.get(\"instrumentKey\") or \"\")\n",
    "            if not tk: continue\n",
    "            netq = int(p.get(\"quantity\") or p.get(\"net_qty\") or p.get(\"net_quantity\") or 0)\n",
    "            avgp = float(p.get(\"average_price\") or p.get(\"avg_price\") or 0.0)\n",
    "            broker_net[tk] = {\"qty\": netq, \"avg_price\": avgp}\n",
    "        for tk, v in broker_net.items():\n",
    "            side = \"BUY\" if v[\"qty\"] >= 0 else \"SELL\"\n",
    "            open_positions[tk] = {\"qty\": abs(int(v[\"qty\"])), \"side\": side, \"avg_price\": float(v[\"avg_price\"])}\n",
    "    except Exception as e:\n",
    "        if VERBOSE_RECON: print(\"[backfill] positions parse error:\", e)\n",
    "\n",
    "    return {\"entry_adjusted\": n_entry_adj, \"exit_adjusted\": n_exit_adj}\n",
    "\n",
    "def _have_live_things():\n",
    "    if any((r.get(\"exit_ts\") is None and int(r.get(\"remaining_qty\", r.get(\"qty\",0)))>0) for r in TRADE_LOG):\n",
    "        return True\n",
    "    if any(v.get(\"qty\",0)>0 for v in open_positions.values()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def backfill_once():\n",
    "    _lat_log(\"backfill_start\")\n",
    "    try:\n",
    "        info = reconcile_via_http()\n",
    "        _lat_log(\"backfill_end\", **info)\n",
    "        if VERBOSE_RECON:\n",
    "            print(f\"[backfill] entries_adj={info['entry_adjusted']} exits_adj={info['exit_adjusted']}\")\n",
    "        return info\n",
    "    except Exception as e:\n",
    "        _lat_log(\"backfill_end\", error=str(e))\n",
    "        if VERBOSE_RECON:\n",
    "            print(\"[backfill] ERROR:\", e)\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def _backfill_worker():\n",
    "    global _last_backfill_ts\n",
    "    while not _backfill_stop_evt.is_set():\n",
    "        try:\n",
    "            time.sleep(1.0)\n",
    "            now = time.time()\n",
    "            if not BACKFILL_ENABLED:\n",
    "                continue\n",
    "            if (now - _last_backfill_ts) < BACKFILL_MIN_INTERVAL_S:\n",
    "                continue\n",
    "            hhmm = pd.Timestamp.now(tz=IST).strftime(\"%H:%M\")\n",
    "            eod_guard = BACKFILL_EOD_GUARD and (hhmm >= \"15:29\" and hhmm <= \"15:30\")\n",
    "            stale_ws = (now - ORDER_WS_LAST_TS) >= BACKFILL_TRIGGER_NO_WS_S\n",
    "            if eod_guard or (stale_ws and _have_live_things()):\n",
    "                backfill_once()\n",
    "                _last_backfill_ts = now\n",
    "        except Exception:\n",
    "            time.sleep(2.0)\n",
    "            continue\n",
    "\n",
    "def start_backfill_daemon():\n",
    "    global _backfill_thread, _backfill_stop_evt\n",
    "    _backfill_stop_evt = threading.Event()\n",
    "    _backfill_thread = threading.Thread(target=_backfill_worker, daemon=True)\n",
    "    _backfill_thread.start()\n",
    "    print(\"Backfill daemon started.\")\n",
    "\n",
    "def stop_backfill_daemon():\n",
    "    global _backfill_thread, _backfill_stop_evt\n",
    "    _backfill_stop_evt.set()\n",
    "    if _backfill_thread is not None:\n",
    "        _backfill_thread.join(timeout=5)\n",
    "    print(\"Backfill daemon stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if SIMULATION_MODE:\n",
    "    raise RuntimeError(\"This notebook is live-first. Set SIMULATION_MODE=False to proceed.\")\n",
    "\n",
    "tokens_with_spot = list(dict.fromkeys(token_list + [UNDERLYING_SPOT_TOKEN]))\n",
    "streamer = start_live_stream(tokens_with_spot, mode=WEBSOCKET_MODE)\n",
    "time.sleep(3.0)\n",
    "\n",
    "with _df_lock:\n",
    "    snapshot = df_feed_enriched.copy()\n",
    "print(\"Feed snapshot rows:\", len(snapshot))\n",
    "display(snapshot.tail(6))\n",
    "\n",
    "try:\n",
    "    if RECONCILE_LIVE_PNL: start_reconciler()\n",
    "except Exception as _e:\n",
    "    print(\"Reconciler start skipped:\", _e)\n",
    "\n",
    "try:\n",
    "    if BACKFILL_ENABLED: start_backfill_daemon()\n",
    "except Exception as _e:\n",
    "    print(\"Backfill daemon start skipped:\", _e)\n",
    "\n",
    "def latency_report(n_tail: int = 50) -> pd.DataFrame:\n",
    "    return pd.DataFrame(LATENCY_LOG[-n_tail:])\n",
    "\n",
    "def router_report(n_tail: int = 200):\n",
    "    tail = ROUTER_LOG[-n_tail:]\n",
    "    df = pd.DataFrame(tail)\n",
    "    if df.empty: return df, {}\n",
    "    agree = df[\"final_decision\"].mean()\n",
    "    used_ollama_rate = df[\"used_ollama\"].mean()\n",
    "    avg_stub = df[\"stub_ms\"].mean()\n",
    "    avg_ollama = df.loc[df[\"used_ollama\"], \"ollama_ms\"].mean() if (df[\"used_ollama\"].any()) else float(\"nan\")\n",
    "    routes = df[\"route\"].value_counts().to_dict()\n",
    "    summary = {\"n\": int(len(df)), \"decision_rate\": float(round(agree, 4)), \"used_ollama_rate\": float(round(used_ollama_rate, 4)),\n",
    "               \"avg_stub_ms\": float(round(avg_stub, 2)), \"avg_ollama_ms\": float(round(avg_ollama, 2)) if avg_ollama == avg_ollama else None, \"routes\": routes}\n",
    "    return df, summary\n",
    "\n",
    "_lat_log(\"decision_start\", rows=len(snapshot))\n",
    "plan = ask_llm_for_strategy_buy_only(snapshot)\n",
    "_lat_log(\"decision_end\", legs=len(plan.get(\"legs\", [])))\n",
    "\n",
    "try:\n",
    "    _lat_log(\"validate_start\")\n",
    "    validated = validate_strategy(plan, snapshot)\n",
    "    _lat_log(\"validate_end\", ok=True)\n",
    "except Exception as e:\n",
    "    validated = None; _lat_log(\"validate_end\", ok=False, err=str(e)); print(\"Validation failed:\", e)\n",
    "\n",
    "orders = []\n",
    "if validated:\n",
    "    _lat_log(\"place_start\", nlegs=len(validated[\"legs\"]))\n",
    "    orders = place_orders(validated, snapshot, dry_run=(not ORDERS_LIVE))\n",
    "    _lat_log(\"place_end\", norders=len(orders))\n",
    "    print(\"Order results:\"); print(json.dumps(orders, indent=2))\n",
    "\n",
    "cfg = ExitConfig(dry_run=(not EXIT_MANAGER_LIVE))\n",
    "start_exit_manager(cfg)\n",
    "\n",
    "_recenter_thread = threading.Thread(target=recenter_daemon, daemon=True); _recenter_thread.start()\n",
    "\n",
    "print(\"Live scalper pipeline running. Use the Stop cell to close sockets and exit manager.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7066b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with _df_lock:\n",
    "    mon = df_feed_enriched.copy()\n",
    "display(mon.tail(12))\n",
    "df_router, router_summary = router_report(500)\n",
    "display(df_router.tail(10))\n",
    "print(\"Router summary:\", router_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6218e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _time_bucket(ts):\n",
    "    if pd.isna(ts): return \"unknown\"\n",
    "    t = ts.tz_convert(IST).time() if ts.tzinfo else ts.tz_localize(IST).time()\n",
    "    if t >= pd.to_datetime(\"09:15\").time() and t < pd.to_datetime(\"10:00\").time():\n",
    "        return \"open\"\n",
    "    if t >= pd.to_datetime(\"14:30\").time() and t <= pd.to_datetime(\"15:30\").time():\n",
    "        return \"close\"\n",
    "    return \"mid\"\n",
    "\n",
    "def _iv_regime(z):\n",
    "    if pd.isna(z): return \"unknown\"\n",
    "    a = abs(float(z))\n",
    "    if a <= 1.0: return \"stable\"\n",
    "    if a <= 2.0: return \"elevated\"\n",
    "    return \"spike\"\n",
    "\n",
    "def router_performance_report():\n",
    "    df = pd.DataFrame([r for r in TRADE_LOG if r.get(\"exit_ts\") is not None])\n",
    "    if df.empty:\n",
    "        return df, {}, pd.DataFrame(), {}\n",
    "    df[\"hit\"] = (df[\"exit_reason\"]==\"target\").astype(int)\n",
    "    df[\"pnl_pct\"] = df[\"pnl_pct\"].astype(float)\n",
    "    grp = df.groupby(\"router_route\", dropna=False)\n",
    "\n",
    "    def _agg_expect(g):\n",
    "        win = g[g[\"pnl_pct\"]>0][\"pnl_pct\"].mean()\n",
    "        loss = (-g[g[\"pnl_pct\"]<0][\"pnl_pct\"]).mean()\n",
    "        win_rate = (g[\"pnl_pct\"]>0).mean()\n",
    "        exp = g[\"pnl_pct\"].mean()\n",
    "        return pd.Series({\n",
    "            \"n\": len(g),\n",
    "            \"hit_rate\": g[\"hit\"].mean(),\n",
    "            \"win_rate\": win_rate,\n",
    "            \"avg_win_pct\": win if pd.notna(win) else 0.0,\n",
    "            \"avg_loss_pct\": loss if pd.notna(loss) else 0.0,\n",
    "            \"expectancy_pct\": exp,\n",
    "            \"volatility_pct\": g[\"pnl_pct\"].std(),\n",
    "            \"avg_hold_s\": g[\"hold_s\"].mean()\n",
    "        })\n",
    "\n",
    "    perf = grp.apply(_agg_expect).reset_index()\n",
    "    return df, perf, df.sort_values(\"exit_ts\"), {}\n",
    "\n",
    "df_trades, perf, _, _ = router_performance_report()\n",
    "display(df_trades.tail(10))\n",
    "print(\"Performance by route:\"); display(perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stop & cleanup\n",
    "try:\n",
    "    stop_exit_manager()\n",
    "except Exception: pass\n",
    "try:\n",
    "    stop_live_stream()\n",
    "except Exception: pass\n",
    "try:\n",
    "    stop_backfill_daemon()\n",
    "except Exception: pass\n",
    "print(\"Shutdown requested.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ce6a4",
   "metadata": {},
   "source": [
    "\n",
    "# --- v4.1 PATCHES (Buy-only) ---\n",
    "# This cell and the following override/extend earlier definitions to improve:\n",
    "# - Stop escalation correctness (modify vs convert; no unconditional widen)\n",
    "# - Dynamic SL offsets (latency EWM + ticks-based micro-vol)\n",
    "# - Unified V3 order wrappers for SL and SL-M + latency logging\n",
    "# - DepthImb smoothing + persistence; microprice drift and spot micro-momentum\n",
    "# - Delta/spread gates adapt to regime; trading window guard + per-token cooldown\n",
    "# - Reconciler status set, partial stop fill tracking, meta on conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === v4.1 toggles & params ===\n",
    "TRADING_WINDOW = (\"09:18\",\"15:20\")     # IST trading window for new entries\n",
    "PER_TOKEN_COOLDOWN_S = 90.0            # cooldown after an exit before re-entry on same token\n",
    "USE_DEPTH_IMB_PERSIST = True\n",
    "DEPTH_IMB_MIN_TICKS = 3                # require this many consecutive ticks of directional imbalance\n",
    "MIN_GAMMA_EFF = 0.0                    # optional floor on Gamma * |spot_slope|\n",
    "MAX_ABS_THETA = None                   # e.g., 30.0 to skip highly negative theta; set None to disable\n",
    "\n",
    "EOD_FLATTEN_ENABLED = True\n",
    "EOD_FLATTEN_AT = \"15:24\"               # force exits at 15:24 IST if any qty remains\n",
    "BROKER_FEE_PER_LOT = 0.0               # for simulation adjustments (if SIM mode used)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, time, math, threading, numpy as np, pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "def log_event(**kv):\n",
    "    try:\n",
    "        kv[\"ts\"] = float(time.time())\n",
    "        with open(\"/mnt/data/trade_events.jsonl\",\"a\") as f:\n",
    "            f.write(json.dumps(kv, default=str) + \"\\n\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def _in_trading_window():\n",
    "    try:\n",
    "        now = pd.Timestamp.now(tz=IST).strftime(\"%H:%M\")\n",
    "        return TRADING_WINDOW[0] <= now <= TRADING_WINDOW[1]\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "def _last_exit_ts_for(token: str):\n",
    "    # Search TRADE_LOG from end for last exit on token\n",
    "    for rec in reversed(TRADE_LOG):\n",
    "        if rec.get(\"token\")==token and rec.get(\"exit_ts\") is not None:\n",
    "            try:\n",
    "                return rec[\"exit_ts\"]\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee66028",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _recent_latency_ms(default=60.0):\n",
    "    try:\n",
    "        df = pd.DataFrame(LATENCY_LOG)\n",
    "        s = df.loc[df[\"event\"]==\"broker_latency_ms\",\"ms\"].tail(200)\n",
    "        if s.empty: return float(default)\n",
    "        return float(s.ewm(alpha=0.2).mean().iloc[-1])\n",
    "    except Exception:\n",
    "        return float(default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f25b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- UpstoxV3Exec v4.1 extensions ---\n",
    "try:\n",
    "    _UpExec = UpstoxV3Exec\n",
    "except NameError:\n",
    "    _UpExec = None\n",
    "\n",
    "if _UpExec is not None:\n",
    "    # add modify\n",
    "    def _modify_order_v3(self, order_id: str, *, price: float = None, trigger_price: float = None,\n",
    "                         order_type: str = None, validity: str = None, quantity: int = None) -> dict:\n",
    "        try:\n",
    "            req = upstox_client.ModifyOrderV3Request(\n",
    "                order_id=order_id,\n",
    "                price=float(price) if price is not None else None,\n",
    "                trigger_price=float(trigger_price) if trigger_price is not None else None,\n",
    "                order_type=order_type, validity=validity,\n",
    "                quantity=int(quantity) if quantity is not None else None\n",
    "            )\n",
    "            t0 = self._now_ms()\n",
    "            resp = self.order_api_v3.modify_order(req)\n",
    "            t1 = self._ow_ms() if hasattr(self, \"_ow_ms\") else self._now_ms()\n",
    "            return {\"ok\": True, \"order_id\": order_id, \"broker_latency_ms\": (t1 - t0)}\n",
    "        except Exception as e:\n",
    "            return {\"ok\": False, \"error\": str(e), \"order_id\": order_id}\n",
    "\n",
    "    UpstoxV3Exec.modify_order_v3 = _modify_order_v3\n",
    "\n",
    "    # add place stop-limit\n",
    "    def _place_stop_limit_exit_v3(self, *, instrument_token: str, exit_side: str, trigger_price: float,\n",
    "                                  limit_price: float, quantity: int, product: str = \"I\", validity: str = \"DAY\",\n",
    "                                  tag: str = None) -> dict:\n",
    "        req = upstox_client.PlaceOrderV3Request(\n",
    "            quantity=int(quantity), product=product, validity=validity, order_type='SL',\n",
    "            price=float(limit_price), trigger_price=float(trigger_price),\n",
    "            instrument_token=instrument_token, transaction_type=exit_side.upper(), tag=(tag or f\"prot-sl-{uuid.uuid4().hex[:8]}\"),\n",
    "            slice=False, is_amo=False\n",
    "        )\n",
    "        t0 = self._now_ms()\n",
    "        try:\n",
    "            resp = self.order_api_v3.place_order(req); t1 = self._now_ms()\n",
    "            oid = (resp.data or {}).get(\"order_id\") if hasattr(resp,\"data\") else None\n",
    "            info = {\"ok\": True, \"order_id\": oid, \"sent_ts\": t0, \"ack_ts\": t1, \"broker_latency_ms\": (t1 - t0)}\n",
    "            LATENCY_LOG.append({\"t\": time.perf_counter(), \"event\":\"broker_latency_ms\", \"ms\": info[\"broker_latency_ms\"]})\n",
    "            return info\n",
    "        except ApiException as e:\n",
    "            return {\"ok\": False, \"error\": str(e), \"sent_ts\": t0}\n",
    "\n",
    "    UpstoxV3Exec.place_stop_limit_exit_v3 = _place_stop_limit_exit_v3\n",
    "\n",
    "    # wrap place_order_v3 to log broker latency\n",
    "    try:\n",
    "        _orig_place = UpstoxV3Exec.place_order_v3\n",
    "        def _place_order_v3_with_lat(self, *args, **kwargs):\n",
    "            info = _orig_place(self, *args, **kwargs)\n",
    "            try:\n",
    "                if info and isinstance(info, dict) and \"broker_latency_ms\" in info:\n",
    "                    LATENCY_LOG.append({\"t\": time.perf_counter(), \"event\":\"broker_latency_ms\", \"ms\": info[\"broker_latency_ms\"]})\n",
    "            except Exception:\n",
    "                pass\n",
    "            return info\n",
    "        UpstoxV3Exec.place_order_v3 = _place_order_v3_with_lat\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Microstructure analytics (v4.1) ---\n",
    "from collections import defaultdict, deque\n",
    "_tick_var = defaultdict(lambda: {\"m_prev\": None, \"var\": 1.0})\n",
    "_imb_ewm = defaultdict(float)\n",
    "_imb_persist = defaultdict(int)\n",
    "_micro_prev = defaultdict(lambda: None)\n",
    "\n",
    "SPOT_BUF = deque(maxlen=64)  # (ts, ltp)\n",
    "\n",
    "def update_tick_vol(token: str, mid: float, tick: float):\n",
    "    if not np.isfinite(mid): return\n",
    "    s = _tick_var[token]\n",
    "    if s[\"m_prev\"] is not None:\n",
    "        d = (mid - s[\"m_prev\"]) / max(tick,1e-6)\n",
    "        s[\"var\"] = 0.9*s[\"var\"] + 0.1*(d*d)\n",
    "    s[\"m_prev\"] = mid\n",
    "\n",
    "def vol_ticks_for(token: str) -> float:\n",
    "    return math.sqrt(max(_tick_var[token][\"var\"], 1e-6))\n",
    "\n",
    "def smooth_imb(token: str, raw: float) -> float:\n",
    "    v = _imb_ewm[token]\n",
    "    if np.isfinite(raw):\n",
    "        v = 0.8*v + 0.2*raw\n",
    "        _imb_ewm[token] = v\n",
    "    return _imb_ewm[token]\n",
    "\n",
    "def update_persist(token: str, imb_ewm: float, side: str):\n",
    "    want = (imb_ewm >= +DEPTH_IMB_MIN) if side==\"CE\" else (imb_ewm <= -DEPTH_IMB_MIN)\n",
    "    _imb_persist[token] = (_imb_persist[token] + 1) if want else 0\n",
    "\n",
    "def microprice(bidp, bidq, askp, askq):\n",
    "    try:\n",
    "        qsum = float(bidq) + float(askq)\n",
    "        if qsum <= 0: return float(\"nan\")\n",
    "        return (askp*bidq + bidp*askq) / qsum\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "def spot_slope_and_r2():\n",
    "    # simple OLS slope on last few points\n",
    "    if len(SPOT_BUF) < 6: return 0.0, 0.0\n",
    "    xs = np.arange(len(SPOT_BUF), dtype=float)\n",
    "    ys = np.array([p[1] for p in SPOT_BUF], dtype=float)\n",
    "    x = xs - xs.mean(); y = ys - ys.mean()\n",
    "    denom = (x**2).sum()\n",
    "    if denom <= 0: return 0.0, 0.0\n",
    "    slope = (x*y).sum() / denom\n",
    "    yhat = x*slope\n",
    "    ss_tot = (y**2).sum(); ss_res = ((y - yhat)**2).sum()\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
    "    return float(slope), float(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Override start_live_stream with v4.1 analytics & faster updates ---\n",
    "def start_live_stream(tokens: list, mode: str = \"full_d30\"):\n",
    "    global live_streamer, df_feed, df_feed_enriched, spot_ltp_current\n",
    "    if not UPSDK_AVAILABLE: raise RuntimeError(\"Upstox SDK not installed.\")\n",
    "    if not CredentialUpstox.ACCESS_TOKEN: raise RuntimeError(\"ACCESS_TOKEN missing.\")\n",
    "\n",
    "    configuration = upstox_client.Configuration()\n",
    "    configuration.access_token = CredentialUpstox.ACCESS_TOKEN\n",
    "    api_client = upstox_client.ApiClient(configuration)\n",
    "    streamer = upstox_client.MarketDataStreamerV3(api_client, instrument_key=tokens, mode=mode)\n",
    "\n",
    "    feed_index = {}  # token -> row index for df_feed\n",
    "\n",
    "    def _on_message(msg):\n",
    "        global df_feed, df_feed_enriched, spot_ltp_current\n",
    "        feeds = msg.get(\"feeds\", {})\n",
    "        for token, payload in feeds.items():\n",
    "            ff = payload.get(\"fullFeed\",{}).get(\"marketFF\",{})\n",
    "            ltpc = ff.get(\"ltpc\",{})\n",
    "            level = ff.get(\"marketLevel\",{}).get(\"bidAskQuote\",[{}])\n",
    "            greeks = ff.get(\"optionGreeks\",{}) or {}\n",
    "            if token == UNDERLYING_SPOT_TOKEN:\n",
    "                try:\n",
    "                    if ltpc.get(\"ltp\") is not None:\n",
    "                        spot_ltp_current = float(ltpc.get(\"ltp\"))\n",
    "                        SPOT_BUF.append((time.time(), spot_ltp_current))\n",
    "                except Exception: pass\n",
    "                continue\n",
    "            # build row\n",
    "            bidp = float(level[0].get(\"bidP\")) if level and level[0].get(\"bidP\") is not None else np.nan\n",
    "            bidq = float(level[0].get(\"bidQ\")) if level and level[0].get(\"bidQ\") is not None else np.nan\n",
    "            askp = float(level[0].get(\"askP\")) if level and level[0].get(\"askP\") is not None else np.nan\n",
    "            askq = float(level[0].get(\"askQ\")) if level and level[0].get(\"askQ\") is not None else np.nan\n",
    "            mid = (bidp + askp)/2.0 if np.isfinite(bidp) and np.isfinite(askp) else (float(ltpc.get(\"ltp\")) if ltpc.get(\"ltp\") is not None else np.nan)\n",
    "            raw_imb = ((bidq - askq) / (bidq + askq)) if (np.isfinite(bidq) and np.isfinite(askq) and (bidq+askq)>0) else np.nan\n",
    "            imb_ewm = smooth_imb(token, raw_imb)\n",
    "            mic = microprice(bidp, bidq, askp, askq)\n",
    "\n",
    "            row = {\n",
    "                \"Token\": token,\n",
    "                \"Ltp\": float(ltpc.get(\"ltp\")) if ltpc.get(\"ltp\") is not None else np.nan,\n",
    "                \"Ltq\": float(ltpc.get(\"ltq\")) if ltpc.get(\"ltq\") is not None else np.nan,\n",
    "                \"Cp\": float(ltpc.get(\"cp\")) if ltpc.get(\"cp\") is not None else np.nan,\n",
    "                \"BidP1\": bidp, \"BidQ1\": bidq, \"AskP1\": askp, \"AskQ1\": askq,\n",
    "                \"Ltt\": to_ist_ms(ltpc.get(\"ltt\")),\n",
    "                \"Oi\": float(ff.get(\"oi\")) if ff.get(\"oi\") is not None else np.nan,\n",
    "                \"Iv\": float(ff.get(\"iv\")) if ff.get(\"iv\") is not None else np.nan,\n",
    "                \"Atp\": float(ff.get(\"atp\")) if ff.get(\"atp\") is not None else np.nan,\n",
    "                \"Tbq\": float(ff.get(\"tbq\")) if ff.get(\"tbq\") is not None else np.nan,\n",
    "                \"Tsq\": float(ff.get(\"tsq\")) if ff.get(\"tsq\") is not None else np.nan,\n",
    "                \"Delta\": float(greeks.get(\"delta\")) if greeks.get(\"delta\") is not None else np.nan,\n",
    "                \"Theta\": float(greeks.get(\"theta\")) if greeks.get(\"theta\") is not None else np.nan,\n",
    "                \"Gamma\": float(greeks.get(\"gamma\")) if greeks.get(\"gamma\") is not None else np.nan,\n",
    "                \"Vega\":  float(greeks.get(\"vega\"))  if greeks.get(\"vega\")  is not None else np.nan,\n",
    "                \"Rho\":   float(greeks.get(\"rho\"))   if greeks.get(\"rho\")   is not None else np.nan,\n",
    "                \"Mid\": mid, \"DepthImb\": raw_imb, \"DepthImbEWM\": imb_ewm, \"MicroP\": mic\n",
    "            }\n",
    "            with _df_lock:\n",
    "                if token in feed_index:\n",
    "                    idx = feed_index[token]\n",
    "                    for k,v in row.items(): df_feed.at[idx, k] = v\n",
    "                else:\n",
    "                    idx = len(df_feed)\n",
    "                    df_feed = pd.concat([df_feed, pd.DataFrame([row])], ignore_index=True)\n",
    "                    feed_index[token] = idx\n",
    "                # enrich\n",
    "                df_loc = df_feed  # already has Mid/Spread etc from previous enrich; recompute spread quickly\n",
    "                if np.isfinite(bidp) and np.isfinite(askp):\n",
    "                    df_loc.at[idx,\"Spread\"] = (askp - bidp)\n",
    "                # attach meta columns from chain on full rebuild periodically to avoid heavy merge each tick\n",
    "                # cheap projection for now:\n",
    "                df_feed_enriched = enrich_feed(df_feed, df_chain)\n",
    "                # update vol ticks\n",
    "                try:\n",
    "                    tick = float(df_feed_enriched.loc[df_feed_enriched[\"Token\"]==token, \"tick_size\"].iloc[0])\n",
    "                except Exception:\n",
    "                    tick = 0.05\n",
    "                update_tick_vol(token, mid, tick)\n",
    "\n",
    "    streamer.on_message = _on_message\n",
    "    streamer.on_open = lambda: print(\"Market WS opened (v4.1)\")\n",
    "    streamer.on_error = lambda e: print(\"Market WS error:\", e)\n",
    "    streamer.on_close = lambda: print(\"Market WS closed\")\n",
    "    streamer.connect()\n",
    "    live_streamer = streamer\n",
    "    return streamer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db07fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_llm_for_strategy_buy_only(df_snapshot: pd.DataFrame) -> Dict[str, Any]:\n",
    "    if df_snapshot.empty or not _in_trading_window():\n",
    "        return {\"legs\": [], \"meta\": {\"reason\": \"empty_or_outside_window\"}}\n",
    "\n",
    "    cols = [\"Mid\",\"strike_price\",\"instrument_type\",\"Delta\",\"Spread\",\"tick_size\",\"DepthImbEWM\",\"Token\",\"lot_size\",\n",
    "            \"BidP1\",\"BidQ1\",\"AskP1\",\"AskQ1\",\"Gamma\",\"Theta\"]\n",
    "    miss = [c for c in cols if c not in df_snapshot.columns]\n",
    "    if miss:\n",
    "        return {\"legs\": [], \"meta\": {\"reason\": f\"missing_columns:{miss}\"}}\n",
    "\n",
    "    # compute spot slope & r2 and adapt delta band\n",
    "    slope, r2 = spot_slope_and_r2()\n",
    "    if abs(slope) > 0 and r2 >= 0.35:\n",
    "        dmin, dmax = 0.45, 0.60   # trending → slightly higher delta\n",
    "    else:\n",
    "        dmin, dmax = DELTA_MIN, DELTA_MAX\n",
    "\n",
    "    snap = df_snapshot.dropna(subset=[\"Mid\",\"strike_price\",\"instrument_type\",\"Delta\"]).copy()\n",
    "    if snap.empty:\n",
    "        return {\"legs\": [], \"meta\": {\"reason\": \"no_valid_rows\"}}\n",
    "\n",
    "    snap[\"absDeltaGap\"] = (snap[\"Delta\"].abs() - 0.50).abs()\n",
    "\n",
    "    def _spread_caps(token: str):\n",
    "        vt = vol_ticks_for(token)\n",
    "        cap_ticks = min(5, max(2, round(0.6 * vt)))\n",
    "        cap_pct = 0.004 if vt < 3 else 0.006\n",
    "        return cap_ticks, cap_pct\n",
    "\n",
    "    def _spread_ok(r):\n",
    "        tick = float(r.get(\"tick_size\") or 0.05)\n",
    "        spread = float(r.get(\"Spread\") or np.inf)\n",
    "        mid = float(r.get(\"Mid\") or np.nan)\n",
    "        cap_ticks, cap_pct = _spread_caps(r[\"Token\"])\n",
    "        ticks_spread = spread / max(tick,1e-6)\n",
    "        rel_spread = spread / max(mid,1e-9) if np.isfinite(mid) else np.inf\n",
    "        return (ticks_spread <= cap_ticks) and (rel_spread <= cap_pct)\n",
    "\n",
    "    def _ok_buy_row(r):\n",
    "        token = r[\"Token\"]\n",
    "        if not _spread_ok(r): return False\n",
    "        if not (dmin <= abs(float(r[\"Delta\"])) <= dmax): return False\n",
    "        imb = float(r.get(\"DepthImbEWM\") or 0.0)\n",
    "        # persistence\n",
    "        pers_ok = True\n",
    "        if USE_DEPTH_IMB_PERSIST:\n",
    "            pers = _imb_persist.get(token, 0)\n",
    "            side = r[\"instrument_type\"]\n",
    "            # update counter by latest imb (approx); require minimum\n",
    "            want = (imb >= +DEPTH_IMB_MIN) if side==\"CE\" else (imb <= -DEPTH_IMB_MIN)\n",
    "            if not want or pers < DEPTH_IMB_MIN_TICKS:\n",
    "                pers_ok = False\n",
    "        if not pers_ok: return False\n",
    "        # Gamma/Theta consideration (optional)\n",
    "        if MAX_ABS_THETA is not None:\n",
    "            th = abs(float(r.get(\"Theta\") or 0.0))\n",
    "            if th > MAX_ABS_THETA: return False\n",
    "        if MIN_GAMMA_EFF > 0.0:\n",
    "            geff = abs(float(r.get(\"Gamma\") or 0.0)) * abs(slope)\n",
    "            if geff < MIN_GAMMA_EFF: return False\n",
    "        # Cooldown after last exit\n",
    "        lastx = _last_exit_ts_for(token)\n",
    "        if lastx is not None:\n",
    "            try:\n",
    "                if (pd.Timestamp.now(tz=IST) - lastx).total_seconds() < PER_TOKEN_COOLDOWN_S:\n",
    "                    return False\n",
    "            except Exception:\n",
    "                pass\n",
    "        # IV z‑gate remains (reuse existing function)\n",
    "        z, iv_ok = iv_zscore_for(token, float(r.get(\"Iv\") or np.nan))\n",
    "        return iv_ok\n",
    "\n",
    "    ce = snap[(snap[\"instrument_type\"]==\"CE\")]\n",
    "    pe = snap[(snap[\"instrument_type\"]==\"PE\")]\n",
    "    ce_ok = ce[ce.apply(_ok_buy_row, axis=1)].sort_values([\"absDeltaGap\",\"Spread\"]).head(1)\n",
    "    pe_ok = pe[pe.apply(_ok_buy_row, axis=1)].sort_values([\"absDeltaGap\",\"Spread\"]).head(1)\n",
    "\n",
    "    pick = None\n",
    "    if not ce_ok.empty and not pe_ok.empty:\n",
    "        # choose by stronger absolute imbalance and microprice drift\n",
    "        def _score(r):\n",
    "            imb = abs(float(r[\"DepthImbEWM\"]))\n",
    "            bq, aq = float(r.get(\"BidQ1\") or 0.0), float(r.get(\"AskQ1\") or 0.0)\n",
    "            mp = microprice(float(r.get(\"BidP1\") or 0.0), bq, float(r.get(\"AskP1\") or 0.0), aq)\n",
    "            return imb + (0.01 if np.isfinite(mp) else 0.0)\n",
    "        r1, r2 = ce_ok.iloc[0], pe_ok.iloc[0]\n",
    "        pick = r1 if _score(r1) >= _score(r2) else r2\n",
    "    elif not ce_ok.empty:\n",
    "        pick = ce_ok.iloc[0]\n",
    "    elif not pe_ok.empty:\n",
    "        pick = pe_ok.iloc[0]\n",
    "    else:\n",
    "        return {\"legs\": [], \"meta\": {\"reason\": \"no_candidate_passed_filters\"}}\n",
    "\n",
    "    lot = int(pick.get(\"lot_size\") or 50)\n",
    "    leg = {\"token\": str(pick[\"Token\"]), \"side\": \"BUY\", \"qty\": lot, \"product\": DEFAULT_PRODUCT, \"order_type\": \"LIMIT\", \"_row\": pick.to_dict()}\n",
    "    meta = {\"mode\": \"long_only\", \"picked\": pick[\"instrument_type\"], \"score\": 0.60, \"dmin\": dmin, \"dmax\": dmax, \"slope\": slope, \"r2\": r2}\n",
    "\n",
    "    # Optional router scoring (unchanged)\n",
    "    context = {\"spot\": float(spot_ltp_current), \"row\": _compact_row(pick), \"rules\": {\"delta\":[dmin, dmax], \"ivZmax\":IV_Z_MAX}}\n",
    "    score, router_meta = score_with_router_and_meta_long_only(context)\n",
    "    meta.update({\"score\": score, **router_meta})\n",
    "\n",
    "    if USE_LLM and (score < LLM_SCORE_THRESHOLD):\n",
    "        return {\"legs\": [], \"meta\": meta}\n",
    "    return {\"legs\": [leg], \"meta\": meta}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dabb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Override compute_dynamic_stop to use EWM latency and ticks-based vol ---\n",
    "def compute_dynamic_stop(entry_price: float, side: str, tick: float, spread: float, bidq1: float,\n",
    "                         iv_z: float, latency_ms: float, stop_pct: float, token: str = None):\n",
    "    trigger = entry_price * (1 - stop_pct)\n",
    "    ticks_spread = spread / max(tick, 1e-6)\n",
    "    vt = vol_ticks_for(token) if token else 1.0\n",
    "    lat_ticks = max(0.0, _recent_latency_ms(latency_ms) / 25.0)\n",
    "    offset_ticks = int(max(1, round(0.5 * ticks_spread + 0.4 * vt + 0.1 * lat_ticks)))\n",
    "    limit = trigger - offset_ticks * tick\n",
    "    limit = math.floor(limit / max(tick,1e-6)) * max(tick,1e-6)\n",
    "    use_sl = (spread <= 0.30) and (bidq1 >= 1) and (abs(iv_z) <= 2.0)\n",
    "    return use_sl, float(trigger), float(limit), {\"offset_ticks\": offset_ticks, \"vt\": vt}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cbae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _place_protective_stop_for_entry(entry_idx: int, token: str, qty: int, entry_price: float, row: pd.Series):\n",
    "    tick = float(row.get(\"tick_size\") or 0.05)\n",
    "    spread = float(row.get(\"Spread\") or 0.0)\n",
    "    bidq1 = float(row.get(\"BidQ1\") or 0.0)\n",
    "    iv = float(row.get(\"Iv\") or np.nan)\n",
    "    iv_z, _ok = iv_zscore_for(token, iv)\n",
    "    lat_ms = _recent_latency_ms(60.0)\n",
    "    stop_pct = float(TRADE_LOG[entry_idx][\"stop_pct\"])\n",
    "    use_sl, trig, limit, meta = compute_dynamic_stop(entry_price, \"BUY\", tick, spread, bidq1, iv_z, lat_ms, stop_pct, token=token)\n",
    "\n",
    "    if not USE_SL_PROTECT:\n",
    "        use_sl = False\n",
    "    if exec_v3 is None:\n",
    "        return {\"ok\": False, \"error\": \"exec_v3 not initialized\"}\n",
    "\n",
    "    if use_sl:\n",
    "        info = exec_v3.place_stop_limit_exit_v3(instrument_token=token, exit_side=\"SELL\", trigger_price=trig,\n",
    "                                                limit_price=limit, quantity=qty, product=PRODUCT_MAP.get(DEFAULT_PRODUCT,\"I\"),\n",
    "                                                tag=f\"STOP-L-e{entry_idx}\")\n",
    "        if info.get(\"ok\"):\n",
    "            oid = info.get(\"order_id\")\n",
    "            TRADE_LOG[entry_idx][\"stop_order_id\"] = oid\n",
    "            TRADE_LOG[entry_idx][\"stop_active\"] = True\n",
    "            TRADE_LOG[entry_idx][\"stop_mode\"] = \"SL\"\n",
    "            if recon is not None:\n",
    "                recon.attach_meta(oid, {\"stop_for_entry_idx\": entry_idx, \"token\": token, \"planned_qty\": qty})\n",
    "            register_stop_sm(oid, token, entry_idx, limit, trig, tick)\n",
    "            return {\"ok\": True, \"order_id\": oid, \"mode\": \"SL\", **meta}\n",
    "        # fallthrough to SL-M if placement failed\n",
    "\n",
    "    info = exec_v3.place_stop_exit_v3(instrument_token=token, exit_side=\"SELL\", trigger_price=trig,\n",
    "                                      quantity=qty, product=PRODUCT_MAP.get(DEFAULT_PRODUCT,\"I\"),\n",
    "                                      tag=f\"STOP-e{entry_idx}\")\n",
    "    if info.get(\"ok\"):\n",
    "        TRADE_LOG[entry_idx][\"stop_order_id\"] = info[\"order_id\"]\n",
    "        TRADE_LOG[entry_idx][\"stop_active\"] = True\n",
    "        TRADE_LOG[entry_idx][\"stop_mode\"] = \"SL-M\"\n",
    "        if recon is not None:\n",
    "            recon.attach_meta(info[\"order_id\"], {\"stop_for_entry_idx\": entry_idx, \"token\": token, \"planned_qty\": qty})\n",
    "        register_stop_sm(info[\"order_id\"], token, entry_idx, limit=trig, trigger=trig, tick=tick)\n",
    "        STOP_SM[info[\"order_id\"]][\"active\"] = False\n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aead640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _stop_escalator_worker():\n",
    "    while not _stop_escalate_evt.is_set():\n",
    "        time.sleep(0.1)\n",
    "        now = time.perf_counter()\n",
    "        for oid in list(STOP_SM.keys()):\n",
    "            st = STOP_SM.get(oid)\n",
    "            if not st or not st.get(\"active\"):\n",
    "                continue\n",
    "            # planned and filled qty from TRADE_LOG if available\n",
    "            eidx = st.get(\"entry_idx\")\n",
    "            planned = int(TRADE_LOG[eidx][\"qty\"]) if (eidx is not None and eidx < len(TRADE_LOG)) else None\n",
    "            filled = int(TRADE_LOG[eidx].get(\"exit_filled_qty\") or 0) if (eidx is not None and eidx < len(TRADE_LOG)) else 0\n",
    "            if planned is not None and filled >= planned:\n",
    "                st[\"active\"] = False; continue\n",
    "\n",
    "            if (now - st[\"placed_ts\"]) * 1000.0 < SL_GRACE_MS:\n",
    "                continue\n",
    "            best_bid = _best_bid_for(st[\"token\"])\n",
    "            if best_bid is None:\n",
    "                continue\n",
    "            move_away = (best_bid < (st[\"limit\"] - st[\"tick\"]))  # for SELL, worse is below limit\n",
    "            if move_away and st[\"widens\"] < SL_MAX_WIDENS:\n",
    "                new_limit = st[\"limit\"] - SL_WIDEN_TICKS * st[\"tick\"]\n",
    "                ok = exec_v3.modify_order_v3(oid, price=new_limit).get(\"ok\", False) if exec_v3 is not None else False\n",
    "                if ok:\n",
    "                    st[\"limit\"] = new_limit\n",
    "                    st[\"widens\"] += 1\n",
    "                    st[\"placed_ts\"] = now\n",
    "                    if VERBOSE_RECON:\n",
    "                        print(f\"[stop-sm] widened {oid} -> {new_limit:.2f} widens={st['widens']}\")\n",
    "                    continue\n",
    "            # convert to SL-M as last resort\n",
    "            if exec_v3 is not None:\n",
    "                try:\n",
    "                    exec_v3.cancel_order_v3(oid)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                info = exec_v3.place_stop_exit_v3(instrument_token=st[\"token\"], exit_side=\"SELL\",\n",
    "                                                  trigger_price=st[\"trigger\"], quantity=int(TRADE_LOG[st[\"entry_idx\"]][\"qty\"]),\n",
    "                                                  product=PRODUCT_MAP.get(DEFAULT_PRODUCT,\"I\"),\n",
    "                                                  tag=f\"STOP-SLM-e{st['entry_idx']}\")\n",
    "                if info.get(\"ok\"):\n",
    "                    new_oid = info.get(\"order_id\")\n",
    "                    STOP_SM[new_oid] = dict(STOP_SM[oid], placed_ts=time.perf_counter(), widens=0)\n",
    "                    STOP_SM[oid][\"active\"] = False\n",
    "                    try:\n",
    "                        TRADE_LOG[eidx][\"stop_converted_to_slm\"] = True\n",
    "                        TRADE_LOG[eidx][\"stop_mode\"] = \"SL→SL-M\"\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    if recon is not None:\n",
    "                        recon.attach_meta(new_oid, {\"stop_for_entry_idx\": eidx, \"token\": st[\"token\"]})\n",
    "                    if VERBOSE_RECON:\n",
    "                        print(f\"[stop-sm] converted {oid} to SL-M\")\n",
    "                else:\n",
    "                    st[\"active\"] = False\n",
    "            else:\n",
    "                st[\"active\"] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b50716",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Reconciler v4.1: broader statuses, partial stop tracking, pre-cancel on target ---\n",
    "_terminal_filled = {\"complete\",\"completed\",\"filled\",\"fully_filled\"}\n",
    "_terminal_ended  = _terminal_filled | {\"cancelled\",\"rejected\"}\n",
    "\n",
    "def _recon_on_message_v41(self, message):\n",
    "    global ORDER_WS_LAST_TS\n",
    "    ORDER_WS_LAST_TS = time.time()\n",
    "\n",
    "    upd = self._extract_update(message)\n",
    "    oid = upd.get('order_id')\n",
    "    if not oid:\n",
    "        if VERBOSE_RECON: print(\"[recon] no order_id:\", message)\n",
    "        return\n",
    "\n",
    "    cur_qty = int(upd.get('filled_quantity') or 0)\n",
    "    cur_avg = float(upd.get('average_price') or 0.0)\n",
    "    cur_val = cur_qty * cur_avg\n",
    "    prev_qty = self.last_seen_fill_qty[oid]\n",
    "    prev_val = self.last_seen_fill_val[oid]\n",
    "    d_qty = max(cur_qty - prev_qty, 0)\n",
    "    d_val = max(cur_val - prev_val, 0.0)\n",
    "    self.last_seen_fill_qty[oid] = cur_qty\n",
    "    self.last_seen_fill_val[oid] = cur_val\n",
    "\n",
    "    self._append_fill_log(upd)\n",
    "    if d_qty > 0 and VERBOSE_RECON:\n",
    "        print(f\"[recon] FILL {oid} Δqty={d_qty} cum={cur_qty} @ {cur_avg}\")\n",
    "\n",
    "    meta = self.order_meta.get(oid, {})\n",
    "    eidx = meta.get(\"exit_of_entry_idx\")\n",
    "    sidx = meta.get(\"stop_for_entry_idx\")\n",
    "    status = (upd.get(\"status\") or \"\").lower()\n",
    "\n",
    "    # Track partial stop fills against planned qty\n",
    "    if sidx is not None:\n",
    "        try:\n",
    "            TRADE_LOG[sidx][\"exit_filled_qty\"] = int(cur_qty)\n",
    "        except Exception:\n",
    "            pass\n",
    "        if status in _terminal_filled:\n",
    "            try:\n",
    "                rec = TRADE_LOG[sidx]\n",
    "                avg_px = float(upd.get(\"average_price\") or rec.get(\"exit_price\") or 0.0)\n",
    "                rec[\"exit_reason\"] = rec.get(\"exit_reason\") or \"stop\"\n",
    "                rec[\"exit_price\"] = float(avg_px) if avg_px else rec.get(\"exit_price\")\n",
    "                rec[\"exit_ts\"] = pd.Timestamp.now(tz=IST)\n",
    "                entry = float(rec.get(\"entry_price\") or 0.0)\n",
    "                side  = str(rec.get(\"side\") or \"BUY\").upper()\n",
    "                pnl_leg = (avg_px - entry) if side==\"BUY\" else (entry - avg_px)\n",
    "                rec[\"pnl_abs\"] = float(pnl_leg); rec[\"pnl_pct\"] = float(pnl_leg / entry) if entry else rec.get(\"pnl_pct\")\n",
    "                rec[\"remaining_qty\"] = 0; rec[\"stop_active\"] = False\n",
    "                stk = TRADE_OPEN_STACK.get(rec[\"token\"], [])\n",
    "                if stk and sidx in stk:\n",
    "                    try: stk.remove(sidx)\n",
    "                    except ValueError: pass\n",
    "                # mark STOP_SM inactive\n",
    "                if oid in STOP_SM: STOP_SM[oid][\"active\"] = False\n",
    "            except Exception as e:\n",
    "                if VERBOSE_RECON: print(\"[recon] stop finalize error:\", e)\n",
    "\n",
    "    # Exit WAP aggregation for target/other exits\n",
    "    if eidx is not None:\n",
    "        agg = self.exit_wap[eidx]\n",
    "        ostate = agg[\"orders\"].setdefault(oid, {\"cum_qty\": 0, \"cum_val\": 0.0})\n",
    "        ostate[\"cum_qty\"] = cur_qty; ostate[\"cum_val\"] = cur_val\n",
    "        if d_qty > 0 and d_val > 0:\n",
    "            agg[\"num\"] += d_val; agg[\"den\"] += d_qty\n",
    "            exit_wap = agg[\"num\"] / max(agg[\"den\"], 1)\n",
    "            try:\n",
    "                rec = TRADE_LOG[eidx]\n",
    "                rec[\"exit_price\"] = float(exit_wap)\n",
    "                rec[\"exit_filled_qty\"] = int(agg[\"den\"])\n",
    "                entry = float(rec.get(\"entry_price\") or 0.0)\n",
    "                side  = str(rec.get(\"side\") or \"SELL\").upper()\n",
    "                pnl_leg = (exit_wap - entry) if side==\"BUY\" else (entry - exit_wap)\n",
    "                rec[\"pnl_abs\"] = float(pnl_leg); rec[\"pnl_pct\"] = float(pnl_leg / entry) if entry else None\n",
    "            except Exception as e:\n",
    "                if VERBOSE_RECON: print(\"[recon] ledger update error:\", e)\n",
    "\n",
    "        if status in _terminal_ended:\n",
    "            try:\n",
    "                rec = TRADE_LOG[eidx]; rec[\"exit_fill_ts\"] = pd.Timestamp.now(tz=IST)\n",
    "                # Cancel protective stop if still active\n",
    "                stop_id = rec.get(\"stop_order_id\")\n",
    "                if stop_id and rec.get(\"stop_active\"):\n",
    "                    if 'exec_v3' in globals() and exec_v3 is not None:\n",
    "                        exec_v3.cancel_order_v3(stop_id)\n",
    "                    rec[\"stop_active\"] = False\n",
    "                    if stop_id in STOP_SM: STOP_SM[stop_id][\"active\"] = False\n",
    "            except Exception as e:\n",
    "                if VERBOSE_RECON: print(\"[recon] stop cancel error:\", e)\n",
    "\n",
    "# Monkey patch class method\n",
    "if 'UpstoxPortfolioReconciler' in globals():\n",
    "    UpstoxPortfolioReconciler._on_message = _recon_on_message_v41\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54455f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _flatten_all_positions_eod():\n",
    "    if exec_v3 is None: \n",
    "        print(\"[EOD] exec_v3 not init; skip flatten\"); \n",
    "        return\n",
    "    with _df_lock:\n",
    "        snapshot = df_feed_enriched.copy()\n",
    "    for token, pos in list(open_positions.items()):\n",
    "        q = int(pos.get(\"qty\") or 0)\n",
    "        if q <= 0: continue\n",
    "        row = snapshot.loc[snapshot[\"Token\"]==token]\n",
    "        if row.empty: continue\n",
    "        row = row.iloc[0]\n",
    "        best_bid = float(row.get(\"BidP1\") or row.get(\"Mid\") or 0.0)\n",
    "        best_ask = float(row.get(\"AskP1\") or row.get(\"Mid\") or 0.0)\n",
    "        tick = float(row.get(\"tick_size\") or 0.05)\n",
    "        info = exec_v3.place_order_v3(instrument_token=token, side=\"SELL\", quantity=q,\n",
    "                                      best_bid=best_bid, best_ask=best_ask, tick_size=tick,\n",
    "                                      product=PRODUCT_MAP.get(DEFAULT_PRODUCT,\"I\"), marketable_limit=True,\n",
    "                                      buffer_ticks=LIMIT_BUFFER_TICKS, tag=\"EOD-FLAT\")\n",
    "        print(\"[EOD] flatten sent:\", token, info)\n",
    "\n",
    "# Hook into backfill worker timing by redefining _backfill_worker with EOD flatten gate\n",
    "try:\n",
    "    _orig_backfill_worker = _backfill_worker\n",
    "    def _backfill_worker():\n",
    "        global _last_backfill_ts\n",
    "        while not _backfill_stop_evt.is_set():\n",
    "            time.sleep(1.0)\n",
    "            now = time.time()\n",
    "            # EOD flatten\n",
    "            try:\n",
    "                hhmm = pd.Timestamp.now(tz=IST).strftime(\"%H:%M\")\n",
    "                if EOD_FLATTEN_ENABLED and hhmm == EOD_FLATTEN_AT and _have_live_things():\n",
    "                    _flatten_all_positions_eod()\n",
    "            except Exception:\n",
    "                pass\n",
    "            if not BACKFILL_ENABLED: continue\n",
    "            if (now - _last_backfill_ts) < BACKFILL_MIN_INTERVAL_S: continue\n",
    "            eod_guard = (hhmm >= \"15:29\" and hhmm <= \"15:30\")\n",
    "            stale_ws = (now - ORDER_WS_LAST_TS) >= BACKFILL_TRIGGER_NO_WS_S\n",
    "            if eod_guard or (stale_ws and _have_live_things()):\n",
    "                backfill_once(); _last_backfill_ts = now\n",
    "except Exception:\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
